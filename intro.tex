\chapter{Introduction}

Time series data, or data consisting of measurements collected sequentially over time, are common in many fields including the social, physical, technological, and biological sciences. Finding innovative ways to analyze and interpret this kind of data has been crucial to advancing these fields and developing important applications such as weather tracking \citep{dixon:wiener:weather:1993}, communication signal processing \citep{gardner:signal:1994}, and social media networks \citep{smith:social:2009}. Analysis of sequential data pose several challenges to the researcher. Firstly, the data often exhibit nonlinear behavior. Secondly, the data are typically autocorrelated, meaning that there tends to be a relationship among data points based on their proximity in time. These issues are problematic for analysis using traditional statistical methods that require linear structure and independent observations.

State-space models provide a general framework that is convenient for modeling nonlinear and autocorrelated data by describing a process in terms of a latent, dynamic state. In these models, observations are regarded as conditionally independent given the underlying state of the system, and the state evolves over time according to a linear or nonlinear process. Typically, the general form of these models may be reasonably assumed, but each model may contain unknown fixed parameters that are specific to the application area. In this thesis, we employ state-space models with unknown fixed parameters to study time series data from two specific areas: disease surveillance and functional magnetic resonance imaging (fMRI).

State-space models are frequently used for disease outbreaks to simultaneously model the underlying disease dynamics and the observation process \citep{Mart:Cone:Lope:Lope:baye:2008, merl2009statistical, ludkovski2010optimal, skvortsov2012monitoring, unkel2012statistical}. Together with syndromic surveillance systems \citep{henning2004overview, wagner2006biosurveillance, wilson2006synsurveillance, hakenewerth2009north, Gins:Mohe:Pate:Bram:Smol:Bril:dete:2009}, these models are used to identify emerging disease outbreaks \citep{neill2006bayesian}, estimate their severity \citep{merl2009statistical}, and predict their duration \cite{ludkovski2010optimal}. Data from fMRI experiments are used for the purpose of mapping neural activation in the brain \citep{ashby:fmri:2011,kiebel:holmes:spm:2007,pold:fmri:2011}. The data are typically analyzed using a linear regression model that correlates the observed data with the expected brain response to the experimental stimulus \citep{friston:frith:JCBFM:1991,friston:holmes:hbm:1995}. We reformulate this regression model within the state-space framework to model autocorrelation in the data in terms of a dynamic state.

In statistical applications where prior knowledge or beliefs about unknown quantities are available, the Bayesian framework is often convenient for performing statistical analysis.  Bayesian inference is conducted through the posterior distribution of any unknown quantities, obtained by updating prior information using observed data. However, the calculation of the posterior distribution in state-space models frequently involves complicated integrals without an explicit analytical form. The most common approach to approximating these posterior distributions is Markov chain Monte Carlo (MCMC) \citep{Gelf:Smit:samp:1990}. In a sequential context, e.g. syndromic surveillance, MCMC is inefficient due to the increase in computational cost incurred by the need for the entire MCMC to be rerun as each new observation arrives. Sequential Monte Carlo (SMC) - or particle filtering - methods enable on-line inference by updating the estimate of the posterior as new data become available. Furthermore, SMC methods can be flexible, general, easy to implement, and amenable to parallel computing. For a general introduction, please see \cite{Douc:deFr:Gord:sequ:2001} and \cite{cappe2007overview}.

In this thesis, we analyze data from disease surveillance and fMRI using MCMC and SMC algorithms. We compare several particle filtering algorithms in terms of how efficiently they estimate states and fixed parameters in a state-space model for tracking a disease epidemic similar to one used by \citet{skvortsov2012monitoring}. We find that an algorithm developed by \citet{Liu:West:comb:2001} that regenerates fixed parameter values through the use of a kernel density approximation outperforms algorithms that incorporate fixed parameters into the state process with degenerate evolutions. We also find, under this particular model, that the \citet{Liu:West:comb:2001} algorithm is competitive with particle MCMC \citep{Andr:Douc:Hol:pmcmc:2010}.

Then, we discuss how SMC methods can be used to compare alternative models through estimation of the marginal likelihood of the data. We compare the performance of more recently developed particle filters in terms of how efficiently they identify a true model using simulated data. We find that a particle learning algorithm \citep{Carv:Joha:Lope:Pols:part} outperforms both the resample-move particle filter \citep{Gilk:Berz:foll:2001} and the \citet{Liu:West:comb:2001} algorithm when applied to data simulated from a local level dynamic linear model with common state and observation variance factor \cite[Chapter 4.3.1][]{petris:camp:2009:dynamic}.

Next, we provide an overview of data generated from fMRI experiments and describe the most common strategies for data analysis used in the field. We underscore the negative impact of analyzing fMRI data without properly accounting for autocorrelation present in the data, and we explore possible models for correctly modeling this autocorrelation. States and unknown parameters in these models are estimated using maximum likelihood estimation, and we compare competitive models against one another through examination of statistical criteria. We also use simulated fMRI time series to compare models in terms of the rate of concluding significant brain activation.

Lastly, we implement a particle learning algorithm for estimating states and fixed parameters in state-space models for fMRI data. We also estimate the marginal likelihood of the data and compare relative posterior probabilities among several models. Specifically, we consider the likelihood of a regression model with a dynamic slope being suitable for fMRI data, with the notion that a changing slope component could model changes in focus or learning on the part of the subject in the fMRI scanner. Using simulated data, we explore parameter settings under which we can correctly identify each of the possible models we consider as being the true data-generating model, and we compare these models using real fMRI data generated from a word recognition experiment. Our results suggest that a dynamic slope model may be suitable only for a very small percentage of fMRI time series, but that larger models that incorporate a dynamic slope as well as other components to account for autocorrelation in fMRI data may be appropriate.

This thesis is organized as follows. Chapter 2 contains descriptions of state-space models in general as well as the specific models we use to analyze syndromic surveillance and fMRI data. Chapter 3 describes MCMC and SMC methods for making inference on states and unknown fixed parameters in these models. Chapter 4 describes an analysis comparing several particle filtering strategies using simulated syndromic data from an influenza-like epidemic outbreak. In Chapter 5, we describe a model comparison strategy using SMC methods and compare several particle filters in terms of their ability to accurately compare first-order dynamic linear models with varying signal-to-noise ratios. Lastly, in Chapter 6, we investigate current methods of effectively modeling autocorrelated fMRI time series and use an SMC model comparison strategy for assessing the suitability of dynamic regression models for fMRI data. 