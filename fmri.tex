\chapter{Statistical analysis of fMRI data \label{ch:fmri}}

In this chapter, we use models and tools described in Chapters \ref{ch:models} and \ref{ch:meth} to analyze time series data collected from an fMRI experiment. We describe the most common method of statistical analysis used in the field, i.e. the correlation-based general linear model (GLM) approach \citep{friston:frith:JCBFM:1991,friston:holmes:hbm:1995}, and discuss challenges associated with analyzing fMRI data using this method. We mainly focus on the problem of how to deal with temporally autocorrelated data. Autocorrelated time series invalidate results obtained using the standard GLM, which assumes independence of the error terms in the model. We explore possible variations of the GLM to account for this autocorrelation and show via simulation the negative consequences of using the standard GLM to analyze autocorrelated data.

We then fit fMRI data collected from a word recognition experiment to the dynamic regression models described in Section \ref{sec:dlm:arwn} using maximum likelihood estimation, and we propose a model comparison strategy using PL. Using simulated data, we evaluate our ability to identify true model parameters via maximum likelihood estimation. Then, we use PL to examine conditions under which we can correctly identify a true data-generating model amongst several candidate models. Finally, we analyze real fMRI data using PL and discuss the appropriateness of the dynamic slope model for this data and as a tool for future fMRI studies.

In Section \ref{sec:fmri:intro}, we provide an overview of fMRI, standard estimation of fMRI time series, and the experimental data set. This material is mainly taken from \citet{ashby:fmri:2011}. In Section \ref{sec:fmri:cor}, we compare several techniques for estimating parameters in fMRI time series models and explore their impact on fitted model residuals as well as false positive/true positive rates of concluding significant brain activation. In Section \ref{sec:fmri:dr}, we investigate our ability to identify true values of model parameters in the dynamic regression models described in Section \ref{sec:dlm:arwn}, and we fit real fMRI data to these models using maximum likelihood estimation. Finally, in Section \ref{sec:fmri:pl}, we use simulated data to examine the possibility of comparing these dynamic regression models against each other using PL, and we discuss results from applying PL under these models to real fMRI data.

\section{Overview of fMRI \label{sec:fmri:intro}}

Functional MRI provides an indirect measure of neural activation in the brain in near real time. Most fMRI experiments measure the \emph{blood oxygen level-dependent (BOLD) signal}, or ratio of oxygenated to deoxygenated hemoglobin in the blood. Evidence suggests that a type of neural activity called the local field potential is closely related to the BOLD signal recorded in an fMRI experiment \citep{logo:bold:2003,logo:bold:2001}. By providing a noninvasive way to study functional changes in the brain over time, fMRI has allowed researchers to study topics that had previously seemed impossible to give a detailed scientific investigation, such as the nature of consciousness \citep{lloyd:conscious:2002}, meditation \citep{cahn:med:2006}, and moral judgement \citep{greene:moral:2001}.

\subsection{The haemodynamic response \label{sec:fmri:hrf}}

The BOLD response to a neural impulse is characterized by an increase in the BOLD signal from a baseline level to its peak at around 6 seconds post-stimulus, followed by a gradual decay back to baseline over the next 20-25 seconds. This typical BOLD response to an impulse as a function of time is referred to as the \emph{haemodynamic response function (hrf)}, and knowledge about this function is crucial for effectively analyzing data from fMRI experiments. Although studies have shown that the hrf varies from person to person based on factors such as age \citep{rich:hrf:2003}, most analyses assume a known form of the hrf for all subjects. A commonly used hrf that is thought to represent an average BOLD response for a typical subject is defined by the SPM software package for analysis of fMRI data (http://www.fil.ion.ucl.ac.uk/spm/doc/). This hrf is known as the canonical hrf (see bottom panel of Figure \ref{fig:fmri:data}). Another commonly used hrf is the gamma function proposed by \citet{boyn:linear:1996}, given by
\begin{equation}
h(s) = \frac{(s/\tau)^{n-1}e^{-s/\tau}}{\tau(n-1)!}, \label{eqn:hrf}
\end{equation}
where $s$ is time in seconds and $\tau$ and $n$ are free parameters that determine the shape of the hrf. We use the canonical hrf for analyzing data from a word recognition experiment in Sections \ref{sec:fmri:arma}, \ref{sec:fmri:mle}, and \ref{sec:fmri:real}, and we use the gamma hrf for simulating fMRI data in Sections \ref{sec:fmri:fpr}, \ref{sec:fmri:res}, \ref{sec:fmri:id}, \ref{sec:fmri:sim}, \ref{sec:fmri:dist}, and \ref{sec:fmri:kappa}.

\subsection{The scanning session \label{sec:fmri:scan}}

An fMRI scanning session consists of one or more runs in which a human subject is presented with a simple task designed to stimulate the brain while scans are taken every few seconds. Runs can typically last anywhere between 10 and 30 minutes, and the \emph{repetition time (TR)}, or length between individual scans, can be anywhere between 1 and 3 seconds. Each scan within a TR involves creating cross-sectional images, or \emph{slices}, across the whole brain. Although TRs less than one second are possible on some machines, decreasing the TR length often comes at the cost sacrificing spatial resolution of the images resulting from each scan.

Each whole brain image consists of a three-dimensional array of volumetric pixels, or \emph{voxels}, and each voxel contains a value of the BOLD response for a small area of the brain. Voxel size and TR must be determined prior to running an experiment based on desired spatial and temporal resolution of the data. An average experiment might involve three 10-minute scanning runs with a TR of 2 seconds. An average scan might consist of 36 slices, where each slice consists of a 64 by 64 array of 3 $\mbox{mm}^3$ voxels. In this average scenario, each image would be made up of 147,456 voxels, and data from the entire scanning session would contain 132,710,400 BOLD values. Combining this with the fact that many studies involve multi-subject experiments, the sheer size of fMRI data sets impose significant challenges for data analysis.

In addition to choosing scanning parameters such as voxel size and TR, designing an fMRI experiment also involves deciding on how the experimental stimulus is presented to the subject in the scanner. Three experimental designs used in fMRI are block designs, slow event-related designs, and rapid event-related designs. Block designs divide functional runs into blocks of continuous activity and continuous rest, usually lasting anywhere from 30 seconds to a couple of minutes. During the activation blocks, subjects are instructed to perform the same task continuously over the entire block. In event-related designs, the stimulus \emph{onsets}, or TRs at which an experimental stimulus is presented to the subject, are chosen randomly, with the time between onsets, or \emph{delay}, usually somewhere between 2 and 16 seconds. Slow event-related designs include rest periods that last around 30 seconds, while rapid event-related designs use shorter rest periods.

The long rest periods included in block and slow event-related designs are meant to allow the BOLD response to decay back to baseline before the next stimulus presentation. This helps increase the power of statistical tests designed to identify neural activation or distinguish between event types. However, these designs result in longer experiments which are more expensive and incur a greater risk of having the subject's mind wander during rest periods and generate non-task related BOLD signal. Rapid event-related designs have become more popular with the development of statistical methods such as the GLM approach that make analysis of data collected from these experiments possible.

This section is intended to provide a quick overview of fMRI for the purpose of giving context to the analyses discussed in the rest of this chapter. For more information on fMRI and designing fMRI experiments, we refer the reader to \citet{ashby:fmri:2011,pold:fmri:2011}.

\subsection{The correlation-based GLM approach \label{sec:fmri:glm}}

The standard correlation-based GLM analysis of fMRI data models the observed BOLD response in a single voxel of the brain as a linear function of the expected BOLD response from a voxel responding to the experimental stimulus, i.e.
\begin{equation}
y_t = \beta_0 + \beta_1\mbox{conv}_t + \epsilon_t, \label{eqn:fmri:glm}
\end{equation}
where $y_t$ is the observed BOLD response at TR $t$, $\mbox{conv}_t$ is the expected BOLD response at TR $t$ in an active voxel, $\beta = (\beta_0,\beta_1)'$ are unknown fixed regression coefficients, and $\epsilon_t \stackrel{iid}{\sim} \mbox{N}(0,\sigma^2)$ are independent random errors. The expected BOLD response, $\mbox{conv}_t$, is calculated by convolving the hrf with an ``on-off'' boxcar function that is equal to 1 when the experimental stimulus is on and 0 when it is off. Specifically,
\begin{equation}
\mbox{conv}_t = \int_0^t N(\omega)h(t-\omega)d\omega, \label{eqn:fmri:conv}
\end{equation}
where $N(\omega)$ represents the value of the neural activation boxcar at time $\omega$. Note that $N(\omega)$ and $h(\omega)$ are defined in continuous time. However, since we observe the BOLD response at discrete time points determined by the TR, we define the time indices $t$ and $\omega$ in units of TRs. For example, if our experiment had a TR of 2 seconds, the gamma hrf defined in equation \eqref{eqn:hrf} could be convolved with a boxcar function via equation \eqref{eqn:fmri:conv} to obtain $\mbox{conv}_t$ by letting $\omega = s/2$. Expected responses to different event types can be included in this model as additional covariates by convolving the hrf with the boxcar function associated with each event. In this chapter, we restrict ourselves to experiments with a single event type.

Under the model given by equation \eqref{eqn:fmri:glm}, the hypothesis test
\begin{equation}
H_0: \beta_1 = 0 \quad H_A: \beta_1 > 0 \label{eqn:fmri:hyp}
\end{equation}
is usually of interest, where rejection of $H_0$ in favor of $H_A$ is interpreted as evidence of neural activation in the voxel from which the fMRI time series came from. To test this hypothesis, ordinary least squares estimates of the unknown fixed parameters $\beta$ and $\sigma^2$ are computed, i.e.
\begin{equation}
\hat{\beta}  = (\hat{\beta}_0,\hat{\beta}_1)' = (X'X)^{-1}X'y \qquad \hat{\sigma}^2 = \frac{1}{T-2}\lVert y-X\hat{\beta} \rVert, \label{eqn:fmri:ols}
\end{equation}
where $T$ is the total number of TRs in the functional run, $X$ is the $T$ by $2$ design matrix with first column all 1's and second column equal to $\mbox{conv}_t$, $y = (y_1,\ldots,y_T)'$, and $\lVert\cdot\rVert$ is the Euclidean norm. The test statistic, $t^*$, and p-value, $p^*$, are then calculated by
\begin{equation}
t^* = \frac{\hat{\beta}_1}{\sqrt{\hat{\sigma}^2(X'X)_{(2,2)}^{-1}}} \qquad p^* = \mbox{P}(t^* > 0|H_0), \label{eqn:fmri:ttest}
\end{equation}
where $(X'X)_{(2,2)}^{-1}$ is the element in the second row and second column of $(X'X)^{-1}$, and $P(A|H_0)$ is the probability of event $A$ assuming $H_0$ is true. Thus, $p^*$ is calculated under the assumption that $t^* \sim \mbox{T}(0,1,T-2)$, and $H_0$ is rejected if $p^*$ is less than some significance threshold $\alpha$.

The majority of fMRI studies perform this hypothesis test independently for every voxel, resulting in a statistical parametric map of brain activation. With this approach, an adjustment to the significance threshold $\alpha$ must be made to account for multiple hypothesis tests being performed simultaneously. For example, if a false positive rate of $\alpha = 0.05$ is desired, a corrected threshold $\alpha^*$ must be used for each independent test so that the probability of a false positive among all tests is 0.05. Because of the spatial relationship among voxels, these hypothesis tests are not actually independent of each other, and this complicates the problem of finding the necessary correction. Typically, an approach relying on the theory of Gaussian random fields is used \citep{wors:grf:1995,wors:mar:cerebral:1996,wors:evans:cerebral:1992,friston:frith:JCBFM:1991}. We refer the reader to \citet[Chapter 6,][]{ashby:fmri:2011} for more information on the multiple comparisons problem.

The standard GLM approach to analyzing fMRI data, which models univariate time series separately for each voxel, is convenient because regression theory allows for simple forms of estimators and fast computation. However, aside from using a multiple comparisons correction, the spatial nature of fMRI data and the connection between voxel-wise time series is ignored using this approach. Hence, a second-stage connectivity analysis is required to gain any insight into neural networks \cite[Chapters 8 and 9][]{ashby:fmri:2011}. The development of multivariate methods that analyze activation and connectivity simultaneously has gained popularity over the last decade. These include independent components analysis \citep{beck:smith:ica:2004}, multi-voxel pattern recognition \citet{norman:mvpa:2006}, representation similarity analysis \citep{nili:rs:2014}, and Bayesian spatio-temporal modeling approaches such as those developed by \citet{wool:jenk:bayesSp:2004}, \citet{bowman:2008:SpMCMC}, \citet{quiros:diez:2010:BayesSpTemp}, and \citet{zhang:guin:2014:npBayesWave}, to name a few.

While the development of efficient numerical approximation algorithms have decreased the computational burden of analyzing fMRI data using Bayesian spatio-temporal models, they are still slower and more difficult to implement than the standard GLM approach. Thus, voxel-wise hypothesis tests are still the norm in fMRI data analysis, and we operate within the framework of the univariate GLM for the remainder of this chapter. For more information on fMRI and standard statistical techniques used in the field, see \citet{ashby:fmri:2011, penny:spm:2011}.

\subsection{Word recognition task \label{sec:fmri:data}}

The data set that we analyze in Sections \ref{sec:fmri:dr} and \ref{sec:fmri:pl} come from an episodic word recognition experiment for one human subject. The task the subject worked on, described in \citet{bennett:miller:2013}, consisted of an encoding session that took place outside the scanner and a recognition session that took place inside the scanner. During encoding, the subject was presented with a list of words one at a time and told to memorize the words so that if they saw one of them again, they would recognize it. During the recognition session, the subject was presented with a another list of words, some of which they saw during encoding and some of which were new. The subject was asked to respond as to whether they thought each word was old or new based on their memory.

While in the scanner, the words were presented according to a rapid-event related design with random delays between onsets somewhere between 2 and 10 seconds. The expected BOLD response ($\mbox{conv}_t$) for this design was then constructed by convolving the canonical hrf with a boxcar function that is equal to 1 during TRs when a word was presented to the subject and 0 otherwise. The middle panel of Figure \ref{fig:fmri:data} shows $\mbox{conv}_t$ for this experiment. Scans of the subject's brain were taken every 1.5 seconds for about 6 minutes ($T = 245$ total TRs) with a voxel size of 3 $\mbox{mm}^3$. Although whole brain data were recorded, we look specifically at time series from 5 by 5 by 5 voxel cubes (125 voxels per cube) extracted from six different brain regions, namely the left frontal pole (FP), left intraparietal sulcus (IPS-left), right intraparietal sulcus (IPS-right), primary visual cortex (PV), left secondary visual cortex (SV-left), and right secondary visual cortex (SV-right).

An important step that is performed prior to analyzing fMRI data is preprocessing of the raw data that comes directly out of the scanner. For example, images need to be spatially realigned to reduce the effect of the subject's head movements while inside the scanner. In addition, a high-resolution structural image taken prior to the functional run can be used to discern the exact location of voxels that are difficult to locate in lower resolution functional images. This process is called \emph{coregistration} of the functional and structural data. The coregistered data then needs to be normalized to a standard brain atlas so that active voxels can be assigned to a neuroanatomic brain structure.

For this data set, preprocessing proceeded as outlined in \citet{bennett:miller:2013}:
\begin{quote}
\dsp
``The functional time series were spatially realigned to the first image using a least squares approach with a 6-parameter rigid body affine transformation \citep{friston:ash:spreg:1995}. Realigned images were then ``unwarped'' to reduce the influence of residual movement-related variance on BOLD signal intensity \citep{andersson:deform:2001}. The functional data were coregistered to a high-resolution T1 anatomical image using mutual information maximization with a 6-parameter rigid body affine transform \citep{ashburner:neelin:reg:1997}. Then, the images were normalized to the standard 3D brain atlas defined by the International Consortium for Brain Mapping using a combination of a 12-parameter linear affine transformation and 3 by 2 by 3 nonlinear three-dimensional discrete cosine transform. A 7th degree B-spline was used as the interpolation method for creating normalized images \citep{ashburner:friston:spnorm:1999,mazz:toga:atlas:1995}.''
\end{quote}

Other common preprocessing steps include spatial smoothing and slice-timing correction. Spatial smoothing is intended to get rid of some of the noise in the data and allow for the use of Gaussian random field theory when applying a correction for multiple hypothesis tests. Slice-timing correction adjusts for the fact that brain slices taken during a particular TR don't occur at the same time. For the word recognition experiment, the data were spatially smoothed with an 8 mm full-width at half maximum isotropic Gaussian kernel. Slice-timing correction was not applied to the data and is not typically used when the TR is less than 2 seconds \citep{penny:spm:2011}.

Preprocessing of fMRI data is intended to improve statistical analysis by removing \emph{artifacts}, or abnormalities in the data due to non-task related events. However, it is possible that preprocessing can also add artifacts to the data. For instance, the compound effect of applying both slice-timing correction and spatial realignment can effect the signal in the data. While researchers hope to find signals in the data that provide insight into task-related neural activity, it is possible that the way data are preprocessed can affect results. For more information on preprocessing of fMRI data, see \citet[Chapter 4,][]{ashby:fmri:2011}.

The top panel of Figure \ref{fig:fmri:data} shows the preprocessed fMRI time series for a voxel in IPS-left. Notice that the pattern of the observed time series somewhat mirrors the active response displayed in the middle panel for TRs greater than 75, but not for TRs less than 75. This type of behavior motivates our thinking that a regression model with a changing slope, such as $M_{011}$, might be appropriate for modeling fMRI data.

\begin{figure}
\ssp
\centering
\caption{Single voxel time series from fMRI experiment} \label{fig:fmri:data}
\includegraphics[width=1.0\textwidth]{fmri-craig-data}
\caption*{Time series data (top), expected BOLD response (middle), and haemodynamic response function (bottom) versus TR for voxel 27 in the left intraparietal sulcus.}
\end{figure}

\section{Temporal autocorrelation \label{sec:fmri:cor}}

The standard GLM approach to identifying task-related activity in a single voxel of the brain relies on an assumption of independence of the error terms, $\epsilon_t$, in equation \eqref{eqn:fmri:glm}. This assumption is not reasonable for fMRI data since random departures between the observed and predicted BOLD responses are likely to be similar among voxels near to each other in time and space. One reason for this is that the BOLD response to neural activation is not uniform across space \citep{aguirre:zarahn:varyBOLD:1998}, so any assumed hrf is guaranteed to be at least slightly inaccurate. Thus, if the BOLD response in a voxel at one particular TR is greater than average, it is likely to also be greater than average in nearby voxels and at subsequent TRs \cite[Chapter 1][]{ashby:fmri:2011}. Other factors that contribute to spatially and temporally autocorrelated errors are unaccounted for signals in the data such as non-task related cognitive activity on the part of the subject and small movements caused by heartbeat and respiration \citep{loc:jos:arma:1997}.

An approach to handling temporally autocorrelated fMRI time series that was developed early on is to ``color'' the data using a low-pass temporal filter to reduce high-frequency noise and amplify the signal in the data \citep{friston:holmes:color:1995,wors:frist:color:1995}. An alternate approach used by \citet{bullmore:prewhiten:1996} involves a two-stage procedure where the data are \emph{prewhitened} by first estimating the autocorrelation in the errors using the residuals from a GLM fit and then transforming the data to remove the autocorrelation. The standard GLM analysis is then applied to the uncorrelated data. The prewhitening approach is an improvement over coloring the data because it yields minimum variance unbiased estimates of the regression coefficients, provided the autocorrelation is accurately estimated from the residuals \citep{frist:penny:classical:2002}. \citet{wool:rip:auto:2001} show using resting state data that prewhitening performs more efficiently than coloring and that the bias in the autocorrelation estimates is acceptably low if adequate spatial and temporal smoothing is carried out during preprocessing.

The prewhitening approach to handling autocorrelated errors is the standard technique used in the FSL software package (http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/). Other approaches attempt to account for temporal autocorrelations explicitly through modeling. For example, \citet{lund:mad:nvr:2006} measured effects thought to contribute to autocorrelated noise such as heartbeat, respiration, and magnetic field strength and included them as additional covariates in the GLM. SPM uses an approach developed by \citet{kiebel:holmes:spm:2007} that models the correlation in the errors by
\begin{equation}
\epsilon \sim \mbox{N}(0,\sigma^2 I_T + \lambda Q) \quad Q_{i,j} = \left\{\begin{array}{ll} 0, & \mbox{if } i=j \\ e^{-|i-j|}, & \mbox{if } i\ne j, \end{array} \right.
\end{equation}
where $T$ is the total number of TRs in the experiment, $\epsilon = (\epsilon_1,\ldots,\epsilon_T)'$, and $\lambda$ is another unknown fixed parameter. Restricted maximum likelihood estimation (REML) is carried out to estimate the unknown fixed parameters, and the hypothesis test in equation \eqref{eqn:fmri:hyp} is performed using the test statistic
\begin{equation}
t^* = \frac{\hat{\beta_1}}{\sqrt{\left((X'X)^{-1}X'(\hat{\sigma}^2 I_T + \hat{\lambda} Q)X(X'X)^{-1}\right)_{(2,2)}}}, \label{eqn:fmri:hyp-reml}
\end{equation}
where $\hat{\beta_1}$, $\hat{\sigma}^2$, and $\hat{\lambda}$ are the REML estimates. We discuss REML more in Section \ref{sec:fmri:fpr}. Under the null hypothesis, $t^* \sim \mbox{T}(0,1,df)$, where the degrees of freedom $df$ is computed by the Satterthwaite approximation \citep{wors:frist:color:1995}. In Section \ref{sec:fmri:fpr}, we compare ordinary least squares (OLS) estimation, prewhitening, and REML in terms of false positive and true positive rates of significant brain activation using simulated data.

\subsection{Exploration of ARMA models \label{sec:fmri:arma}}

Numerous studies have used first and second order autoregressive models for the error term of the GLM \citep{bullmore:prewhiten:1996, loc:jos:arma:1997}. We now explore the class of regression models with $\mbox{ARMA}(P,Q)$ errors discussed in Section \ref{sec:dlm:arma} using maximum likelihood estimation to see if other ARMA error structures might be appropriate for the word recognition data set.

Recall from Section \ref{sec:dlm:arma} that the DLM formulation of a regression model with $\mbox{ARMA}(P,Q)$ errors is given by equations \eqref{eqn:dlm:reg:obs} and \eqref{eqn:dlm:reg:state} with $x_t = (x_{t,1} ,x_{t,2}, \ldots, x_{t,m})'$ an $m$-dimensional vector, $m = \mbox{max}(P,Q+1)$, $F_t$ a time-invariant $1 \times m$ vector with first element equal to 1 and the rest 0, $v_t = 0$ for all $t$, $G$ a $m \times m$ matrix that takes the form
\[
G = \left(
 \begin{array}{ccccc}
 \phi_1 & \vdots \\
 \phi_2 & \vdots \\
 \phi_3 & \vdots && I_{m-1} \\
 \vdots & \vdots \\
 \cdots & \cdots & \cdots & \cdots & \cdots \\
 \phi_m &\vdots & 0 & \cdots & 0
 \end{array}
\right),
\]
and $W = \sigma^2ee'$ with $e = (1, \gamma_1, \ldots, \gamma_m)'$. The unknown fixed parameters are given by $\theta = (\beta', \phi', \gamma', \sigma^2)'$, where $\beta = (\beta_0,\beta_1)'$, $\phi = (\phi_1,\phi_2,\ldots,\phi_P)'$ and $\gamma = (\gamma_1,\gamma_2,\ldots,\gamma_Q)'$. We let $U_t = (1,\mbox{conv}_t)$, where $\mbox{conv}_t$ is the convolution, evaluated at TR $t$ via equation \eqref{eqn:fmri:conv}, of the canonical hrf with the on-off boxcar function representing the stimulus pattern for the word recognition experiment. We adopt the convention that $\phi_s = 0$ for $s > P$ and $\gamma_r = 0$ for $r > Q$.

Maximization of the likelihood is performed using the R function {\tt arima}, which calls on {\tt optim} to minimize the negative log likelihood, given by
\begin{equation}
-\log p(y_{1:T}|\theta) = \frac{1}{2}\sum_{t=1}^T \log|Q_t| + \frac{1}{2}\sum_{t=1}^T \zeta_t' Q_t^{-1} \zeta_t. \label{eqn:fmri:loglik}
\end{equation}
Here, $\zeta_t = y_t - U_t\beta - f_t$ are the \emph{innovations} of the ARMA process, with $f_t$ and $Q_t$ being the mean and variance of the one-step ahead forecasts for $y_t$. For fixed $\theta$, $f_t$ and $Q_t$ are computed via the Kalman filter in equation \eqref{eqn:dlm:kal}, provided the initial values $m_0$ and $C_0$. These initial values are chosen such that the stationarity constraint given in equation \eqref{eqn:arma:prior} is satisfied \citep{gardner:harvey:mlearma:1980}. Given an initial set of fixed parameter values, optimization is performed using an iterative algorithm that alternates between running the Kalman filter conditional on $\theta$ and minimizing equation \eqref{eqn:fmri:loglik} conditional on $f_{1:T}$ and $Q_{1:T}$ \citep{durbin:koopman:timeseries:2012,shum:stof:2006:timeseries}. Fixed parameter values are constrained to their regions of stationarity, given by equations \eqref{eqn:arpoly} and \eqref{eqn:mapoly}, using the transformation method of \citet{jones:arma:1980}.

Five randomly chosen voxels from each of the six brain regions were fit to regression models with ARMA errors for all combinations of $P$ and $Q$ up to order 10. We then evaluated each model fit using three criteria: Akaike's information criterion (AIC) \citep{sak:ish:kit:aic:1986}, AIC corrected for bias (AICC) \citep{sug:aicc:1978,hurv:tsai:aicc:1989}, and Bayes' information criterion (BIC) \citep{schwarz:bic:1978}. For our model with a single regression covariate, the formulas for these criteria are given by
\begin{align}
AIC &= -2\log p(y_{1:T}|\hat{\theta}) + 2(P+Q+3) \label{eqn:aic} \\
AICC &= -2\log p(y_{1:T}|\hat{\theta}) + 2T\frac{P+Q+2}{T-P-Q-3} \label{eqn:aicc} \\
BIC &= -2\log p(y_{1:T}|\hat{\theta}) + (\log T)(P+Q+3), \label{eqn:bic}
\end{align}
where $\hat{\theta}$ is the MLE of the unknown fixed parameters and $\log p(y_{1:T}|\hat{\theta})$ is the value of the log-likelihood at convergence of the optimization procedure.

We prefer to use models that minimize these criteria. The first term is the same for all criteria and should be smaller for better model fits. The second term is a penalty for the number of parameters in the model. BIC imposes the strongest penalty for having more parameters and is most likely out of the three to prefer simpler models. The values of $P$ and $Q$ that minimized each of these criteria for each randomly selected voxel were recorded, and the average $P$ and $Q$ for each brain region are shown in Table \ref{tab:fmri:arma}. From these averages, it appears that AIC and AICC prefer $P$ and $Q$ near 3 while BIC prefers $P = 1$ and an $Q = 0$ or 1. We prefer to use the simpler models chosen by BIC and will mainly focus on models that incorporate first-order autoregressive errors in the remainder of this chapter.

\begin{table}
\ssp
\centering
\caption{Mean AR and MA orders for experimental fMRI data} \label{tab:fmri:arma}
\begin{tabular}{|l|cc|cc|cc|}
\hline
Region & \multicolumn{6}{|c|}{Criterion} \\
\hline
 & \multicolumn{2}{|c|}{AIC} & \multicolumn{2}{|c|}{AICC} & \multicolumn{2}{|c|}{BIC} \\
\hline
 & $P$ & $Q$ & $P$ & $Q$ & $P$ & $Q$ \\
\hline
Left frontal pole          & 2.80 & 3.20 & 2.80 & 2.90 & 1.70 & 0.90 \\
Left intraparietal sulcus  & 3.75 & 3.50 & 3.50 & 3.25 & 1.81 & 0.06 \\
Right intraparietal sulcus & 3.20 & 2.80 & 3.20 & 2.80 & 0.80 & 0.80 \\
Primary visual             & 3.10 & 3.00 & 3.10 & 2.70 & 0.90 & 1.70 \\
Secondary visual left      & 3.20 & 2.90 & 2.10 & 2.40 & 1.40 & 0.00 \\
Secondary visual right     & 3.20 & 3.00 & 3.10 & 2.50 & 0.70 & 0.70 \\
\hline
Mean across regions     & 3.21 & 3.07 & 2.97 & 2.76 & 1.22 & 0.69 \\
\hline
\end{tabular}
\caption*{Mean AR and MA orders ($P$ and $Q$, respectively) chosen according to AIC, AICC, and BIC for maximum likelihood fits of regression models with ARMA errors to voxel-wise time series from 5 by 5 by 5 voxel cubes taken from 6 different brain regions.}
\end{table}

\subsection{False positive and true positive rates \label{sec:fmri:fpr}}

In this section, we consider the impact of different approaches to testing for brain activation in autocorrelated voxel-wise time series. Specifically, we examine false positive and true positive rates. The false positive rate is the rate of concluding significant neural activation in a voxel when there is no activity present. The true positive rate (or power) is the rate of concluding significant neural activation when there is in fact activity present. We prefer methods that yield a high true positive rate while keeping the false positive rate low. In this section, we examine the effect on the false positive rate of using standard OLS estimation of the regression slope, and we compare different methods for accounting for temporal autocorrelation in terms of their effect on false postive and true positive rates.

To analyze false positive and true positive rates, we simulated fMRI data from the regression model described in Section \ref{sec:fmri:arma} with AR(1) error structure (i.e. $P = 1$ and $Q = 0$). An experiment with a rapid event-related design and a single event type was created by simulating random times between onsets according to a truncated geometric distribution with a maximum time-to-event of 10 TRs. We used a TR of 2 seconds and let the experiment run for 250 total TRs. Onset of the stimuli were assumed to last the length of the TR, and an on-off boxcar function of 1's and 0's was constructed to match the stimulus pattern. The independent variable in the regression, $\mbox{conv}_t$, was constructed by convolving the boxcar function with the gamma hrf from equation \eqref{eqn:hrf} with $\tau = 2$ and $n = 4$. Figure \ref{fig:fmri:design} displays the simulated experimental design and expected BOLD response for active voxels.

Time series of length $T = 250$ were then simulated according to $M_{100}$, i.e. a regression model with AR(1) errors. For these simulations, we let $\beta_0 = 750$ and $\sigma^2 = 15$, and one thousand time series were generated for every $(\beta_1,\phi) \in \{0,1,2,3\}\times\{0.25,0.50,0.75,0.95\}$. Different values of $\beta_1$ were used so that we could analyze false positive rates (for $\beta_1 = 0$) and power (for $\beta_1 > 0$). Similarly, different values of $\phi$ were used for simulation so that we could analyze false positive rates and true positive rates for increasing amounts of autocorrelation in the data.

\begin{figure}
\ssp
\centering
\caption{Simulated rapid-event related design of fMRI experiment} \label{fig:fmri:design}
\includegraphics[width=1.0\textwidth]{fmri-design-3-500-1}
\caption*{Simulated boxcar function (top), hrf (middle), and convolution of the boxcar with the hrf (bottom) for a rapid-event related design of an fMRI experiment.}
\end{figure}

For each simulated time series, we tested the hypothesis in equation \eqref{eqn:fmri:hyp} using the OLS method, i.e. where the test statistic and p-value are calculated according to equations \eqref{eqn:fmri:ols} and \eqref{eqn:fmri:ttest}. We also performed hypothesis tests using prewhitening (PW) and two variations of a REML approach. Our PW and REML approaches both assume a stationary AR(1) process for the error terms in the GLM, i.e.
\begin{align}
y &= X\beta + \epsilon, \quad \mbox{ where} \label{eqn:fmri:ar1} \\
\epsilon &\sim \mbox{N}(0,\sigma^2\Lambda), \nonumber \\
\Lambda_{i,j} &= \frac{\phi^{|i-j|}}{1 - \phi^2}, \nonumber
\end{align}
$\beta = (\beta_0,\beta_1)'$ are the fixed regression coefficients, $y$ and $X$ are data vector and design matrix, respectively, as defined in equations \eqref{eqn:fmri:ols} and \eqref{eqn:fmri:ttest}, and $\epsilon = (\epsilon_1,\ldots,\epsilon_T)'$ is the vector of error terms.
 
The PW approach uses the fact that if $\Lambda$ is known, the data can be transformed via
\begin{equation}
y^* = S^{-1}y \qquad X^* = S^{-1}X, \label{eqn:gls:trans}
\end{equation}
where $S$ is the Cholesky decomposition of $\Lambda$ (i.e. $SS' = \Lambda$), to yield the independent error GLM given by
\begin{equation}
y^* = X^*\beta + \epsilon \quad \epsilon \sim \mbox{N}(0,\sigma^2I_T). \label{eqn:gls}
\end{equation}
We carry out the PW method on a time series from a single voxel by first fitting the data using OLS. Then, the residuals from this fit are refit using maximum likelihood to a zero-mean AR(1) process via the {\tt arima} function in R. The maximum likelihood estimate of the autocorrelation in the residuals, given by $\hat{\phi}$, is used to approximate $\phi$ in equation \eqref{eqn:fmri:ar1}, and an estimate of the covariance matrix $\Lambda$ is computed according to
\begin{equation}
\hat{\Lambda}_{(i,j)} = \frac{\hat{\phi}^{|i-j|}}{1-\hat{\phi}^2}. \label{eqn:pw:cor}
\end{equation}
The data are then transformed according to
\begin{equation}
\hat{y}^* = \hat{S}^{-1}y \qquad \hat{X}^* = \hat{S}^{-1}X, \label{eqn:pw:trans}
\end{equation}
where $\hat{S}$ is the Cholesky decomposition of $\hat{\Lambda}$. Lastly, the hypothesis test is performed using the OLS method with $\hat{y}^*$ and $\hat{X}^*$ used in place of $y$ and $X$ in equations \eqref{eqn:fmri:ols} and \eqref{eqn:fmri:ttest}.

For hypothesis tests using REML, we first obtain an estimate of $\phi$ by maximizing the profiled log-restricted likelihood, derived by \citet{harville:reml:1977} and given by
\begin{align}
\log p(y|\phi) \propto & -(T-2)\log\left|\left| y^* - X^*\left[(X^*)'X^*\right]^{-1}(X^*)'y^* \right|\right| \label{eqn:fmri:plrl} \\
 & - \frac{1}{2}\log\left|(X^*)'X^*\right| - \frac{1}{2} \log \Lambda. \nonumber
\end{align}
Estimation using the restricted likelihood is intended to remove bias in estimating variance components due to fixed regression coefficients, and the expression in \eqref{eqn:fmri:plrl} is obtained by integrating $\beta$ out of the full likelihood. Note that the data and design matrix in equation \eqref{eqn:fmri:plrl} are transformed such that the model errors are independent, and $y^*$, $X^*$, and $\Lambda$ are each implicitly functions of $\phi$. Once $\hat{\phi}$ that maximizes equation \eqref{eqn:fmri:plrl} is found, estimates of $\beta$ and $\sigma^2$ are computed by
\begin{equation}
\hat{\beta} = \left[(\hat{X}^*)'\hat{X}^*\right]^{-1}(\hat{X}^*)'\hat{y}^* \qquad \hat{\sigma}^2 = \frac{1}{T-2}\left|\left| \hat{y}^*-\hat{X}^*\hat{\beta} \right|\right|, \label{eqn:fmri:reml}
\end{equation}
where $\hat{\phi}$ maximizes $\log p(y|\phi)$ and $\hat{X}^*$ and $\hat{y}^*$ are calculated using equations \eqref{eqn:pw:cor} and \eqref{eqn:pw:trans}. The t-test in equation \eqref{eqn:fmri:ttest} is then carried out using the REML estimates of $\hat{\beta}_1$ and $\hat{\sigma}^2$, and $\hat{X}^*$ is used in place of $X$.

% using the test statistic
%\begin{equation}
%t^* = \frac{\hat{\beta_1}}{\sqrt{\left((X'X)^{-1}X'(\hat{\sigma}^2\hat{\Lambda})X(X'X)^{-1}\right)_{(2,2)}}}, \label{eqn:fmri:hyp-reml:ar1}
%\end{equation}
%and $p^*$ is calculated as in equation \eqref{eqn:fmri:ttest} under the assumption that $t^* \sim \mbox{T}(0,1,T-2)$.

We used the {\tt gls} function in R package {\tt nlme} to find $\hat{\phi}$ that maximizes the profiled log-restricted likelihood in equation \eqref{eqn:fmri:plrl} \citep{pin:bates:mixed:2000}. The t-test was then performed conditional on the REML estimate of $\Lambda$, as described above. However, because the correlation structure is estimated and not known, the null distribution of the t-statistic does not exactly follow $\mbox{T}(0,1,T-2)$. Alternatively, we can adjust the degrees of freedom of the t-distribution to account for the estimated autocorrelation in the data. We consider a strategy that corrects the degrees of freedom using an effective sample size adjustment for time series with first-order autocorrelation \citep{dawdy:matalas:ess:1964}. Specifically, we adjust the degrees of freedom in the t-test to $T' - 2$, where
\begin{equation}
T' = T\frac{1-\hat{\phi}}{1+\hat{\phi}}. \label{eqn:fmri:ess}
\end{equation}
We will refer to the method that incorporates REML estimates of the unknown fixed parameters with an effective sample size adjustment to the degrees of freedom of the t-test as REMLc (for corrected REML).

Table \ref{tab:fmri:fpr} displays false positive rates of rejecting $H_0$ using significance thresholds $\alpha = 0.001, 0.01, \mbox{ and } 0.05$ for the 1000 simulations using $\beta_1 = 0$ and increasing values of $\phi$. Methods of estimation that accurately assess the uncertainty in $\hat{\beta_1}$ should yield false positive rates equal to $\alpha$. We can see from the table that using OLS inflates the false positive rate, and furthermore that the factor by which the false positive rate is inflated relative to $\alpha$ increases as $\alpha$ decreases. This is an undesirable feature, since lower $\alpha$ levels should result in more conservative tests.

From the plots in Figure \ref{fig:fmri:fpr}, we see that 95\% confidence intervals around the false positive rate for PW and REML contain the nominal threshold $\alpha$ for all values of $\phi$. REMLc appears to give slightly lower false positive rates than REML and PW for $\phi \le 0.75$ and decidedly lower false positive rates for $\phi = 0.95$. While this may seem to be an advantage of REMLc, a decrease in the false positive rate can come at the cost of a decrease in the true positive rate as well. Figure \ref{fig:fmri:roc} illustrates this point using ROC curves. The ROC curves in this figure display the true positive rate versus the false positive rate for the hypothesis tests performed according to each method. The methods with the largest area under the ROC curve performed the best in terms of distinguishing between the null and alternative hypotheses. We see from the curve corresponding to $\phi = 0.95$ that REMLc is outperformed by PW and REML, suggesting that although REMLc offers a decrease in the false positive rate for highly autocorrelated data relative to the other methods, it does not identify as many active voxels.

\begin{table}
\ssp
\centering
\caption{False positive rates for simulated fMRI data} \label{tab:fmri:fpr}
\begin{tabular}{|c|cccc|}
\hline
$\alpha$ & OLS & PW & REML & REMLc \\
\hline
 & \multicolumn{4}{|c|}{$\phi = 0.25$} \\
\hline
0.001 & 0.006 & 0.001 & 0.001 & 0.001 \\
0.010 & 0.028 & 0.011 & 0.010 & 0.010 \\
0.050 & 0.106 & 0.050 & 0.049 & 0.048 \\
\hline
 & \multicolumn{4}{|c|}{$\phi = 0.50$} \\
\hline
0.001 & 0.022 & 0.002 & 0.002 & 0.002 \\
0.010 & 0.070 & 0.010 & 0.009 & 0.007 \\
0.050 & 0.161 & 0.054 & 0.052 & 0.052 \\
\hline
 & \multicolumn{4}{|c|}{$\phi = 0.75$} \\
\hline
0.001 & 0.061 & 0.001 & 0.001 & 0.000 \\
0.010 & 0.130 & 0.017 & 0.016 & 0.015 \\
0.050 & 0.213 & 0.064 & 0.062 & 0.055 \\
\hline
 & \multicolumn{4}{|c|}{$\phi = 0.95$} \\
\hline
0.001 & 0.072 & 0.000 & 0.000 & 0.000 \\
0.010 & 0.144 & 0.011 & 0.011 & 0.000 \\
0.050 & 0.230 & 0.046 & 0.049 & 0.023 \\
\hline
\end{tabular}
\caption*{False positive rates at significance levels $\alpha = 0.001, 0.01, \mbox{ and } 0.05$ (rows) for testing $H_0: \beta_1 = 0$ vs $H_A: \beta_1 > 0$ using OLS, PW, REML, and REMLc (columns) on simulated data from $M_{100}$ with $\beta = (750, 3)$, $\sigma^2 = 15$, and increasing $\phi$ (embedded tables).}
\end{table}

\begin{figure}
\ssp
\centering
\caption{False positive rates for simulated fMRI data} \label{fig:fmri:fpr}
\includegraphics[width=1.0\textwidth]{simstudy-FPR}
\caption*{False positive rates (solid lines) and 95\% confidence intervals (dashed lines) for testing $H_0: \beta_1 = 0$ vs $H_A: \beta_1 > 0$ plotted against the nominal threshold level $\alpha$ (gray line) using OLS (black lines), PW (red lines), REML (green lines), and REMLc (blue lines) on simulated data from $M_{100}$ with $\beta = (750, 0)$, $\sigma^2 = 15$, and increasing $\phi$ (plot panels).}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{ROC curves for simulated fMRI data} \label{fig:fmri:roc}
\includegraphics[width=1.0\textwidth]{simstudy-ROC-3}
\caption*{ROC curves for testing $H_0: \beta_1 = 0$ vs $H_A: \beta_1 > 0$ using OLS (black lines), PW (red lines), REML (green lines), and REMLc (blue lines) on simulated data from $M_{100}$ with $\beta = (750, 3)$, $\sigma^2 = 15$, and increasing $\phi$ (plot panels).}
\end{figure}

\subsection{Testing independence of residuals \label{sec:fmri:res}}

In the previous section, we used false positive rates to compare several methods that attempt to sufficiently capture the autocorrelation in fMRI time series. To do this, we simulated non-active voxels by letting the true $\beta_1 = 0$. In practice, however, we don't know beforehand which voxels are inactive, making false positive rates difficult to obtain. Many studies have attempted to analyze false positive rates using \emph{resting state} data, or fMRI data generated from a subject at rest \citep{purdon:weiss:fpr:1998,burock:dale:fpr:2000,wool:rip:auto:2001}. These studies have effectively provided insight into the impact of certain autocorrelation estimation algorithms, sampling rates, and experimental designs on false positive rates. However, it is difficult to assess whether voxels from a subject who is resting are really inactive. For example, the subject's mind could wander during the experiment and generate a BOLD signal. Furthermore, research suggests that some brain areas exhibit some intrinsic activation during resting state, such as those associated with the default mode network \citep{grei:kras:dfmnet:2003,grei:sup:dfmnet:2009}.

An alternate strategy that has been used for evaluating different models of autocorrelation in fMRI data is to examine the residuals from a model fit and test whether or not they are uncorrelated \citep{luo:nich:diag:2003,leonski:bax:res:2008}. In particular \citet{leonski:bax:res:2008} compares a number of autocorrelation estimation algorithms used in different software packages such as SPM and FSL. They suggest that an AR(2) process be used for modeling the errors in fMRI time series. This is based in part on the fact that residuals from AR(2) fits were determined to be uncorrelated more often than for other models according statistical tests such as the Durbin-Watson and cumulative periodogram tests.

While an AR(2) error structure may be appropriate for modeling some data sets, we contend that an analysis of residuals should not be the basis for this decision. This is because of the potential for overfitting. To illustrate, we fit the simulated data described in Section \ref{sec:fmri:fpr} with $\beta = (750,3)'$, $\sigma^2 = 15$, and $\phi \in \{0.25,0.50,0.75,0.95\}$ to regression models with independent, AR(1), and AR(2) errors. The regression models with independent errors were fit using OLS, and those with AR(1) and AR(2) errors were fit using the {\tt arima} function in R. For each model fit, we tested the independence of the residuals using the Ljung-Box test for lag-1 autocorrelations \citep{box:test:1978}. The results in Table \ref{tab:fmri:res} show that even though the true data-generating model has AR(1) errors, residuals from the AR(2) fit were determined to be uncorrelated as much if not more than those from the AR(1) fit. For this reason, we do not recommend evaluating models with autocorrelated errors based on an assessment of independence of residuals. Instead, in Section \ref{sec:fmri:pl}, we explore a model comparison strategy based on PL.

\begin{table}
\ssp
\centering
\caption{Proportion of whitened residuals for simulated fMRI data} \label{tab:fmri:res}
\begin{tabular}{|c|ccc|}
\hline
$\alpha$ & OLS & AR(1) & AR(2) \\
\hline
 & \multicolumn{3}{|c|}{$\phi = 0.25$} \\
\hline
0.001 & 0.332 & 1.000 & 1.000 \\
0.010 & 0.134 & 1.000 & 1.000 \\
0.050 & 0.028 & 1.000 & 1.000 \\
\hline
 & \multicolumn{3}{|c|}{$\phi = 0.50$} \\
\hline
0.001 & 0.000 & 1.000 & 1.000 \\
0.010 & 0.000 & 1.000 & 1.000 \\
0.050 & 0.000 & 0.999 & 1.000 \\
\hline
 & \multicolumn{3}{|c|}{$\phi = 0.75$} \\
\hline
0.001 & 0.000 & 1.000 & 1.000 \\
0.010 & 0.000 & 1.000 & 1.000 \\
0.050 & 0.000 & 0.994 & 1.000 \\
\hline
 & \multicolumn{3}{|c|}{$\phi = 0.95$} \\
\hline
0.001 & 0.000 & 1.000 & 1.000 \\
0.010 & 0.000 & 0.991 & 1.000 \\
0.050 & 0.000 & 0.958 & 1.000 \\
\hline
\end{tabular}
\caption*{Proportion of whitened residuals determined by Ljung-Box test at varying significance levels $\alpha$ (rows) from fitting data simulated from $M_{100}$ with $\beta = 3$, $\sigma^2 = 15$, and increasing $\phi$ (embedded tables) to regression models with independent (OLS), AR(1), and AR(2) error structures.}
\end{table}

\section{Fitting dynamic regression models \label{sec:fmri:dr}}

We now turn our attention to the dynamic regression models described in Section \ref{sec:dlm:arwn}. Specifically, we examine the dynamic intercept model ($M_{101}$), dynamic slope model ($M_{011}$), and a model with both a dynamic intercept and a dynamic slope ($M_{111}$). $M_{101}$ can be thought of as a regression model with AR(1)+WN errors, which is commonly used to analyze fMRI time series. Of particular interest to us is the possibility of modeling fMRI time series using $M_{011}$ or $M_{111}$ . While models similar to $M_{101}$ are thought to adequately capture autocorrelation in fMRI data, we explore the possibility that a model such as $M_{011}$ can improve on existing methods by incorporating a dynamic slope that can adapt to learning or changes in focus on the part of the subject.

\subsection{Identifiability of dynamic regression models \label{sec:fmri:id}}

Before applying the dynamic regression models to actual fMRI data, we examine whether the models themselves are identifiable. To do this, we simulated 1000 time series of length $T = 250$ from each of $M_{101}$, $M_{011}$, and $M_{111}$ using the expected BOLD response pictured in the middle panel of Figure \ref{fig:fmri:design} as the covariate $\mbox{conv}_t$. We let the true $\beta = (750, 15)'$ for all models and repeated the simulations for various values of $\phi$, $\sigma^2_s$, $\sigma^2_m$, $\rho$, and $\sigma^2_b$ (these last two parameters are only relevant for $M_{111}$). Specifically, for $M_{101}$ and $M_{011}$, we simulate for all combinations of $\phi \in \{0.1, 0.5, 0.9\}$, $\sigma^2_s \in \{1, 5, 10, 15, 20\}$, and $\sigma^2_m = 10$. For $M_{111}$, we simulate for all combinations of $\phi \in \{0.3, 0.6, 0.9\}$, $\sigma^2_s \in \{1, 5, 10, 15, 20\}$, $\sigma^2_b \in \{1, 5, 10, 15, 20\}$, $\rho \in \{0.3, 0.6, 0.9\}$, and $\sigma^2_m = 10$. The choice of these particular values was motivated by the MLEs from fitting real fMRI data in Section \ref{sec:fmri:mle}.

For each simulated time series, we calculate MLEs for the unknown fixed parameters using the {\tt dlmMLE} function in R package {\tt dlm} \citep{petris:camp:2009:dynamic}. We use this function instead of {\tt arima} because it allows us to incorporate the observation error, $v_t$, into the model. Like {\tt arima}, this function uses a call to {\tt optim} to minimize the negative log likelihood, expressed as
\begin{equation}
-\log p(y_{1:T}|\theta) \propto \frac{1}{2}\sum_{t=1}^T \log |Q_t| + \frac{1}{2}\sum_{t=1}^T (y_t-f_t)'Q_t^{-1}(y_t-f_t). \label{eqn:fmri:dlmll}
\end{equation}
Here, $f_t$ and $Q_t$ depend implicitly on $\theta$ and are calculated according to the Kalman filter given by equation \eqref{eqn:dlm:kal} with initial values $m_0 = C_0 = 0$ (to constrain $x_0 = 0$). Notice the similarity between equation \eqref{eqn:fmri:dlmll} and the negative log likelihood that is minimized using the {\tt arima} function given by equation \eqref{eqn:fmri:loglik}. The only difference between these two expressions is the omission of the regression term, $U_t\beta$, in equation \eqref{eqn:fmri:dlmll}. This is because the {\tt dlmMLE} function operates on models of the form given by equations \eqref{eqn:dlm:obs} and \eqref{eqn:dlm:state}, where the additional regression term is not included. Thus, to use this function to find MLEs of fixed parameters in the dynamic regression models, $\beta$ and $U_t$ must be incorporated into $x_t$ and $F_t$. Letting $F_t$ and $x_t$ be the 1 by 1 matrix and univariate state, respectively, defined in the formulation of the dynamic regression models from Section \ref{sec:dlm:arwn}, we can reexpress the model as
\begin{align}
y_t &= \tilde{F}_t\tilde{x}_t + v_t \label{eqn:dlmmle:obs} \\
\tilde{x}_t &= \tilde{G}\tilde{x}_{t-1} + w_t, \label{eqn:dlmmle:state}
\end{align}
where $\tilde{x}_t = (\beta_0,\beta_1,x_t)'$, $\tilde{F}_t = (1,U_t,F_t)$,
\[\tilde{G} = \left(\begin{array}{ccc} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & \phi\end{array}\right), \]
and \[v_t \stackrel{iid}{\sim} \mbox{N}(0,\sigma^2_m) \quad w_t \stackrel{iid}{\sim} \mbox{N}\left(\left(\begin{array}{c} 0 \\ 0 \\ 0 \end{array}\right), \left(\begin{array}{ccc} 0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & \sigma^2_s \end{array}\right)\right).\]
MLEs of $\phi$, $\sigma^2_s$, are $\sigma^2_m$ (denoted $\hat{\phi}$, $\hat{\sigma}^2_s$, and $\hat{\sigma}^2_m$) are then obtained using {\tt dlmMLE}. MLEs for $\beta$ are obtained from the first and second elements of $m_T$ after running the Kalman filter conditional on $\hat{\phi}$, $\hat{\sigma}^2_s$, and $\hat{\sigma}^2_m$.

Figure \ref{fig:fmri:id:M011SNR} displays histograms of the MLEs for fits of $M_{011}$ to data simulated from the same model with $\phi = 0.1$ and increasing signal-to-noise ratio $\sigma^2_s / \sigma^2_m$. $\beta$ appears to be identified for all values of the signal-to-noise ratio, as evidenced by two-dimensional histograms that show an ellipse with a clear mode near the true value. $\phi$, $\sigma^2_s$, and $\sigma^2_m$, however, don't appear to be identified as well for lower values of the signal-to-noise ratio and particularly for $\sigma^2_s / \sigma^2_m = 0.1$. Figure \ref{fig:fmri:id:M011PRR} shows similar plots with $\sigma^2_s / \sigma^2_m = 0.1$ and increasing $\phi$. While identification of $\phi$, $\sigma^2_s$, and $\sigma^2_m$ is poor for $\phi = 0.1$, a drastic improvement is shown by increasing $\phi$ to 0.5 and 0.9. $\beta$, again, is identified well for all fixed parameter values shown in the figure.

\begin{figure}
\ssp
\centering
\caption{Identifying dynamic slope model by increasing signal-to-noise ratio} \label{fig:fmri:id:M011SNR}
\includegraphics[width=0.75\textwidth]{1000-250-M011-conv-750-15-1-5-SNR-10-10}
\caption*{Histograms in 1D (for $\phi$, second column) and 2D (for $\beta$ and $(\sigma^2_s,\sigma^2_m)$, 1st and 3rd columns) of MLEs of fits of $M_{011}$ to data simulated from $M_{011}$ with $\beta = (750,15)'$, $\phi = 0.1$, $\sigma^2_m = 10$, and increasing $\sigma^2_s$ (rows). Blue X's denote true values of $\beta$ and $(\sigma^2_s,\sigma^2_s)$, and blue vertical lines denote the true value of $\phi$.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Identifying dynamic slope model by increasing autocorrelation} \label{fig:fmri:id:M011PRR}
\includegraphics[width=1.0\textwidth]{1000-250-M011-conv-750-15-PRR-5-1-10-10}
\caption*{Histograms in 1D (for $\phi$, second column) and 2D (for $\beta$ and $(\sigma^2_s,\sigma^2_m)$, 1st and 3rd columns) of MLEs of fits of $M_{011}$ to data simulated from $M_{011}$ with $\beta = (750,15)'$, $\sigma^2_s = 1$, $\sigma^2_m = 10$, and increasing $\phi$ (rows). Blue X's denote true values of $\beta$ and $(\sigma^2_s,\sigma^2_s)$, and blue vertical lines denote the true values of $\phi$.}
\end{figure}

Figures \ref{fig:fmri:id:M011SNR} and \ref{fig:fmri:id:M011PRR} provide evidence that $M_{011}$ is identifiable provided the signal-to-noise ratio and autocorrelation coefficient is not too low. Similar plots shown in Figures \ref{fig:fmri:id:M101SNR} and \ref{fig:fmri:id:M101PRR} reveal that identifiability of $M_{101}$ is more challenging. We see in Figure \ref{fig:fmri:id:M101SNR} that no signal-to-noise ratio between 0.1 and 2 is adequate for identifying $M_{101}$ with $\phi = 0.1$. However, in Figure \ref{fig:fmri:id:M101PRR}, we see that for $\sigma^2_s / \sigma^2_m = 0.1$, increasing $\phi$ to 0.9 is enough to identify this model. In all cases, however, $\beta$ appears to be adequately identified.

\begin{figure}
\ssp
\centering
\caption{Identifying dynamic intercept model by increasing signal-to-noise ratio} \label{fig:fmri:id:M101SNR}
\includegraphics[width=0.75\textwidth]{1000-250-M101-conv-750-15-1-5-SNR-10-10}
\caption*{Histograms in 1D (for $\phi$, second column) and 2D (for $\beta$ and $(\sigma^2_s,\sigma^2_m)$, 1st and 3rd columns) of MLEs of fits of $M_{101}$ to data simulated from $M_{101}$ with $\beta = (750,15)'$, $\phi = 0.1$, $\sigma^2_m = 10$, and increasing $\sigma^2_s$ (rows). Blue X's denote true values of $\beta$ and $(\sigma^2_s,\sigma^2_s)$, and blue vertical lines denote the true value of $\phi$.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Identifying dynamic intercept model by increasing autocorrelation} \label{fig:fmri:id:M101PRR}
\includegraphics[width=1.0\textwidth]{1000-250-M101-conv-750-15-PRR-5-1-10-10}
\caption*{Histograms in 1D (for $\phi$, second column) and 2D (for $\beta$ and $(\sigma^2_s,\sigma^2_m)$, 1st and 3rd columns) of MLEs of fits of $M_{101}$ to data simulated from $M_{101}$ with $\beta = (750,15)'$, $\sigma^2_s = 1$, $\sigma^2_m = 10$, and increasing $\phi$ (rows). Blue X's denote true values of $\beta$ and $(\sigma^2_s,\sigma^2_s)$, and blue vertical lines denote the true values of $\phi$.}
\end{figure}

Lastly, identification of $M_{111}$ appears to be the most challenging. Figure \ref{fig:fmri:id:M111lowb} shows that by increasing the ratio of the white noise variance of the dynamic intercept to the white noise variance of the dynamic slope, $\sigma^2_s / \sigma^2_b$, to 15, $\sigma^2_m$ can be identified but $\phi$ and $\sigma^2_b$ are clearly not. On the other hand, if $\sigma^2_b$ is increased to 20 as in Figure \ref{fig:fmri:id:M111highb}, identification of $\phi$ and $\sigma^2_b$ is improved, but a larger ratio $\sigma^2_s / \sigma^2_b$ is needed to identify $\sigma^2_m$. In all cases, identification of $\beta$ appears to be slightly worse relative to $M_{011}$ and $M_{101}$.

\begin{figure}
\ssp
\centering
\caption{Identifying model with both dynamic slope and intercept with small slope variance} \label{fig:fmri:id:M111lowb}
\includegraphics[width=1.0\textwidth]{1000-250-M111-conv-750-15-9-6-SNR-1-10}
\caption*{Histograms in 1D (for $\sigma^2_m$, last column) and 2D (for $\beta$, $(\phi,\rho)$ and $(\sigma^2_s,\sigma^2_m)$, first 3 columns) of MLEs of fits of $M_{111}$ to data simulated from $M_{111}$ with $\beta = (750,15)'$, $\phi = 0.9$, $\rho = 0.6$, $\sigma^2_b = 1$, $\sigma^2_m = 10$, and increasing $\sigma^2_s$ (rows). Blue X's denote true values of $\beta$, $(\phi,\rho)$, and $(\sigma^2_s,\sigma^2_b)$, and blue vertical lines denote the true value of $\sigma^2_m$.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Identifying model with both dynamic slope and intercept with large slope variance} \label{fig:fmri:id:M111highb}
\includegraphics[width=1.0\textwidth]{1000-250-M111-conv-750-15-9-6-SNR-20-10}
\caption*{Histograms in 1D (for $\sigma^2_m$, last column) and 2D (for $\beta$, $(\phi,\rho)$ and $(\sigma^2_s,\sigma^2_m)$, first 3 columns) of MLEs of fits of $M_{111}$ to data simulated from $M_{111}$ with $\beta = (750,15)'$, $\phi = 0.9$, $\rho = 0.6$, $\sigma^2_b = 20$, $\sigma^2_m = 10$, and increasing $\sigma^2_s$ (rows). Blue X's denote true values of $\beta$, $(\phi,\rho)$, and $(\sigma^2_s,\sigma^2_b)$, and blue vertical lines denote the true value of $\sigma^2_m$.}
\end{figure}

Figures \ref{fig:fmri:id:M011SNR} through \ref{fig:fmri:id:M111highb} suggest that out of the three models, $M_{011}$ is the easiest to identify and $M_{111}$ is the most difficult. This is further supported by the decrease in the proportion of simulations for which the {\tt optim} function successively converges to the MLEs (see the convergence rates displayed under the plots for $\beta$). Models with identifiability issues are somtimes characterized by flat likelihoods that can make it difficult to find local maxima using iterative routines. We also note that identifiability for all three models improves by increasing the length of the simulated time series, $T$ (results not shown). To adequately identify $M_{111}$, however, $T$ would need to be increased well beyond the length of a typical fMRI experiment ($T \approx 5000$). For this reason, we discard $M_{111}$ at this point and examine only $M_{011}$ and $M_{101}$ in the remainder of this chapter.

\subsection{Fitting word recognition data \label{sec:fmri:mle}}

We now provide results from fitting the word recognition data set to $M_{101}$ and $M_{011}$ using maximum likelihood estimation. As in Section \ref{sec:fmri:id}, the {\tt dlmMLE} function was used to obtain MLEs for fixed parameters in $M_{101}$ and $M_{011}$. In addition, we offer a comparison with standard GLM fits of $M_{001}$ using OLS. Figure \ref{fig:fmri:mle:beta} displays two-dimensional histograms of $\hat{\beta}$ over the 125 voxels from each brain region according to each model. The histograms suggest that significant brain activation is present in all regions except for FP. Also, estimates are relatively consistent across models for all brain regions with the exception of FP, where histograms for $M_{011}$ include a cloud of more active voxels while the other two models don't.

Also apparent from this figure is the bimodal nature of brain activation in SV-left and SV-right. Voxels were divided into high and low clusters, denoted by ``Cluster H'' and ``Cluster L'', respectively, in these two regions for each model using the K-means clustering method \citep{hartigan:wong:kmeans:1979} applied to $\hat{\theta}$. Table \ref{tab:fmri:prop} shows that about 65\% of voxels from these two regions fall in a cluster of higher activation and higher baseline BOLD response, evidenced by the higher regional average values of $\hat{\beta_1}$ and $\hat{\beta_0}$ in Table \ref{tab:fmri:mle:clusters}. The clustering of voxels in these brain regions could provide support for the $M_{011}$ model, since an apparent change in the regression slope over such close space might suggest that a change in the regression slope over time is also reasonable.

Unlike MLEs for $\beta$, MLEs for $\phi$, $\sigma^2_s$, and $\sigma^2_m$ are not consistent between $M_{011}$ and $M_{101}$. Tables \ref{tab:fmri:mle:means} and \ref{tab:fmri:mle:clusters} show that in IPS-left, IPS-right, and PV, estimates for $\phi$ are, on average, higher under $M_{011}$ than they are under $M_{101}$.  In addition, the average signal-to-noise ratio, $\sigma^2_s / \sigma^2_m$, is estimated to be much higher in these three regions for $M_{101}$. In contrast, average estimates of $\phi$ in SV-left and SV-right are lower under $M_{011}$ than they are under $M_{101}$, and the opposite relationship is true for the average estimates of $\sigma^2_s / \sigma^2_m$. The opposing nature of autocorrelation and signal-to-noise estimates between $M_{101}$ and $M_{011}$ suggests that these models account for variation and autocorrelation in the data differently. What $M_{101}$ models as increased signal-to-noise, $M_{011}$ interprets as increased autocorrelation in the dynamic slope. Conversely, what $M_{011}$ models as increased signal-to-noise, $M_{101}$ interprets as increased autocorrelation in the errors.

%Two-dimensional histograms of $(\hat{\sigma}^2_s,\hat{\sigma}^2_m)$ in Figure \ref{fig:fmri:mle:sigma} also reveal patterns that differ between the two models. In IPS-left, IPS-right, PV, and SV-left, the estimated measurement variance, $\sigma^2_m$, under $M_{101}$ is close to 0 for most voxels. In contrast, voxels fit in these brain regions using $M_{011}$ yield estimates of $\sigma^2_m$ well above 0. In FP and SV-right, histograms for $M_{101}$ show larger values of $\hat{\sigma}^2_m$ and, interesting, the MLEs for $\sigma^2_m$ under $M_{011}$ seem to shrink toward 0.

\begin{figure}
\ssp
\centering
\caption{Histograms of MLEs of regression coefficients} \label{fig:fmri:mle:beta}
\includegraphics[width=0.6\textwidth]{craig_mle-beta}
\caption*{Two-dimensional histograms of MLEs of $\beta$ using real fMRI data from six brain regions (rows) fitted to dynamic regression models (columns). Blue X's denote the marginal averages of the MLEs from each brain region, and for each of two clusters in SV-left and SV-right.}
\end{figure}

%\begin{figure}
%\ssp
%\centering
%\caption{Histograms of MLEs for autocorrelation coefficient} \label{fig:fmri:mle:phi}
%\includegraphics[width=0.4\textwidth]{craig_mle-phi}
%\caption*{Histograms if MLEs of $\phi$ for real fMRI data from six brain regions (rows) fitted to dynamic regression models (columns). Blue vertical lines denote the average MLE of $\phi$ from each brain region, and for each of two clusters in SV-left and SV-right.}
%\end{figure}
%
%\begin{figure}
%\ssp
%\centering
%\caption{Histograms of MLEs for state and observation variances} \label{fig:fmri:mle:sigma}
%\includegraphics[width=0.6\textwidth]{craig_mle-sigma}
%\caption*{Two-dimensional histograms of MLEs of $(\sigma^2_s,\sigma^2_m)$ for real fMRI data from six brain regions (rows) fitted to dynamic regression models (columns). Blue X's denote the marginal averages of the MLEs from each brain region, and for each of two clusters in SV-left and SV-right.}
%\end{figure}

\begin{table}
\ssp
\centering
\caption{Average MLEs in single cluster brain regions} \label{tab:fmri:mle:means}
\begin{tabular}{|l|rrrr|}
\hline
Parameter & FP & IPS-left & IPS-right & PV \\
\hline
 & \multicolumn{4}{|c|}{$M_{011}$} \\
\hline
$\beta_0$ & 759.155 & 951.101 & 831.359 & 808.257 \\
$\beta_1$ & 1.395 & 15.009 & 24.894 & 16.492 \\
$\phi$ & 0.736 & 0.853 & 0.871 & 0.832 \\
$\sigma^2_s$ & 8.746 & 27.268 & 53.171 & 70.646 \\
$\sigma^2_m$ & 10.031 & 22.522 & 41.340 & 21.826 \\
\hline
 & \multicolumn{4}{|c|}{$M_{101}$} \\
\hline
$\beta_0$ & 759.875 & 950.038 & 830.901 & 807.434 \\
$\beta_1$ & -1.032 & 18.879 & 26.838 & 21.247 \\
$\phi$ & 0.746 & 0.637 & 0.654 & 0.596 \\
$\sigma^2_s$ & 3.323 & 16.970 & 29.565 & 23.498 \\
$\sigma^2_m$ & 6.105 & 0.534 & 1.382 & 1.727 \\
\hline
 & \multicolumn{4}{|c|}{$M_{001}$} \\
\hline
$\beta_0$ & 759.204 & 950.773 & 831.191 & 807.846 \\
$\beta_1$ & -1.448 & 16.087 & 24.688 & 19.039 \\
$\sigma^2_m$ & 12.480 & 29.579 & 54.511 & 37.629 \\
\hline
\end{tabular}
\caption*{Average MLEs calculated marginally for each fixed parameter (rows) for real fMRI data from four different brain regions (columns) fit to dynamic regression models (embedded tables).}
\end{table}

\begin{table}
\ssp
\centering
\caption{Average MLEs in bi-cluster brain regions} \label{tab:fmri:mle:clusters}
\begin{tabular}{|l|rr|rr|}
\hline
Parameter & \multicolumn{2}{|c|}{SV-left} & \multicolumn{2}{|c|}{SV-right} \\
\hline
 & Cluster H & Cluster L & Cluster H & Cluster L \\
\hline
 & \multicolumn{4}{|c|}{$M_{011}$} \\
\hline
$\beta_0$ & 874.999 & 363.601 & 697.816 & 308.080 \\
$\beta_1$ & 23.133 & 12.203 & 21.767 & 9.415 \\
$\phi$ & 0.566 & 0.520 & 0.489 & 0.630 \\
$\sigma^2_s$ & 11.475 & 4.378 & 13.162 & 4.889 \\
$\sigma^2_m$ & 0.502 & 0.393 & 2.423 & 3.906 \\
\hline
 & \multicolumn{4}{|c|}{$M_{101}$} \\
\hline
$\beta_0$ & 875.319 & 362.054 & 698.025 & 307.655 \\
$\beta_1$ & 20.009 & 11.708 & 13.883 & 9.361 \\
$\phi$ & 0.821 & 0.761 & 0.979 & 0.864 \\
$\sigma^2_s$ & 11.941 & 7.986 & 1.727 & 7.427 \\
$\sigma^2_m$ & 14.116 & 4.953 & 16.345 & 8.719 \\
\hline
 & \multicolumn{4}{|c|}{$M_{001}$} \\
\hline
$\beta_0$ & 875.084 & 361.957 & 697.769 & 307.538 \\
$\beta_1$ & 22.414 & 12.135 & 21.723 & 10.168 \\
$\sigma^2_m$ & 17.409 & 6.332 & 19.450 & 11.108 \\
\hline
\end{tabular}
\caption*{Average MLEs calculated marginally for each fixed parameter (rows) for real fMRI data from each cluster of secondary visual left and secondary visual right (columns) fit to dynamic regression models (embedded tables).}
\end{table}

\begin{table}
\ssp
\centering
\caption{Proportion of voxels with high activation} \label{tab:fmri:prop}
\begin{tabular}{|c|cc|}
\hline
Model & SV-left & SV-right \\
\hline
$M_{011}$ & 0.672 & 0.648 \\
$M_{101}$ & 0.677 & 0.648 \\
$M_{001}$ & 0.672 & 0.648 \\
\hline
\end{tabular}
\caption*{Proportion of voxels in each of secondary visual left and right (columns) classified into high activation cluster for each model fit (rows).}
\end{table}

\section{Comparing dynamic regression models using particle learning \label{sec:fmri:pl}}

In the previous section, we explored fits of $M_{011}$, $M_{101}$, and $M_{001}$ to the word recognition data using maximum likelihood estimation. In this section, we investigate the relative appropriateness of these models for the data using an SMC model comparison strategy. Results in Chapter \ref{ch:comp} showed that the performance of PL is superior to the RM and KDPF in terms of accurately estimating the marginal likelihood and posterior model probabilities within the context of the local level DLM with common state and observation variance factor. Since the dynamic regression models we consider for fMRI data admit tractable forms of the distributions needed to implement the PL, we use this algorithm to compare models in this section.

In Sections \ref{sec:pl} and \ref{sec:pl:dr}, we described a PL scheme to estimate the filtered distributions of states and unknown fixed parameters in $M_{011}$ (letting $F_t = \mbox{conv}_t$) and $M_{101}$ (letting $F_t = 1$). Using this algorithm, we also have a way of estimating the marginal likelihood of the data through equation \eqref{eqn:onestep:pf}. For $M_{001}$, an exact form of the marginal likelihood is available \citep{ohagan:bayes:1994}, given by
\begin{equation}
p(y_{1:T}) = \frac{1}{(2\pi)^{T/2}}\sqrt{\frac{|B_0^{-1}|}{|B_T^{-1}|}}\left(\frac{(b_{m_0})^{a_{m_0}}}{(b_{m_T})^{a_{m_T}}}\right)\left(\frac{\Gamma(a_{m_T})}{\Gamma(a_{m_0})}\right), \label{eqn:ols:marglik}
\end{equation}
where
\begin{align}
B_T &= (X'X + B_0^{-1})^{-1} &\quad \vartheta_T &= B_T(X'y + B_0^{-1}\vartheta_0) \label{eqn:bayesreg} \\
a_{m_T} &= a_{m_0} + T/2 &\quad b_{m_T} &= b_{m_0} + \frac{1}{2}(y'y + \vartheta_0'B_0^{-1}\vartheta_0 - \vartheta_T'B_T^{-1}\vartheta_T), \nonumber
\end{align}
and $\vartheta_0$, $B_0$, $a_{m_0}$, and $b_{m_0}$ are prior hyperparameters (see equation \ref{eqn:dynreg:prior1}). Given the exact marginal likelihood of the data under $M_{001}$ and approximations to the marginal likelihood under $M_{101}$ and $M_{011}$, relative posterior model probabilities among the three models can be computed according to equation \eqref{eqn:modelcomp}.

In order to implement PL on fMRI time series data from a single voxel, we need to specify the prior distribution, $p(x_0,\theta)$, and the number of particles to use in the particle filter. For all three models under consideration, we use a prior of the form given by equations \eqref{eqn:dynreg:prior1} and \eqref{eqn:dynreg:prior2}, i.e. $p(x_0, \theta) = p(\beta|\sigma^2_m)p(\sigma^2_m)p(\phi|\sigma^2_s)p(\sigma^2_s)\delta_0(x_0)$ with
\begin{align}
&\beta|\sigma^2_m \sim \mbox{N}(\vartheta_0, \sigma^2_mB_0) \qquad \sigma^2_m \sim \mbox{IG}(a_{m_0}, b_{m_0}) \label{eqn:fmri:pl:prior1} \\
&\phi|\sigma^2_s \sim \mbox{N}(\varphi_0, \sigma^2_s\Phi_0) \qquad \sigma^2_s \sim \mbox{IG}(a_{s_0}, b_{s_0}). \label{eqn:fmri:pl:prior2}
\end{align}
The hyperparameters $\vartheta_0$, $B_0$, $\varphi_0$, $\Phi_0$, $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ are known, and we let $B_0$ and $\Phi_0$ take the form
\begin{equation}
B_0 = \kappa^2 \left(\begin{array}{cc} 1000 & 0 \\ 0 & 225 \end{array}\right) \quad \Phi_0 = \kappa^2\times0.25. \label{eqn:fmri:kappa}
\end{equation}
We let $\kappa = 1$ in Sections \ref{sec:fmri:sim} and \ref{sec:fmri:real}, but let $\kappa > 0$ in Section \ref{sec:fmri:dist} to examine the sensitivity of marginal likelihood of the data to more diffuse priors.

%In Section \ref{sec:fmri:sim}, we use PL to estimate unknown states and fixed parameters in dynamic regression models using simulated data. In this case, we let the hyperparameters $b_0$ and $\varphi_0$ be equal to the true values of $\beta$ and $\phi$ used for simulation, respectively. The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ are set such that the means of the priors on $\sigma^2_s$ and $\sigma^2_m$ are equal to their respective true values used for simulation and the variances are both equal to $\kappa^2\times500$. We let $\kappa = 1$ in this section, but then compare the sensitivity of marginal likelihood estimates to more diffuse priors by increasing $\kappa$ in Section \ref{sec:fmri:dist}.
%
%In Section \ref{sec:fmri:dist}, we let $b_0$ and $\varphi_0$ be equal to the MLEs of $\beta$ and $\phi$, respectively, for the specific voxel that is being analyzed. Similarly, the inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ are set such that the means of the priors on $\sigma^2_s$ and $\sigma^2_m$ are equal to their respective MLEs for the specific voxel being analyzed and the variances are both equal to $\kappa^2\times500$. While this can be seen as using the data twice, we specify priors in this way in this section only in order to produce a fair model comparison among $M_{011}$, $M_{101}$, and $M_{001}$.
%
%In Section \ref{sec:fmri:real}, we analyze voxel-wise time series from the word recognition data set. When analyzing data from a specific voxel, we let $b_0$ and $\varphi_0$ be equal to the average MLE for $\beta$ and $\phi$, respectively, among voxels in the same brain region (as given in Table \ref{tab:fmri:mle:means}). For voxels in SV-left or SV-right, $b_0$ and $\varphi_0$ are set to the average values of $\hat{\beta}$ and $\hat{\phi}$ among voxels in the same cluster (as given in Table \ref{tab:fmri:mle:clusters}). The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ are set such that the mean of the priors on $\sigma^2_s$ and $\sigma^2_m$ are equal to their respective the average MLEs in Tables \ref{tab:fmri:mle:means} and \ref{tab:fmri:mle:clusters} and the variances are both equal to $\kappa^2\times500$.

\subsection{Analyzing simulated fMRI data using particle learning (PL) \label{sec:fmri:sim}}

In this section, we simulate data from $M_{011}$ and $M_{101}$, and we test the PL algorithm by running it under the data generating model for increasing number of particles. Based on the resulting particle samples, we obtain estimates of the filtered distributions of the dynamic regression coefficients and fixed parameters. Specifically, we compare sequential 95\% credible intervals for unknown states and fixed parameters obtained from PL with those from running the MCMC algorithm described in Section \ref{sec:mcmc:dr}.

Time series of length $T = 250$ were simulated from both models with true fixed parameter values set to $\beta = (750,15)'$, $\phi = 0.95$, $\sigma^2_s = 10$, and $\sigma^2_m = 10$. The same $\mbox{conv}_t$ generated from the simulated rapid event-design pictured in Figure \ref{fig:fmri:design} was used as the regression covariate. The simulated time series, $y_t$, and change in the regression slope, $x_t$, from $M_{011}$ are pictured in Figure \ref{fig:fmri:sim}. Notice from this figure that $y_t$ mirrors the convolution function better at TRs where $x_t$ is high.

For both PL and MCMC, the prior distribution on the initial state and fixed parameters were specified according to equations \eqref{eqn:fmri:pl:prior1} and \eqref{eqn:fmri:pl:prior2} with $\kappa = 1$. We let the hyperparameters $b_0$ and $\varphi_0$ be equal to the true values of $\beta$ and $\phi$ used for simulation, respectively. The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ were set such that the prior means for each of $\sigma^2_s$ and $\sigma^2_m$ were equal to their respective true values used for simulation, and such that each prior variance was equal to $\kappa^2\times500$.

\begin{figure}
\ssp
\centering
\caption{Simulated fMRI data from dynamic slope model} \label{fig:fmri:sim}
\includegraphics[width=1.0\textwidth]{fmri-ar-sim-750-15-95-10-10-M101}
\caption*{Simulated fMRI time series $y_t$ (top) from $M_{011}$ with $\beta = (750,15)'$, $\phi = 0.95$, $\sigma^2_s = 10$, and $\sigma^2_m = 10$. Convolution of the hrf and neural activation pattern $\mbox{conv}_t$ and simulated change in dynamic slope $x_t$ are displayed in the middle and bottom panels, respectively.}
\end{figure}

We ran the PL algorithm under the true model on the time series simulated from both models using 500, 1000, 5000, 10000, and 20000 particles. In addition, we ran three MCMC chains for each simulation under the true model using the same priors. For each chain, initial values of $\beta_0$, $\beta_1$, $\phi$ were set to 0 and initial values for $\sigma^2_s$ and $\sigma^2_m$ were set to 1. Initial values of the states, $x_t$ for $t = 0,1,\ldots,T$, were drawn from a standard normal distribution. Twenty-five thousand iterations were run for each chain with a burn-in period of 5000 iterations, and every 20th iteration was saved.

The results for $M_{011}$ shown in Figure \ref{fig:fmri:quant:M011} indicate that the filtered distributions of the fixed parameters and dynamic slope estimated by PL have converged near the true posterior if at least 10000 particles are used. In addition, the filtered distributions at time $T = 250$ appear to agree with the MCMC estimate for the dynamic slope and all fixed parameters. The same plots for the data simulated from $M_{101}$ (Figure \ref{fig:fmri:quant:M101}) show similar results.

\begin{figure}
\ssp
\centering
\caption{Credible intervals from PL compared with MCMC for simulated fMRI data} \label{fig:fmri:quant:M011}
\includegraphics[width=1.0\textwidth]{fmri_pl_quant-M101-M101-560-1-1-FALSE-FALSE-FALSE}
\caption*{Sequential 95\% credible intervals for the dynamic slope (top left) and fixed parameters (other panels) in $M_{011}$ using PL with increasing number of particles (colors) compared with MCMC (black X's) run on simulated data from $M_{011}$ with $\beta = (750,15)'$, $\phi = 0.95$, $\sigma^2_s = 10$, and $\sigma^2_m = 10$ (displayed above top middle panel). True values of fixed parameters used for simulation and true simulated dynamic slopes are represented by gray lines. Interval estimates from MCMC are displayed only for $\beta_1 + x_T$ and for each of the fixed parameters conditional on all the data ($T = 250$). The same prior distributions on the initial state and fixed parameters were used for running both PL and MCMC, with $p(x_0) = \delta_{0}(x_0)$, $b_0$ and $\phi_0$ set to the true $\beta$ and $\phi$, respectively, and remaining hyperparameters displayed above the top left and right panels.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Credible intervals from PL compared with MCMC for simulated fMRI data} \label{fig:fmri:quant:M101}
\includegraphics[width=1.0\textwidth]{fmri_pl_quant-M011-M011-560-1-1-FALSE-FALSE-FALSE}
\caption*{Sequential 95\% credible intervals for the dynamic intercept (top left) and fixed parameters (other panels) in $M_{101}$ using PL with increasing number of particles (colors) compared with MCMC (black X's) run on simulated data from $M_{101}$ with $\beta = (750,15)'$, $\phi = 0.95$, $\sigma^2_s = 10$, and $\sigma^2_m = 10$ (displayed above top middle panel). True values of fixed parameters used for simulation and true simulated dynamic slopes are represented by gray lines. Interval estimates from MCMC are displayed only for $\beta_0 + x_T$ and for each of the fixed parameters conditional on all the data ($T = 250$). The same prior distributions on the initial state and fixed parameters were used for running both PL and MCMC, with $p(x_0) = \delta_{0}(x_0)$, $b_0$ and $\phi_0$ set to the true $\beta$ and $\phi$, respectively, and remaining hyperparameters displayed above the top left and right panels.}
\end{figure}

\subsection{Distinguishing dynamic regression models using PL \label{sec:fmri:dist}}

The results from the previous section indicate that stable estimates of dynamic regression coefficients and fixed parameters can be obtained by PL if enough particles are used. We now examine estimation of the marginal likelihood using PL. In particular, we are interested in understanding parameter settings under which $M_{011}$, $M_{101}$, and $M_{001}$ can be distinguished from one another by looking at the marginal likelihood.

To study this, we simulated time series of length $T = 250$ from both $M_{011}$ and $M_{101}$ with the same convolution function used in the previous section, $\beta = (750,15)'$, and various values of $\phi$, $\sigma^2_s$, and $\sigma^2_m$. Specifically, we simulated time series for all combinations of $\phi \in \{0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95,0.99\}$, $\sigma^2_s \in \{1,2,3,4,5,10,15,20\}$, and $\sigma^2_m = 10$. We then ran the PL algorithm, under both $M_{011}$ and $M_{101}$, three times on each simulated time series using 500 particles and specify the prior hyperparameters $B_0$ and $\Phi_0$ by letting $\kappa = 1$ in equation \eqref{eqn:fmri:kappa}. For each simulation, we calculated the MLEs of the unknown fixed parameters prior to running the PL, and we let the hyperparameters $b_0$ and $\varphi_0$ be equal to the MLEs of $\beta$ and $\phi$, respectively. The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ were set such that the prior means for each of $\sigma^2_s$ and $\sigma^2_m$ were equal to their respective MLEs, and such that each prior variance was equal to $\kappa^2\times500$.

Some PL runs did not complete due to values of the conditional likelihood, $p(y_t|x_t,\theta)$, being too low for some particles. For each PL run that successfully completed, we computed estimates of the log marginal likelihood. In addition, we computed the exact log marginal likelihood under $M_{001}$ for each simulated time series using equation \eqref{eqn:ols:marglik}.

Figures \ref{fig:fmri:phi:M011} and \ref{fig:fmri:phi:M101} show the results for the data simulated from $M_{011}$ and $M_{101}$, respectively. Both figures indicate that the log marginal likelihood under the true data-generating model is larger than the log marginal likelihood under the other models provided the true $\phi$ and signal-to-noise ratio, $\sigma^2_s/\sigma^2_m$, are large enough. However, it appears more difficult to identify $M_{101}$ as the true model than it does for $M_{011}$. For example, when the true signal-to-noise ratio under $M_{011}$ is 1.5, 2, or 2.5 (bottom row of Figure \ref{fig:fmri:phi:M011}), the log marginal likelihood obtained from each PL run under $M_{011}$ is larger than those obtained from all PL runs under the other models for any $\phi \ge 0.1$. In contrast, when the true signal-to-noise ratio under $M_{101}$ is 1.5, 2, or 2.5 (bottom row of Figure \ref{fig:fmri:phi:M101}), $\phi \ge 0.6$ is required for all log marginal likelihoods obtained from PL runs under $M_{101}$ to be larger than those obtained for all PL runs under the other models.

\begin{figure}
\ssp
\centering
\caption{Distinguishing the dynamic slope model from the dynamic intercept and simple linear regression models} \label{fig:fmri:phi:M011}
\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-M101-1-500-phi-496-594-1}
\caption*{Log marginal likelihoods of data simulated from $M_{011}$ with $\beta=(750,15)$, $\sigma^2_m = 10$, increasing $\phi$ (x-axis) and increasing $\sigma^2_s$ (plot panels) under $M_{011}$ (black lines), $M_{101}$ (red lines), and $M_{001}$ (blue lines). Log marginal likelihoods from three independent PL runs with 500 particles under each model for each simulation are displayed by colored points. When running the PL, prior hyperparameters $B_0$ and $\Phi_0$ were specified by equation \eqref{eqn:fmri:kappa} with $\kappa = 1$, and $b_0$ and $\varphi_0$ were set to the MLEs of $\beta$ and $\phi$, respectively. The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ were set such that the prior means for each of $\sigma^2_s$ and $\sigma^2_m$ were equal to their respective MLEs, and such that each prior variance was equal to $500$.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Distinguishing the dynamic intercept model from the dynamic slope and simple linear regression models} \label{fig:fmri:phi:M101}
\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-M011-1-500-phi-496-594-1}
\caption*{Log marginal likelihoods of data simulated from $M_{101}$ with $\beta=(750,15)$, $\sigma^2_m = 10$, increasing $\phi$ (x-axis) and increasing $\sigma^2_s$ (plot panels) under $M_{011}$ (black lines), $M_{101}$ (red lines), and $M_{001}$ (blue lines). Log marginal likelihoods from three independent PL runs with 500 particles under each model for each simulation are displayed by colored points. When running the PL, prior hyperparameters $B_0$ and $\Phi_0$ were specified by equation \eqref{eqn:fmri:kappa} with $\kappa = 1$, and $b_0$ and $\varphi_0$ were set to the MLEs of $\beta$ and $\phi$, respectively. The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ were set such that the prior means for each of $\sigma^2_s$ and $\sigma^2_m$ were equal to their respective MLEs, and such that each prior variance was equal to $500$.}
\end{figure}

\subsection{Sensitivity of the marginal likelihood to priors \label{sec:fmri:kappa}}

It is important to also understand that comparing models in terms of the log marginal likelihood, as in Figures \ref{fig:fmri:phi:M011} and \ref{fig:fmri:phi:M101}, is highly sensitive to the specified prior distribution on the initial state and fixed parameters. This is because the marginal likelihood is computed by integrating out the states and fixed parameters from the joint likelihood, i.e.
\begin{equation}
p(y_{1:T}) = \int_{\theta} \int_{x_0} \int_{x_1} \cdots \int_{x_T} \prod_{t=1}^T\left(p(y_t|x_t,\theta)p(x_t|x_{t-1},\theta)\right)p(x_0,\theta)\mbox{d}x_{0:T}\mbox{d}\theta \label{eqn:int:marg}
\end{equation}
Thus, if $p(x_0,\theta)$ is diffuse, $p(y_{1:T})$ will be much smaller than it would be for $p(x_0,\theta)$ that is more concentrated around the joint posterior, $p(x_{0:T},\theta|y_{1:T})$.

To examine the sensitivity of comparing $M_{011}$, $M_{101}$, and $M_{001}$ to specified priors of the form given by equations \eqref{eqn:fmri:pl:prior1} and \eqref{eqn:fmri:pl:prior2}, we simulated two more time series under both $M_{011}$ and $M_{101}$ for each set of fixed parameter values. Then, we ran the PL algorithm three times under the true data-generating model using $\kappa = 5$ and 500 particles for each of the now three total simulations generated using each set of true fixed parameter values (remaining prior hyperparameters were set based on the MLEs as in Section \ref{sec:fmri:dist}). This process was then repeated for $\kappa = 10$ and $\kappa = 15$. The goal here is that we want to examine the effect of increasing $\kappa$ on the values of $\phi$ and $\sigma^2_s / \sigma^2_m$ required for the log marginal likelihoods obtained from all three PL runs under the true data-generating model to be higher than the log marginal likelihoods obtained from all PL runs under the other models with $\kappa = 1$. For example, for running the PL under $M_{011}$ with $\kappa = 1$ on data simulated from the same model with true $\sigma^2_s / \sigma^2_m = 1$, a true value of $\phi \ge 0.7$ is required for the log marginal likelihoods obtained from all three PL runs to be higher than those obtained from all PL runs under the other models (see plot in the second row and third column of Figure \ref{fig:fmri:phi:M011}).

Theoretically, we should be able to increase $\kappa$ to the point that the true model is less likely than the other models regardless of the true values of $\phi$ and $\sigma^2_s / \sigma^2_m$. Figures \ref{fig:fmri:kappa:M011} and \ref{fig:fmri:kappa:M101} illustrate this point. In Figure \ref{fig:fmri:kappa:M011}, we see that as $\kappa$ is increased, the true values of $\phi$ and $\sigma^2_s / \sigma^2_m$ required identify $M_{011}$ as the true model get larger. This phenomenon is even more pronounced when considering $M_{101}$ as the true model, as in Figure \ref{fig:fmri:kappa:M101}. For example, when $\kappa = 15$, the true autocorrelation in the data must be at least 0.8 to identify $M_{101}$ as the true model, regardless of how large the signal-to-noise ratio is.

Setting $\kappa = 1$ assumes a prior standard deviation of 100 for the regression intercept and 15 for the regression slope. From Figure \ref{fig:fmri:mle:beta}, we see that values of $\hat{\beta}_0$ and $\hat{\beta}_1$ for most voxels are within 2 prior standard deviations of the average MLE of their respective regions or clusters. Similarly, most MLEs for $\phi$, $\sigma^2_s$, and $\sigma^2_m$ (not shown) fall within two standard deviations of the region or cluster average for $\kappa = 1$. For this reason, we think a prior of the form given by equations \eqref{eqn:fmri:pl:prior1} and \eqref{eqn:fmri:pl:prior2} with $\kappa = 1$ is reasonable for this data. Furthermore, most of the MLEs for $\phi$ and $\sigma^2_s / \sigma^2_m$ calculated in Tables \ref{tab:fmri:mle:means} and \ref{tab:fmri:mle:clusters} are above the values required to identify $M_{011}$ or $M_{101}$ as the true model, as indicated by the top left plots of Figures \ref{fig:fmri:kappa:M011} and \ref{fig:fmri:kappa:M101}. From this perspective, it also encouraging that a decrease in the average MLEs of $\sigma^2_s / \sigma^2_m$ shown in Tables \ref{tab:fmri:mle:means} and \ref{tab:fmri:mle:clusters} is often accompanied by an increase in the the MLE of $\phi$ in the corresponding brain region.

\begin{figure}
\ssp
\centering
\caption{Distinguishing the dynamic slope model from the dynamic intercept and simple linear regression models with increasing prior variance} \label{fig:fmri:kappa:M011}
\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-phiSNR-M101-3-500-496-594-1-5-10-15}
\caption*{Minimum values of $\phi \in \{0.1,0.2,\ldots,0.9,0.95,0.99\}$ (y-axis) for which $M_{011}$ is distinguished from $M_{101}$ and $M_{001}$ as being the true model for data simulated from $M_{011}$ with $\beta = (750,15)'$ and $\sigma^2_m = 10$, and fixed $\sigma^2_s \in \{0.1,0.2,\ldots,0.5,1.0,1.5,2.0,2.5\}$ (x-axis). $M_{011}$ is determined to be distinguished from $M_{101}$ and $M_{001}$ if log marginal likelihood estimates under $M_{011}$ obtained from three independent PL runs with 500 particles on the same data are each greater than all three estimates from PL runs on the same data under each of $M_{101}$ and $M_{001}$. Points are displayed for three separate sets of simulations (colors) from $M_{011}$ for all combinations of the fixed parameter values mentioned and increasing prior standard deviation factor $\kappa$ (plot panels) to determine the hyperparameters $B_0$ and $\Phi_0$ used in the PL runs (see equation \eqref{eqn:fmri:kappa}). Remaining prior hyperparameters were set based on the MLEs as described in Section \ref{sec:fmri:dist}. If there exists no value of $\phi$ for which $M_{011}$ is distinguished from $M_{101}$ and $M_{001}$ for fixed $\sigma^2_s$ within a given set of simulations, no point is plotted for that value of $\sigma^2_s$.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Distinguishing the dynamic intercept model from the dynamic slope and simple linear regression models with increasing prior variance} \label{fig:fmri:kappa:M101}
\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-phiSNR-M011-3-500-496-594-1-5-10-15}
\caption*{Minimum values of $\phi \in \{0.1,0.2,\ldots,0.9,0.95,0.99\}$ (y-axis) for which $M_{101}$ is distinguished from $M_{011}$ and $M_{001}$ as being the true model for data simulated from $M_{101}$ with $\beta = (750,15)'$ and $\sigma^2_m = 10$, and fixed $\sigma^2_s \in \{0.1,0.2,\ldots,0.5,1.0,1.5,2.0,2.5\}$ (x-axis). $M_{101}$ is determined to be distinguished from $M_{011}$ and $M_{001}$ if log marginal likelihood estimates under $M_{101}$ obtained from three independent PL runs with 500 particles on the same data are each greater than all three estimates from PL runs on the same data under each of $M_{011}$ and $M_{001}$. Points are displayed for three separate sets of simulations (colors) from $M_{101}$ for all combinations of the fixed parameter values mentioned and increasing prior standard deviation factor $\kappa$ (plot panels) to determine the hyperparameters $B_0$ and $\Phi_0$ used in the PL runs (see equation \eqref{eqn:fmri:kappa}). Remaining prior hyperparameters were set based on the MLEs as described in Section \ref{sec:fmri:dist}. If there exists no value of $\phi$ for which $M_{101}$ is distinguished from $M_{011}$ and $M_{001}$ for fixed $\sigma^2_s$ within a given set of simulations, no point is plotted for that value of $\sigma^2_s$.}
\end{figure}

Our last analysis using simulated data is aimed at determining how many particles are needed when running the PL algorithm to accurately estimate relative posterior model probabilities among $M_{011}$, $M_{101}$, and $M_{001}$. This should depend on how different the marginal likelihoods are among the three models. For instance, if the marginal likelihood of the data under one of the models is large relative to the marginal likelihoods under the others, the posterior probability is likely to be 1 for that model and 0 for the others, regardless of how variable the estimate of the marginal likelihood is. For this reason, we consider a ``worst'' case scenario, i.e. time series simulated from each of $M_{011}$ and $M_{101}$ with true fixed parameter values set such that it is difficult to distinguish the true model from among $M_{011}$, $M_{101}$, and $M_{001}$. Using Figures \ref{fig:fmri:phi:M011} and \ref{fig:fmri:phi:M101} as a guide, we simulate time series from each of $M_{011}$ and $M_{101}$ using the following true fixed parameter values:
\begin{align}
M_{011}: \beta = (750,15)' \quad \phi = 0.3 \quad \sigma^2_s = 1 \quad \sigma^2_m = 10 \label{eqn:fmri:sim:M011} \\
M_{101}: \beta = (750,15)' \quad \phi = 0.5 \quad \sigma^2_s = 1 \quad \sigma^2_m = 10 \label{eqn:fmri:sim:M101}
\end{align}

The PL algorithm was run twenty times under both $M_{011}$ and $M_{101}$ on each simulated time series using 500, 1000, 5000, and 10000 particles. Again, we specify prior hyperparameters based on the MLEs as in Sections \ref{sec:fmri:dist} and \ref{Sec:fmri:kappa} with $\kappa = 1$. By grouping together a single log marginal likelihood approximation under $M_{101}$, a single log marginal likelihood approximation under $M_{011}$, and an exact marginal likelihood under $M_{001}$ calculated according to equation \eqref{eqn:ols:marglik}, a set of posterior probabilities among the three models can be calculated according to equation \eqref{eqn:modelcomp}. Twenty such sets of posterior model probabilities were calculated using the log marginal likelihood approximations obtained from the PL runs, and the results are displayed in Figure \ref{fig:fmri:comp:M011} using compositional plots. From these figures, we can see that 5000 particles are needed when implementing the PL in order for estimates of the posterior model probabilities to stabilize.

%\begin{figure}
%\ssp
%\centering
%\caption{Log marginal likelihoods of data simulated from dynamic slope model with increasing particles in PL} \label{fig:fmri:loglik:M011}
%\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-M101-498-1}
%\caption*{Kernel density approximation to the distribution of 20 log marginal likelihood estimates for $M_{011}$ (black lines) and $M_{101}$ (red lines) along with true log marginal likelihood of $M_{001}$ (blue vertical lines) using PL with increasing number of particles (plot panels) on simulated data from $M_{011}$ with $\beta = (750,15)'$, $\phi = 0.3$, $\sigma^2_s = 1$, and $\sigma^2_m = 10$.}
%\end{figure}
%
%, and another simulated time series from $M_{101}$ with $\beta = (750,15)'$, $\phi = 0.5$, $\sigma^2_s = 1$, and $\sigma^2_m = 10$.
%
%\begin{figure}
%\ssp
%\centering
%\caption{Log marginal likelihoods of data simulated from dynamic intercept model with increasing particles in PL} \label{fig:fmri:loglik:M101}
%\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-M011-500-1}
%\caption*{Kernel density approximation to the distribution of 20 log marginal likelihood estimates for $M_{011}$ (black lines) and $M_{101}$ (red lines) along with true log marginal likelihood of $M_{001}$ (blue vertical lines) using PL with increasing number of particles (plot panels) on simulated data from $M_{101}$ with $\beta = (750,15)'$, $\phi = 0.5$, $\sigma^2_s = 1$, and $\sigma^2_m = 10$.}
%\end{figure}

\begin{figure}
\ssp
\centering
\caption{Ternary diagrams of posterior model probabilities for simulated fMRI data from dynamic slope model} \label{fig:fmri:comp:M011}
\includegraphics[width=1.0\textwidth]{fmri_pl_comp-M101-498-1}
\caption*{Posterior model probabilities among $M_{011}$, $M_{101}$, and $M_{001}$ (corners of triangles) estimated for each of twenty runs of the PL under each model for increasing number of particles (plot panels) on data simulated from $M_{011}$ with $\beta = (750,15)'$, $\phi = 0.3$, $\sigma^2_s = 1$, and $\sigma^2_m = 10$. Each point represents a set of posterior probabilities (one for each model), and the proximity of the point to a particular corner of the triangle represents the posterior probability of the model in that corner relative to the other models. The prior distribution $p(x_0,\theta)$ used in the PL runs is given by equations \eqref{eqn:fmri:pl:prior1}, \eqref{eqn:fmri:pl:prior1}, and \eqref{eqn:fmri:kappa} with $\kappa = 1$ and $b_0$, $\varphi_0$, $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ set based on the MLEs as described in Section \ref{sec:fmri:dist}.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Ternary diagrams of posterior model probabilities for simulated fMRI data from dynamic intercept model} \label{fig:fmri:comp:M101}
\includegraphics[width=1.0\textwidth]{fmri_pl_comp-M011-500-1}
\caption*{Posterior model probabilities among $M_{011}$, $M_{101}$, and $M_{001}$ (corners of triangles) estimated for each of twenty runs of the PL under each of the models for increasing number of particles (plot panels) on data simulated from $M_{101}$ with $\beta = (750,15)'$, $\phi = 0.5$, $\sigma^2_s = 1$, and $\sigma^2_m = 10$. Each point represents a set of posterior probabilities (one for each model), and the proximity of the point to a particular corner of the triangle represents the posterior probability of the model in that corner relative to the other models. The prior distribution $p(x_0,\theta)$ used in the PL runs is given by equations \eqref{eqn:fmri:pl:prior1}, \eqref{eqn:fmri:pl:prior1}, and \eqref{eqn:fmri:kappa} with $\kappa = 1$ and $b_0$, $\varphi_0$, $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ set based on the MLEs as described in Section \ref{sec:fmri:dist}.}
\end{figure}

\subsection{Comparing models for word recognition data using PL \label{sec:fmri:real}}

In this section, we examine results from running the PL on fMRI data generated from the word recognition experiment. We ran the PL algorithm using 5000 particles under both $M_{011}$ and $M_{101}$ on time series from every voxel in our study (750 total). The prior distribution $p(x_0,\theta)$ was again specified by equations \eqref{eqn:fmri:pl:prior1}, \eqref{eqn:fmri:pl:prior1}, and \eqref{eqn:fmri:kappa} with $\kappa = 1$. Prior means $b_0$ and $\varphi_0$ were set to the average MLEs of $\beta$ and $\phi$, respectively, among voxels in the brain region (or cluster for SV-left and SV-right) from which the voxel being analyzed came from. The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ were set such that the prior means for each of $\sigma^2_s$ and $\sigma^2_m$ were equal to their respective regional or cluster average MLEs, and such that each prior variance was equal to $500$.

For each voxel-specific time series, we estimated the marginal likelihood of the data under both $M_{011}$ and $M_{101}$. We also computed the exact marginal likelihood under $M_{001}$ for time series from each voxel. We then used the estimated and exact marginal likelihoods to compute relative posterior probabilities among the three models for each voxel. The model with the highest posterior probability for a given voxel was determined to be the ``preferred'' model for that voxel. The proportion of voxels that prefer each of the model across the six different brain regions are displayed in Table \ref{tab:fmri:favor}.

From Table \ref{tab:fmri:favor}, we see that a vast majority of the voxels prefer $M_{101}$. The compositional plots in Figure \ref{fig:fmri:comp:real} affirm this as well, with a majority of points from each brain region concentrated near the corner of the ternary diagram represented by $M_{101}$. Models that account for temporal autocorrelation in fMRI time series using only an autocorrelated error term, as in $M_{101}$, have been standard in fMRI studies, and these results provide further support for that standard.

However, there are a few brain regions, most notably SV-left and IPS-right, for which a non-trivial percentage of voxels prefer $M_{011}$ or $M_{001}$. To examine this further, we have plotted 95\% credible intervals for the filtered distributions of the dynamic slope at each time $t$ based on samples generated from PL runs under $M_{011}$. Figure \ref{fig:fmri:slopes:real} displays these intervals for a 5 by 5 slice of voxels in SV-left. In addition, we have color coded the lines representing the sequential credible intervals according to whether the corresponding voxel falls in the low or high activation cluster, and we've displayed colored bars along the top of the plots that provide a visualization of the relative posterior model probabilities for a specific voxel.

We notice from this slice of voxels that there is a spatial nature to the location of the low and high activation clusters. In addition, we see a spatial pattern associated with which model the voxels prefer. The cluster of voxels that prefer the dynamic slope model seem to lie along the gradient between the low and high activation clusters, suggesting the possibility that the temporal shift in activation over the course of the experiment is related to the spatial shift. This increase in neural activity could perhaps be in response to a shift in focus or adaptation in the processing of words on the part of the subject in the scanner, with the response being prominent in some voxels more than others.

%\begin{figure}
%\ssp
%\centering
%\caption{Log marginal likelihoods of real fMRI data} \label{fig:fmri:loglik:real}
%\includegraphics[width=1.0\textwidth]{craig_pl-loglik-1-5000-1-FALSE-FALSE-FALSE}
%\caption*{Kernel density approximation to the distribution of log marginal likelihood estimates of data from 125 voxels from each of 6 different brain regions (plot panels) for $M_{011}$ (black lines) and $M_{101}$ (red lines) along with true log marginal likelihood of $M_{001}$ (blue vertical lines) using PL with 5000 particles.}
%\end{figure}

\begin{table}
\ssp
\centering
\caption{Proportion of voxels favoring different regression models} \label{tab:fmri:favor}
\begin{tabular}{|c|ccc|}
\hline
Region & $M_{101}$ & $M_{011}$ & $M_{001}$ \\
\hline
FP & 0.976 & 0.000 & 0.024 \\
IPS-left & 0.992 & 0.008 & 0.000 \\
IPS-right & 0.880 & 0.096 & 0.024 \\
PV & 1.000 & 0.000 & 0.000 \\
SV-left & 0.800 & 0.144 & 0.056 \\
SV-right & 0.952 & 0.032 & 0.016 \\
\hline
\end{tabular}
\caption*{Proportion of voxels in each brain region (rows) with highest posterior model probability coming from each of $M_{101}$, $M_{011}$, and $M_{001}$ (columns). For $M_{101}$ and $M_{011}$, posterior model probabilities were calculated using the PL with 5000 particles. For $M_{001}$, the true posterior probability was calculated analytically according to equation \eqref{eqn:ols:marglik}. The prior distribution $p(x_0,\theta)$ assumed for each of three models is specified as described at the beginning of Section \ref{sec:fmri:real}.}
\end{table}

\begin{figure}
\ssp
\centering
\caption{Posterior probabilities of dynamic regression models for real fMRI data} \label{fig:fmri:comp:real}
\includegraphics[width=1.0\textwidth]{craig_pl-comp-1-5000-1-FALSE-FALSE-FALSE}
\caption*{Posterior model probabilities among dynamic regression models (corners of triangles) calculated according to equation \eqref{eqn:modelcomp} and represented via compositional plots for 125 voxels (black dots) in each of 6 brain regions (plot panels). Marginal likelihoods needed for calculating posterior model probabilities were calculated analytically using equation \eqref{eqn:ols:marglik} for $M_{001}$, and using the PL with 5000 particles for $M_{011}$ and $M_{101}$. The prior distribution $p(x_0,\theta)$ assumed for each model is specified as described at the beginning of Section \ref{sec:fmri:real}. Each point represents a set of posterior probabilities (one for each model), and the proximity of the point to a particular corner of the triangle represents the posterior probability of the model in that corner relative to the other models.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Filtered dynamic slopes and posterior model probabilities for data from SV-left} \label{fig:fmri:slopes:real}
\includegraphics[width=1.0\textwidth]{craig_state-pl-SV-left-M101-3-FALSE-5000}
\caption*{Sequential 95\% credible intervals for dynamic slopes (lines) and 95\% credible intervals for $\phi|y_{1:T}$ and $\frac{\sigma^2_s}{\sigma^2_m}|y_{1:T}$ (displayed above plot panels) obtained from running PL under $M_{011}$ with 5000 particles on each voxel from a 5 by 5 slice in the y-z plane of secondary visual left. Line colors correspond to whether a voxel was classified into the low or high activation cluster according to MLEs obtained in Section \ref{sec:fmri:mle}. The proportion of the solid bar along the top of a given plot colored for a specific model represents the posterior probability of that model, relative to the other models, given data from the corresponding voxel for that plot (as represented in Figure \ref{fig:fmri:comp:real}). The prior distribution $p(x_0,\theta)$ assumed for each model is specified as described at the beginning of Section \ref{sec:fmri:real}.}
\end{figure}

An alternate explanation for the results shown in Figure \ref{fig:fmri:slopes:real} could be that the increase in the dynamic slope over time is not due to increased neural activity, but rather to other sources of noise in the data such as a mis-specification of the hrf or physiological processes like heartbeat and respiration. These sources of autocorrelation in the data may be more suitably modeled by $M_{101}$, evidenced by the fact that most of the voxels in the high activation cluster prefer $M_{101}$. The voxels that prefer $M_{011}$ or $M_{101}$ could lie in areas where the hrf is more accurate or where signals due to physiological processes are not as pronounced. The fact that a few of these voxels prefer $M_{001}$ over $M_{011}$ supports this hypothesis.

Model identification results from Section \ref{sec:fmri:dist} suggest that our model comparison analysis using the PL should be used with caution. Specifically, $\phi$ and $\sigma^2_s / \sigma^2_m$ need to be sufficiently large in order for the true model to be distinguished from the others using an estimate of the marginal likelihood. In addition, the marginal likelihood can be highly sensitive to specific prior distributions on the unknown states and fixed parameters. Thus, a diffuse prior can lower the marginal likelihood of the data under the true model relative to other models. The maximum likelihood estimates of $\phi$, $\sigma^2_s$, and $\sigma^2_m$ given for SV-left in Table \ref{tab:fmri:mle:clusters} appear to be high enough to believe that the results shown in Figure \ref{fig:fmri:slopes:real} are not a fluke to misidentification. However, the interval estimates obtained from running the PL, displayed above the plots in Figure \ref{fig:fmri:slopes:real}, indicate a large degree of uncertainty in these parameters.

\section{Discussion \label{sec:fmri:discussion}}

In this chapter, we present an analysis of fMRI data collected from an episodic word recognition task, focusing specifically on voxels from six different brain regions. Using maximum likelihood estimation, we fit regression models with ARMA errors to data from randomly selected voxels in each brain region, and we found that AIC and AICC prefer models with an ARMA(3,3) error structure while BIC tends to prefer AR(1) or ARMA(1,1) errors. We showed via simulation that testing for significant brain activation in fMRI time series using a standard OLS regression technique leads to an inflation of the false positive rate of concluding significant brain activation. In addition, we showed that in the presence of highly autocorrelated time series, a method for adjusting the degrees of freedom in the t-test for significant brain activation can lower the false positive rate while decreasing the power of the test. We also illustrated using a simulated example that comparing autocorrelation estimation algorithms by examining the independence of model residuals can give misleading results.

We proposed models for accounting for autocorrelation in fMRI data that contain a dynamic intercept, dynamic slope, or both. Using data simulated from each model, we explored parameter settings under which the models are identifiable. We concluded that the dynamic slope model is easiest to identify while identification of the model with both a dynamic slope and dynamic intercept is more difficult. We fit the dynamic slope, dynamic intercept, and ordinary regression models to real fMRI data using maximum likelihood estimation and identified clusters of high and low activation in the secondary visual cortex.

Lastly, we introduced a model comparison strategy based on estimating the marginal likelihood of data under different models using PL. We showed using simulated data that sufficiently high lag-1 autocorrelation and signal-to-noise needs to be present in the data in order to correctly select the dynamic slope or dynamic intercept model. Using real fMRI data, we estimated relative posterior probabilities among the dynamic slope, dynamic intercept, and ordinary regression models and found that a vast majority of voxels prefer the dynamic intercept model, while the region with the highest percentage of voxels that prefer the dynamic slope model was the left secondary visual cortex ($\approx$ 15\%).

It is conceivable that the most appropriate model for this data might be one with both a dynamic intercept and a dynamic slope. For instance, it could be the case that, for most voxels, the variation in the data due to the dynamic intercept part of the model swamps the dynamic slope component. The small clusters of voxels that prefer the dynamic slope model could be one of the few areas where the dynamic slope component accounts for more of the variation in the data. However, typical fMRI experiments do not generate time series long enough to correctly identify parameters of this model. Re-parametrization of the model could possibility alleviate identification issues, and spatio-temporal modeling approaches that borrow information from neighboring voxels could open up the possibility of correctly analyzing models with multiple autoregressive components.

The results from this section provide evidence in support of the use of a model for statistical analysis of fMRI data that incorporates a dynamic slope component, albeit in conjunction with other components to account for remaining sources of autocorrelation in the data. The use of the PL algorithm provides insight into the relative appropriateness of these models for describing the behavior of neural activation in specific brain regions of interest. 