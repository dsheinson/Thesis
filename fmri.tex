\chapter{Statistical analysis of fMRI data \label{ch:fmri}}

In this chapter, we use models and tools described in Chapters \ref{ch:models} and \ref{ch:meth} to analyze time series data collected from an fMRI experiment. We describe the most common method of statistical analysis used in the field, i.e. the correlation-based general linear model (GLM) approach \citep{friston:frith:JCBFM:1991,friston:holmes:hbm:1995}, and discuss challenges associated with analyzing fMRI data using this method. Autocorrelated time series invalidate results obtained using the standard GLM, which assumes independence of the error terms in the model. We explore variations of the GLM to account for this autocorrelation and show via simulation the negative consequences of using the standard GLM to analyze autocorrelated data.

We then use the dynamic regression models described in Section \ref{sec:dlm:arwn}, with maximum likelihood
estimation, to describe variation in fMRI data collected from a word recognition experiment. We propose a strategy to compare
different dynamic regression models using PL. Using simulated data, we evaluate our ability to identify true model parameters via maximum likelihood estimation. Then, we use PL to examine conditions under which we can correctly identify a true data-generating model amongst several candidate models. Finally, we analyze real fMRI data using PL and discuss the appropriateness of the dynamic slope model for this data and as a tool for future fMRI studies.

In Section \ref{sec:fmri:intro}, we provide an overview of fMRI, standard estimation of fMRI time series, and the experimental data set. This material is mainly taken from \citet{ashby:fmri:2011}. In Section \ref{sec:fmri:cor}, we compare several techniques for estimating parameters in fMRI time series models and explore their impact on fitted model residuals as well as false positive/true positive rates of concluding significant brain activation. In Section \ref{sec:fmri:dr}, we investigate our ability to identify true values of model parameters in the dynamic regression models described in Section \ref{sec:dlm:arwn}, and we fit real fMRI data using these models by maximum likelihood. Finally, in Section \ref{sec:fmri:pl}, we use simulated data to examine the ability to compare these dynamic regression models against each other using PL, and we discuss results from applying PL under these models to real fMRI data.

\section{Overview of fMRI \label{sec:fmri:intro}}

Functional MRI provides an indirect measure of neural activation in the brain in near real time. Most fMRI experiments measure the \emph{blood oxygen level-dependent (BOLD) signal}, or ratio of oxygenated to deoxygenated hemoglobin in the blood. Evidence suggests that a type of neural activity called the local field potential is closely related to the BOLD signal recorded in an fMRI experiment \citep{logo:bold:2003,logo:bold:2001}. By providing a noninvasive way to study functional changes in the brain over time, fMRI has allowed researchers to study topics that had previously seemed impossible to give a detailed scientific investigation, such as the nature of consciousness \citep{lloyd:conscious:2002}, meditation \citep{cahn:med:2006}, and moral judgement \citep{greene:moral:2001}.

\subsection{The haemodynamic response \label{sec:fmri:hrf}}

The BOLD response to a neural impulse is characterized by an increase in the BOLD signal from a baseline level to its peak at around 6 seconds post-stimulus, followed by a gradual decay back to baseline over the next 20-25 seconds. This typical BOLD response to an impulse as a function of time is referred to as the \emph{haemodynamic response function (hrf)}, and knowledge about this function is crucial for effectively analyzing data from fMRI experiments. Although studies have shown that the hrf varies from person to person based on factors such as age \citep{rich:hrf:2003}, most analyses assume a known form of the hrf for all subjects. A commonly used hrf that is thought to represent an average BOLD response for a typical subject is defined by the SPM software package for analysis of fMRI data (http://www.fil.ion.ucl.ac.uk/spm/doc/). This hrf is known as the canonical hrf (see bottom panel of Figure \ref{fig:fmri:data}). Another commonly used hrf is the gamma function proposed by \citet{boyn:linear:1996}, given by
\begin{equation}
h(s) = \frac{(s/\tau)^{n-1}e^{-s/\tau}}{\tau(n-1)!}, \label{eqn:hrf}
\end{equation}
where $s$ is time in seconds and $\tau$ and $n$ are free parameters that determine the shape of the hrf. We use the canonical hrf for analyzing data from a word recognition experiment in Sections \ref{sec:fmri:arma}, \ref{sec:fmri:mle}, and \ref{sec:fmri:real}, and we use the gamma hrf for simulating fMRI data in Sections \ref{sec:fmri:fpr}, \ref{sec:fmri:res}, \ref{sec:fmri:id}, \ref{sec:fmri:sim}, \ref{sec:fmri:dist}, and \ref{sec:fmri:kappa}.

\subsection{The scanning session \label{sec:fmri:scan}}

An fMRI scanning session consists of one or more runs in which a human subject is presented with a simple task designed to stimulate the brain while scans are taken every few seconds. Runs can typically last anywhere between 10 and 30 minutes, and the \emph{repetition time (TR)}, or length between individual scans, can be anywhere between 1 and 3 seconds. Each scan within a TR involves creating cross-sectional images, or \emph{slices}, across the whole brain. Although TRs less than one second are possible on some machines, decreasing the TR length often comes at the cost of sacrificing spatial resolution of the images resulting from each scan.

Each whole brain image consists of a three-dimensional array of volumetric pixels, or \emph{voxels}, and each voxel contains a value of the BOLD response for a small area of the brain. Voxel size and TR must be determined prior to running an experiment based on desired spatial and temporal resolution of the data. An average experiment might involve three 10-minute scanning runs with a TR of 2 seconds. An average scan might consist of 36 slices, where each slice consists of a 64 by 64 array of 3 $\mbox{mm}^3$ voxels. In this average scenario, each image would be made up of 147,456 voxels, and data from the entire scanning session would contain 132,710,400 BOLD values. Combining this with the fact that many studies involve multi-subject experiments, the sheer sizes of fMRI data sets pose significant challenges for data analysis.

In addition to choosing scanning parameters such as voxel size and TR, designing an fMRI experiment also involves deciding how the experimental stimulus is presented to the subject in the scanner. Three experimental designs frequently used in fMRI are block designs, slow event-related designs, and rapid event-related designs. Block designs divide functional runs into blocks of continuous activity and continuous rest, usually lasting anywhere from 30 seconds to a couple of minutes. During the activation blocks, subjects are instructed to perform the same task continuously over the entire block. In event-related designs, the stimulus \emph{onsets} (i.e., TRs at which an experimental stimulus is presented to the subject) are chosen randomly, with the time between onsets, or \emph{delay}, usually somewhere between 2 and 16 seconds. Slow event-related designs include rest periods that last around 30 seconds, while rapid event-related designs use shorter rest periods.

The long rest periods included in block and slow event-related designs are meant to allow the BOLD response to decay back to baseline before the next stimulus presentation. This helps increase the power of statistical tests designed to identify neural activation or distinguish between event types. However, these designs result in longer experiments which are more expensive and incur a greater risk of having the subject's mind wander during rest periods and generate non-task related BOLD signal. Rapid event-related designs have become more popular with the development of statistical methods such as the GLM approach that make analysis of data collected from these experiments possible.

This section is intended to provide a quick overview of fMRI for the purpose of giving context to the analyses discussed in the rest of this chapter. For more information on fMRI and designing fMRI experiments, we refer the reader to \citet{ashby:fmri:2011,pold:fmri:2011}.

\subsection{The correlation-based GLM approach \label{sec:fmri:glm}}

The standard correlation-based GLM analysis of fMRI data models the observed fMRI data in a single voxel of the brain as a linear function of the expected BOLD response from a voxel responding to the experimental stimulus, i.e.
\begin{equation}
y_t = \beta_0 + \beta_1\mbox{conv}_t + \epsilon_t, \label{eqn:fmri:glm}
\end{equation}
where $y_t$ is the observed fMRI signal at TR $t$, $\mbox{conv}_t$ is the expected BOLD response at TR $t$ in an active voxel, $\beta = (\beta_0,\beta_1)'$ are unknown fixed regression coefficients, and $\epsilon_t \stackrel{iid}{\sim} \mbox{N}(0,\sigma^2)$ are independent random errors. The expected BOLD response, $\mbox{conv}_t$, is calculated by convolving the hrf with an ``on-off'' boxcar function that is equal to 1 when the experimental stimulus is on, and 0 when it is off. Specifically,
\begin{equation}
\mbox{conv}_t = \int_0^{t'} N(s)h(t-s)\mbox{d}s, \label{eqn:fmri:conv}
\end{equation}
where $N(s)$ represents the value of the neural activation boxcar at time $s$ in seconds. Although $N(s)$ and $h(s)$ are defined with respect to time in seconds, we observe fMRI data at discrete time points determined by the TR. Thus, we define the time index $t$ in units of TRs and let $t' = s / TR$. Expected responses to different event types can be included in this model as additional covariates by convolving the hrf with the boxcar function associated with each event. In this chapter, we restrict ourselves to experiments with a single event type.

Under the model given by equation \eqref{eqn:fmri:glm}, the hypothesis test
\begin{equation}
H_0: \beta_1 = 0 \quad H_A: \beta_1 > 0 \label{eqn:fmri:hyp}
\end{equation}
is usually of interest, where rejection of $H_0$ in favor of $H_A$ is interpreted as evidence of neural activation in the voxel from which the fMRI time series came from. To test this hypothesis, ordinary least squares estimates of the unknown fixed parameters $\beta$ and $\sigma^2$ are computed, i.e.
\begin{equation}
\hat{\beta}  = (\hat{\beta}_0,\hat{\beta}_1)' = (X'X)^{-1}X'y \qquad \hat{\sigma}^2 = \frac{1}{T-2}\lVert y-X\hat{\beta} \rVert^2, \label{eqn:fmri:ols}
\end{equation}
where $T$ is the total number of TRs in the functional run, $X$ is the $T$ by $2$ design matrix with first column all 1's and second column equal to $\mbox{conv}_t$, $y = (y_1,\ldots,y_T)'$, and $\lVert\cdot\rVert$ is the Euclidean norm. The test statistic, $T^*$, and p-value, $p^*$, are then calculated by
\begin{equation}
T^* = \frac{\hat{\beta}_1}{\sqrt{\hat{\sigma}^2(X'X)_{(2,2)}^{-1}}} \qquad p^* = \mbox{P}(T^* > t^*_{obs}|H_0), \label{eqn:fmri:ttest}
\end{equation}
where $(X'X)_{(2,2)}^{-1}$ is the element in the second row and second column of $(X'X)^{-1}$, $t^*_{obs}$ is the realization of the random variable $T^*$, and $P(A|H_0)$ is the probability of event $A$ assuming $H_0$ is true. Thus, $p^*$ is calculated under the assumption that $t^* \sim \mbox{T}(0,1,T-2)$, and $H_0$ is rejected if $p^*$ is less than some significance threshold $\alpha$.

The majority of fMRI studies perform this hypothesis test independently for every voxel, resulting in a statistical parametric map of brain activation. With this approach, an adjustment to the significance threshold $\alpha$ must be made to account for multiple hypothesis tests being performed simultaneously. For example, if a false positive rate of $\alpha = 0.05$ is desired, a corrected threshold $\alpha^*$ must be used for each independent test so that the probability of at least one false positive among all tests is 0.05. Because of the spatial relationship among voxels, these hypothesis tests are not actually independent of each other, and this complicates the problem of finding the necessary correction. Typically, an approach relying on the theory of Gaussian random fields is used \citep{wors:grf:1995,wors:mar:cerebral:1996,wors:evans:cerebral:1992,friston:frith:JCBFM:1991}. We refer the reader to \citet[Chapter 6,][]{ashby:fmri:2011} for more information on the multiple comparisons problem.

The standard GLM approach to analyzing fMRI data, which models univariate time series separately for each voxel, is convenient because regression theory allows for simple forms of estimators and fast computation. However, aside from using a multiple comparisons correction, the spatial nature of fMRI data and the connection between voxel-wise time series is ignored using this approach. Hence, a second-stage connectivity analysis is required to gain any insight into neural networks \cite[Chapters 8 and 9][]{ashby:fmri:2011}. The development of multivariate methods that analyze activation and connectivity simultaneously has gained popularity over the last decade. These include independent components analysis \citep{beck:smith:ica:2004}, multi-voxel pattern recognition \citet{norman:mvpa:2006}, representation similarity analysis \citep{nili:rs:2014}, and Bayesian spatio-temporal modeling approaches such as those developed by \citet{wool:jenk:bayesSp:2004}, \citet{bowman:2008:SpMCMC}, \citet{quiros:diez:2010:BayesSpTemp}, and \citet{zhang:guin:2014:npBayesWave}, to name a few.

While the development of efficient numerical approximation algorithms have decreased the computational burden of analyzing fMRI data using Bayesian spatio-temporal models, they are still slower and more difficult to implement than the standard GLM approach. Thus, voxel-wise hypothesis tests are still the norm in fMRI data analysis, and we operate within the framework of univariate voxel-specific time series models for the remainder of this chapter. For more information on fMRI and standard statistical techniques used in the field, see \citet{ashby:fmri:2011, penny:spm:2011}.

\subsection{Word recognition task \label{sec:fmri:data}}

The data set that we analyze in Sections \ref{sec:fmri:dr} and \ref{sec:fmri:pl} comes from an episodic word recognition experiment for one human subject. The task the subject worked on, described in \citet{bennett:miller:2013}, consisted of an encoding session that took place outside the scanner and a recognition session that took place inside the scanner. During encoding, the subject was presented with a list of words one at a time and told to memorize the words so that if they saw one of them again, they would recognize it. During the recognition session, the subject was presented with another list of words, some of which they saw during encoding and some of which were new. The subject was asked to respond as to whether they thought each word was old or new based on their memory.

While in the scanner, the words were presented according to a rapid-event related design with random delays between onsets lasting somewhere between 2 and 10 seconds. The expected BOLD response ($\mbox{conv}_t$) for this design was then constructed by convolving the canonical hrf with a boxcar function that is equal to 1 during TRs when a word was presented to the subject and 0 otherwise. The middle panel of Figure \ref{fig:fmri:data} shows $\mbox{conv}_t$ for this experiment. Scans of the subject's brain were taken every 1.5 seconds for about 6 minutes ($T = 245$ total TRs) with a voxel size of 3 $\mbox{mm}^3$. Although whole brain data were recorded, we look specifically at time series from 5 by 5 by 5 voxel cubes (125 voxels per cube) extracted from six different brain regions, namely the left frontal pole (FP), left intraparietal sulcus (IPS-left), right intraparietal sulcus (IPS-right), primary visual cortex (PV), left secondary visual cortex (SV-left), and right secondary visual cortex (SV-right).

An important step that is performed prior to analyzing fMRI data is preprocessing of the raw data that comes directly out of the scanner. For example, images need to be spatially realigned to reduce the effect of the subject's head movements while inside the scanner. In addition, a high-resolution structural image taken prior to the functional run can be used to discern the exact location of voxels that are difficult to locate in lower resolution functional images. This process is called \emph{coregistration} of the functional and structural data. The coregistered data then needs to be normalized to a standard brain atlas so that active voxels can be assigned to a neuroanatomic brain structure.

For this data set, preprocessing proceeded as outlined in \citet{bennett:miller:2013}:
\begin{quote}
\dsp
``The functional time series were spatially realigned to the first image using a least squares approach with a 6-parameter rigid body affine transformation \citep{friston:ash:spreg:1995}. Realigned images were then ``unwarped'' to reduce the influence of residual movement-related variance on BOLD signal intensity \citep{andersson:deform:2001}. The functional data were coregistered to a high-resolution T1 anatomical image using mutual information maximization with a 6-parameter rigid body affine transform \citep{ashburner:neelin:reg:1997}. Then, the images were normalized to the standard 3D brain atlas defined by the International Consortium for Brain Mapping using a combination of a 12-parameter linear affine transformation and 3 by 2 by 3 nonlinear three-dimensional discrete cosine transform. A 7th degree B-spline was used as the interpolation method for creating normalized images \citep{ashburner:friston:spnorm:1999,mazz:toga:atlas:1995}.''
\end{quote}

Other common preprocessing steps include spatial smoothing and slice-timing correction. Spatial smoothing is intended to get rid of some of the noise in the data and allow for the use of Gaussian random field theory when applying a correction for multiple hypothesis tests. Slice-timing correction adjusts for the fact that brain slices taken during a particular TR don't occur at the same time. For the word recognition experiment, the data were spatially smoothed with an 8 mm full-width at half maximum isotropic Gaussian kernel. Slice-timing correction was not applied to the data and is not typically used when the TR is less than 2 seconds \citep{penny:spm:2011}.

Preprocessing of fMRI data is intended to improve statistical analysis by removing \emph{artifacts}, or abnormalities in the data due to non-task related events. However, it is possible that preprocessing can also add artifacts to the data. For instance, the compound effect of applying both slice-timing correction and spatial realignment can affect the signal in the data. While researchers hope to find signals in the data that provide insight into task-related neural activity, it is possible that the way data are preprocessed can affect results. For more information on preprocessing of fMRI data, see \citet[Chapter 4,][]{ashby:fmri:2011}.

The top panel of Figure \ref{fig:fmri:data} shows the preprocessed fMRI time series for a voxel in IPS-left. Notice that the pattern of the observed time series somewhat mirrors the active response displayed in the middle panel for TRs greater than 75, but not for TRs less than 75. This type of behavior motivates our thinking that a regression model with a changing slope, such as $M_{011}$, might be appropriate for modeling fMRI data.

\begin{figure}
\ssp
\centering
\caption{Single voxel time series from fMRI experiment} \label{fig:fmri:data}
\includegraphics[width=1.0\textwidth]{fmri-craig-data}
\caption*{Time series data (top), expected BOLD response (middle), and haemodynamic response function (bottom) versus TR for voxel 27 in the left intraparietal sulcus.}
\end{figure}

\section{Temporal autocorrelation \label{sec:fmri:cor}}

The standard GLM approach for identifying task-related activity in a single voxel of the brain relies on an assumption of independence of the error terms, $\epsilon_t$, in equation \eqref{eqn:fmri:glm}. This assumption is not reasonable for fMRI data since random departures between the observed and predicted BOLD responses are likely to be similar among voxels near to each other in time and space. One reason for this is that the BOLD response to neural activation is not uniform across space \citep{aguirre:zarahn:varyBOLD:1998}, so any assumed hrf is guaranteed to be at least slightly inaccurate. Thus, if the BOLD response in a voxel at one particular TR is greater than average, it is likely to also be greater than average in nearby voxels and at subsequent TRs \cite[Chapter 1][]{ashby:fmri:2011}. Other factors that contribute to spatially and temporally autocorrelated errors include unaccounted for signals in the data, such as non-task related cognitive activity on the part of the subject, and small movements caused by heartbeat and respiration \citep{loc:jos:arma:1997}.

An approach to handling temporally autocorrelated fMRI time series that was developed early on is to ``color'' the data using a low-pass temporal filter to reduce high-frequency noise and amplify the signal in the data \citep{friston:holmes:color:1995,wors:frist:color:1995}. An alternate approach used by \citet{bullmore:prewhiten:1996} involves a two-stage procedure where the data are \emph{prewhitened} by first estimating the autocorrelation in the errors using the residuals from a GLM fit and then transforming the data to remove the autocorrelation. The standard GLM analysis is then applied to the prewhitened data. The prewhitening approach is an improvement over coloring the data because it yields minimum variance unbiased estimates of the regression coefficients, provided the autocorrelation is accurately estimated from the residuals \citep{frist:penny:classical:2002}. \citet{wool:rip:auto:2001} use resting state data to demonstrate that prewhitening performs more efficiently than coloring in their data, and that bias in estimating the autocorrelation during prewhitening can be lowered by carrying out spatial and temporal smoothing during preprocessing.

The prewhitening approach to handling autocorrelated errors is the standard technique used in the FSL software package (http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/). Other approaches attempt to account for temporal autocorrelations explicitly through modeling. For example, \citet{lund:mad:nvr:2006} measured effects thought to contribute to autocorrelated noise such as heartbeat, respiration, and magnetic field strength, and included them as additional covariates in the GLM. SPM uses an approach developed by \citet{kiebel:holmes:spm:2007} that models the correlation in the errors by
\begin{equation}
\epsilon \sim \mbox{N}(0,\sigma^2 I_T + \lambda Q) \quad Q_{i,j} = \left\{\begin{array}{ll} 0, & \mbox{if } i=j \\ e^{-|i-j|}, & \mbox{if } i\ne j, \end{array} \right. \label{eqn:fmri:kiebel}
\end{equation}
where $T$ is the total number of TRs in the experiment, $\epsilon = (\epsilon_1,\ldots,\epsilon_T)'$, and $\lambda$ is another unknown fixed parameter. Restricted maximum likelihood estimation (REML) is carried out to estimate the unknown fixed parameters, and the hypothesis test in equation \eqref{eqn:fmri:hyp} is performed using the test statistic
\begin{equation}
T^* = \frac{\hat{\beta_1}}{\sqrt{\left((X'X)^{-1}X'(\hat{\sigma}^2 I_T + \hat{\lambda} Q)X(X'X)^{-1}\right)_{(2,2)}}}, \label{eqn:fmri:hyp-reml}
\end{equation}
where $\hat{\beta_1}$, $\hat{\sigma}^2$, and $\hat{\lambda}$ are the REML estimates. We discuss REML further in Section \ref{sec:fmri:fpr}. Under the null hypothesis, $t^* \sim \mbox{T}(0,1,df)$, where the degrees of freedom $df$ is computed by the Satterthwaite approximation \citep{wors:frist:color:1995}. In Section \ref{sec:fmri:fpr}, we compare ordinary least squares (OLS) estimation, prewhitening, and REML in terms of false positive and true positive rates of significant brain activation using simulated data.

\subsection{Exploration of ARMA models \label{sec:fmri:arma}}

Numerous studies have attempted to account for temporal autocorrelation in fMRI data by replacing the error term in equation \eqref{eqn:fmri:glm} by first and second order autoregressive processes \citep{bullmore:prewhiten:1996, loc:jos:arma:1997}. We now explore the class of regression models with $\mbox{ARMA}(P,Q)$ errors discussed in Section \ref{sec:dlm:arma} using maximum likelihood estimation to investigate whether other ARMA error structures might be appropriate for the word recognition data set.

Recall from Section \ref{sec:dlm:arma} that the DLM formulation of a regression model with $\mbox{ARMA}(P,Q)$ errors is given by equations \eqref{eqn:dlm:reg:obs} and \eqref{eqn:dlm:reg:state} with $x_t = (x_{t,1} ,x_{t,2}, \ldots, x_{t,m})'$ an $m$-dimensional vector, $m = \mbox{max}(P,Q+1)$, $F_t$ a time-invariant $1 \times m$ vector with first element equal to 1 and the rest 0, $v_t = 0$ for all $t$, $G$ a $m \times m$ matrix that takes the form
\[
G = \left(
 \begin{array}{ccccc}
 \phi_1 & \vdots \\
 \phi_2 & \vdots \\
 \phi_3 & \vdots && I_{m-1} \\
 \vdots & \vdots \\
 \cdots & \cdots & \cdots & \cdots & \cdots \\
 \phi_m &\vdots & 0 & \cdots & 0
 \end{array}
\right),
\]
and $W = \sigma^2ee'$ with $e = (1, \gamma_1, \ldots, \gamma_{m-1})'$. The unknown fixed parameters are given by $\theta = (\beta', \phi', \gamma', \sigma^2)'$, where $\beta = (\beta_0,\beta_1)'$, $\phi = (\phi_1,\phi_2,\ldots,\phi_P)'$ and $\gamma = (\gamma_1,\gamma_2,\ldots,\gamma_Q)'$. We let $U_t = (1,\mbox{conv}_t)$, where $\mbox{conv}_t$ is the convolution, evaluated at TR $t$ via equation \eqref{eqn:fmri:conv}, of the canonical hrf with the on-off boxcar function representing the stimulus pattern for the word recognition experiment. We adopt the convention that $\phi_s = 0$ for $s > P$ and $\gamma_r = 0$ for $r > Q$.

Maximization of the likelihood is performed using the R function {\tt arima} \citep{Rstats}, which calls on {\tt optim} to minimize the negative log likelihood, given by
\begin{equation}
-\log p(y_{1:T}|\theta) = \frac{1}{2}\sum_{t=1}^T \log|Q_t| + \frac{1}{2}\sum_{t=1}^T \zeta_t' Q_t^{-1} \zeta_t \label{eqn:fmri:loglik}
\end{equation}
\citep[Chapter 6]{shum:stof:2006:timeseries}. Here, $\zeta_t = y_t - f_t$ are the \emph{innovations} of the ARMA process, with $f_t$ and $Q_t$ being the mean and variance of the one-step ahead forecasts for $y_t$. For fixed $\theta$, $f_t$ and $Q_t$ are computed via the Kalman filter in equation \eqref{eqn:dlm:kal}, provided the initial values $m_0$ and $C_0$. These initial values are chosen automatically by {\tt arima} such that the stationarity constraint given in equation \eqref{eqn:arma:prior} is satisfied \citep{gardner:harvey:mlearma:1980}. Given an initial set of fixed parameter values, optimization is performed using an iterative algorithm that alternates between running the Kalman filter conditional on $\theta$ and minimizing equation \eqref{eqn:fmri:loglik} conditional on $f_{1:T}$ and $Q_{1:T}$ \citep{durbin:koopman:timeseries:2012}. Fixed parameter values are constrained to their regions of stationarity, given by equations \eqref{eqn:arpoly} and \eqref{eqn:mapoly}, using the transformation method of \citet{jones:arma:1980}.

Time series regression models with ARMA errors for all combinations of $P$ and $Q$ up to order 10 were fit to data from five randomly chosen voxels from each of the six brain regions using the {\tt arima} function. We then evaluated each model fit using three criteria: Akaike's information criterion (AIC) \citep{sak:ish:kit:aic:1986}, AIC corrected for bias (AICC) \citep{sug:aicc:1978,hurv:tsai:aicc:1989}, and Bayes' information criterion (BIC) \citep{schwarz:bic:1978}. For our model with a single regression covariate, the formulas for these criteria are given by
\begin{align}
AIC &= -2\log p(y_{1:T}|\hat{\theta}) + 2(P+Q+3) \label{eqn:aic} \\
AICC &= -2\log p(y_{1:T}|\hat{\theta}) + 2T\frac{P+Q+2}{T-P-Q-3} \label{eqn:aicc} \\
BIC &= -2\log p(y_{1:T}|\hat{\theta}) + (\log T)(P+Q+3), \label{eqn:bic}
\end{align}
where $\hat{\theta}$ is the MLE of the unknown fixed parameters and $\log p(y_{1:T}|\hat{\theta})$ is the value of the log-likelihood at convergence of the maximum likelihood optimization procedure.

When performing model selection using one of the above criteria, the goal is to select a model that minimizes the specific chosen criterion. The first term is the same for all criteria and should be smaller for better model fits. The second term is a penalty for the number of parameters in the model (a measure of model complexity). BIC imposes the strongest penalty for having more parameters and is the most likely out of the three to prefer simpler models. In our study, we recorded the values of $P$ and $Q$ that minimized each of these criteria for each randomly selected voxel, and the average $P$ and $Q$ for each brain region are shown in Table \ref{tab:fmri:arma}. From these averages, it appears that AIC and AICC prefer $P$ and $Q$ near 3 while BIC prefers $P = 1$ and an $Q = 0$ or 1. We prefer to use the simpler models chosen by BIC and will primarily focus on models that incorporate first-order autoregressive errors in the remainder of this chapter.

\begin{table}
\ssp
\centering
\caption{Mean AR and MA orders for experimental fMRI data} \label{tab:fmri:arma}
\begin{tabular}{|l|cc|cc|cc|}
\hline
Region & \multicolumn{6}{|c|}{Criterion} \\
\hline
 & \multicolumn{2}{|c|}{AIC} & \multicolumn{2}{|c|}{AICC} & \multicolumn{2}{|c|}{BIC} \\
\hline
 & $P$ & $Q$ & $P$ & $Q$ & $P$ & $Q$ \\
\hline
Left frontal pole          & 2.80 & 3.20 & 2.80 & 2.90 & 1.70 & 0.90 \\
Left intraparietal sulcus  & 3.75 & 3.50 & 3.50 & 3.25 & 1.81 & 0.06 \\
Right intraparietal sulcus & 3.20 & 2.80 & 3.20 & 2.80 & 0.80 & 0.80 \\
Primary visual             & 3.10 & 3.00 & 3.10 & 2.70 & 0.90 & 1.70 \\
Secondary visual left      & 3.20 & 2.90 & 2.10 & 2.40 & 1.40 & 0.00 \\
Secondary visual right     & 3.20 & 3.00 & 3.10 & 2.50 & 0.70 & 0.70 \\
\hline
Mean across regions     & 3.21 & 3.07 & 2.97 & 2.76 & 1.22 & 0.69 \\
\hline
\end{tabular}
\caption*{Mean AR and MA orders ($P$ and $Q$, respectively) chosen according to AIC, AICC, and BIC for maximum likelihood fits of regression models with ARMA errors to voxel-wise time series from 5 by 5 by 5 voxel cubes taken from 6 different brain regions.}
\end{table}

\subsection{False positive and true positive rates \label{sec:fmri:fpr}}

In this section, we consider the impact of different approaches to testing for brain activation in autocorrelated voxel-wise time series. Specifically, we examine false positive and true positive rates. The false positive rate is the rate of concluding significant neural activation in a voxel when there is no activity present. The true positive rate (or power) is the rate of concluding significant neural activation when there is in fact activity present. We prefer methods that yield a high true positive rate while keeping the false positive rate low. In this section, we examine the effect on the false positive rate of using standard OLS estimation of the regression slope in equation \eqref{eqn:fmri:glm}, and we compare different methods for accounting for temporal autocorrelation in terms of their effect on false postive and true positive rates.

To analyze false positive and true positive rates, we simulated fMRI data from the regression model described in Section \ref{sec:fmri:arma} with AR(1) error structure (i.e. $P = 1$ and $Q = 0$). An experiment with a rapid event-related design and a single event type was created by simulating random times between onsets according to a truncated geometric distribution with a maximum time-to-event of 10 TRs. We used a TR of 2 seconds and let the experiment run for 250 total TRs. Onset of the stimuli were assumed to last the length of the TR, and an on-off boxcar function of 1's and 0's was constructed to match the stimulus pattern. The explanatory variable in the regression, $\mbox{conv}_t$, was constructed by convolving the boxcar function with the gamma hrf from equation \eqref{eqn:hrf} with $\tau = 2$ and $n = 4$. Figure \ref{fig:fmri:design} displays the simulated experimental design and expected BOLD response ($\mbox{conv}_t$) for active voxels.

\begin{figure}
\ssp
\centering
\caption{Simulated rapid-event related design of fMRI experiment} \label{fig:fmri:design}
\includegraphics[width=1.0\textwidth]{fmri-design-3-500-1-big}
\caption*{Simulated boxcar function (top), hrf (middle), and convolution of the boxcar with the hrf (bottom) for a rapid-event related design of an fMRI experiment.}
\end{figure}

Time series of length $T = 250$ were then simulated according to $M_{100}$, i.e. a regression model with AR(1) errors as in equations \eqref{eqn:dlm:reg:obs} and \eqref{eqn:dlm:reg:state} with $m = P = 1$, $Q = 0$, $F_t = 1$ for all $t$, $v_t \sim \delta_0(v_t)$ for all $t$ (i.e., $v_t = 0$ for all $t$), $G = \phi$, $W = \sigma^2$, $\beta = (\beta_0,\beta_1)'$, and $U_t = (1, \mbox{conv}_t)$. For these simulations, we let $\beta_0 = 750$ and $\sigma^2 = 15$, and one thousand time series were generated for every $(\beta_1,\phi) \in \{0,1,2,3\}\times\{0.25,0.50,0.75,0.95\}$. Different values of $\beta_1$ were used so that we could analyze false positive rates (for $\beta_1 = 0$) and power (for $\beta_1 > 0$). Similarly, different values of $\phi$ were used for simulation so that we could analyze false positive rates and true positive rates for increasing amounts of autocorrelation in the data.

For each simulated time series, we tested the hypothesis in equation \eqref{eqn:fmri:hyp} using the OLS method, i.e. where the test statistic and p-value are calculated according to equations \eqref{eqn:fmri:ols} and \eqref{eqn:fmri:ttest}. We also performed hypothesis tests using prewhitening (PW) and two variations of a REML approach. Our PW and REML approaches each assume that the data are generated from $M_{100}$, as described in the preceding paragraph, where the AR(1) process for $x_t$ is stationary. This model can be reformulated as
\begin{align}
y &= X\beta + \epsilon, \quad \mbox{ where} \label{eqn:fmri:ar1} \\
\epsilon &\sim \mbox{N}(0,\sigma^2\Lambda), \nonumber \\
\Lambda_{i,j} &= \frac{\phi^{|i-j|}}{1 - \phi^2}, \nonumber
\end{align}
$\beta = (\beta_0,\beta_1)'$ are the fixed regression coefficients, $y$ and $X$ are data vector and design matrix, respectively, as defined immediately after equation \eqref{eqn:fmri:ols}, and $\epsilon = (\epsilon_1,\ldots,\epsilon_T)'$ is the vector of error terms.

The PW approach uses the fact that if $\Lambda$ is known, the data can be transformed via
\begin{equation}
y^* = S^{-1}y \qquad X^* = S^{-1}X, \label{eqn:gls:trans}
\end{equation}
where $S$ is the Cholesky decomposition of $\Lambda$ (i.e. $SS' = \Lambda$), to yield the independent error GLM given by
\begin{equation}
y^* = X^*\beta + \epsilon \quad \epsilon \sim \mbox{N}(0,\sigma^2I_T). \label{eqn:gls}
\end{equation}
We carry out the PW method on a time series from a single voxel by first estimating $\beta_0$ and $\beta_1$ using OLS. Then, a zero mean
AR(1) process is fitted to the residuals from the resulting fit, using maximum likelihood via the {\tt arima} function in R. The maximum likelihood estimate of the autocorrelation in the residuals, denoted by $\hat{\phi}$, is used to approximate $\phi$ in equation \eqref{eqn:fmri:ar1}, and an estimate of the covariance matrix $\Lambda$ is computed according to
\begin{equation}
\hat{\Lambda}_{(i,j)} = \frac{\hat{\phi}^{|i-j|}}{1-\hat{\phi}^2}. \label{eqn:pw:cor}
\end{equation}
The data are then transformed according to
\begin{equation}
\hat{y}^* = \hat{S}^{-1}y \qquad \hat{X}^* = \hat{S}^{-1}X, \label{eqn:pw:trans}
\end{equation}
where $\hat{S}$ is the Cholesky decomposition of $\hat{\Lambda}$. Lastly, the hypothesis test is performed using the OLS method with $\hat{y}^*$ and $\hat{X}^*$ used in place of $y$ and $X$ in equations \eqref{eqn:fmri:ols} and \eqref{eqn:fmri:ttest}.

Estimation using the restricted likelihood is intended to remove bias in estimating variance components that is due to fixed regression coefficients being included in the model. This is achieved by integrating $\beta$ out of the full likelihood. For hypothesis tests using REML, we first obtain an estimate of $\phi$ by maximizing the profiled log-restricted likelihood, derived by \citet{harville:reml:1977} and given by
\begin{align}
\log p(y|\phi) \propto & -(T-2)\log\left|\left| y^* - X^*\left[(X^*)'X^*\right]^{-1}(X^*)'y^* \right|\right| \label{eqn:fmri:plrl} \\
 & - \frac{1}{2}\log\left|(X^*)'X^*\right| - \frac{1}{2} \log |\Lambda| \nonumber
\end{align}
\citep[Page 205]{pin:bates:mixed:2000}. Here, $y^*$, $X^*$, and $\Lambda$ are implicitly functions of $\phi$, with $y^*$ and $X^*$ described by equation \eqref{eqn:gls:trans} and $\Lambda$ described by the third line of equation \eqref{eqn:fmri:ar1}. Once $\hat{\phi}$ that maximizes $\log p(y|\phi)$ in equation \eqref{eqn:fmri:plrl} is found, $\hat{\Lambda}$ is calculated according to equation \eqref{eqn:pw:cor}, $\hat{X}^*$ and $\hat{y}^*$ are calculated according to equation \eqref{eqn:pw:trans}, and REML estimates of $\beta$ and $\sigma^2$ are computed according to
\begin{equation}
\hat{\beta} = \left[(\hat{X}^*)'\hat{X}^*\right]^{-1}(\hat{X}^*)'\hat{y}^* \qquad \hat{\sigma}^2 = \frac{1}{T-2}\left|\left| \hat{y}^*-\hat{X}^*\hat{\beta} \right|\right|^2. \label{eqn:fmri:reml}
\end{equation}

% using the test statistic
%\begin{equation}
%t^* = \frac{\hat{\beta_1}}{\sqrt{\left((X'X)^{-1}X'(\hat{\sigma}^2\hat{\Lambda})X(X'X)^{-1}\right)_{(2,2)}}}, \label{eqn:fmri:hyp-reml:ar1}
%\end{equation}
%and $p^*$ is calculated as in equation \eqref{eqn:fmri:ttest} under the assumption that $t^* \sim \mbox{T}(0,1,T-2)$.

We used the {\tt gls} function in R package {\tt nlme} to find $\hat{\phi}$ that maximizes the profiled log-restricted likelihood in equation \eqref{eqn:fmri:plrl} \citep{pin:bates:mixed:2000}, and then used equations \eqref{eqn:fmri:reml} to calculate $\hat{\beta}$ and $\hat{\sigma}^2$. We then performed the t-test in equation \eqref{eqn:fmri:ttest} using these estimates of $\hat{\beta}_1$ and $\hat{\sigma}^2$, with $\hat{X}^*$ used in place of $X$. However, because $\phi$ is estimated in addition to $\sigma^2$, the null distribution of the test statistic $T^*$ no longer follows a t-distribution. Nonetheless, we can perform the t-test conditional on the REML estimate of $\phi$ by using $\mbox{T}(0,1,T-2)$ as an approximation to the null distribution of $T^*$.

A better approximation to the null distribution of $T^*$ can be achieved by using a t-distribution with an adjusted degrees of freedom. For example, \citet{kiebel:holmes:spm:2007} adjusts the degrees of freedom of the t-test for the model described by equation \eqref{eqn:fmri:kiebel} using the Satterthwaite approximation described in \citet{wors:frist:color:1995}. We consider a strategy prescribed by \citet{dawdy:matalas:ess:1964}, where the problem of autocorrelated time series within the context of statistical tests that depend on an assumption of independent random samples is circumvented by calculating the so-called ``effective sample size''. Specifically, we use an effective sample size adjustment for time series with first-order autocorrelation, given by
\begin{equation}
T' = T\frac{1-\hat{\phi}}{1+\hat{\phi}}, \label{eqn:fmri:ess}
\end{equation}
and we adjust the degrees of freedom of the t-test by using $T' - 2$. We will refer to the method that approximates the null distribution of $T^*$ using $\mbox{T}(0,1,T-2)$ as the REML approach, and we will refer to the method that approximates this distribution using $\mbox{T}(0,1,T'-2)$ as the REMLc approach (for corrected REML).

Table \ref{tab:fmri:fpr} displays false positive rates of rejecting $H_0$ using significance thresholds $\alpha = 0.001, 0.01, \mbox{ and } 0.05$ for the 1000 simulations using $\beta_1 = 0$ and for each of four values of $\phi$. Methods of estimation that accurately assess the uncertainty in $\hat{\beta_1}$ should yield false positive rates equal to $\alpha$. The results from Table \ref{tab:fmri:fpr} illustrate that using OLS inflates the false positive rate, and furthermore that the ratio of the false positive rate to $\alpha$ increases as $\alpha$ decreases. %This is an undesirable feature, since lower $\alpha$ levels should result in more conservative tests.

Figure \ref{fig:fmri:fpr} displays false positive rates with increasing $\alpha$ for each method and each true value of $\phi$, as well as 95\% confidence intervals for the false positive rates calculated using a normal approximation to the distribution of the proportion of false positives out of the 1000 simulations. The 95\% confidence intervals around the false positive rate for PW and REML contain the nominal threshold $\alpha$ for all values of $\phi$. REMLc appears to give slightly lower false positive rates than REML and PW for $\phi \le 0.75$ and decidedly lower false positive rates for $\phi = 0.95$ (for which the approximate confidence intervals for REMLc do not contain the nominal value of $\alpha$). While at first glance this may seem to be an advantage of REMLc, a decrease in the false positive rate can come at the cost of a decrease in the true positive rate as well. Figure \ref{fig:fmri:roc} illustrates this point using ROC curves. The ROC curves in this figure display the true positive rate versus the false positive rate for the hypothesis tests performed according to each method. The methods with the largest area under the ROC curve performed the best in terms of distinguishing between the null and alternative hypotheses. The curve corresponding to $\phi = 0.95$ shows that REMLc is outperformed by PW and REML in our simulation, suggesting that although REMLc offers a decrease in the false positive rate for highly autocorrelated data relative to the other methods, it does not correctly identify as many truly active voxels.

\begin{table}
\ssp
\centering
\caption{False positive rates for simulated fMRI data} \label{tab:fmri:fpr}
\begin{tabular}{|c|cccc|}
\hline
$\alpha$ & OLS & PW & REML & REMLc \\
\hline
 & \multicolumn{4}{|c|}{$\phi = 0.25$} \\
\hline
0.001 & 0.006 & 0.001 & 0.001 & 0.001 \\
0.010 & 0.028 & 0.011 & 0.010 & 0.010 \\
0.050 & 0.106 & 0.050 & 0.049 & 0.048 \\
\hline
 & \multicolumn{4}{|c|}{$\phi = 0.50$} \\
\hline
0.001 & 0.022 & 0.002 & 0.002 & 0.002 \\
0.010 & 0.070 & 0.010 & 0.009 & 0.007 \\
0.050 & 0.161 & 0.054 & 0.052 & 0.052 \\
\hline
 & \multicolumn{4}{|c|}{$\phi = 0.75$} \\
\hline
0.001 & 0.061 & 0.001 & 0.001 & 0.000 \\
0.010 & 0.130 & 0.017 & 0.016 & 0.015 \\
0.050 & 0.213 & 0.064 & 0.062 & 0.055 \\
\hline
 & \multicolumn{4}{|c|}{$\phi = 0.95$} \\
\hline
0.001 & 0.072 & 0.000 & 0.000 & 0.000 \\
0.010 & 0.144 & 0.011 & 0.011 & 0.000 \\
0.050 & 0.230 & 0.046 & 0.049 & 0.023 \\
\hline
\end{tabular}
\caption*{False positive rates at significance levels $\alpha = 0.001, 0.01, \mbox{ and } 0.05$ (rows) for testing $H_0: \beta_1 = 0$ vs $H_A: \beta_1 > 0$ using OLS, PW, REML, and REMLc (columns) on 1000 simulated data sets of length $T = 250$ from $M_{100}$ with $\beta = (750, 3)$, $\sigma^2 = 15$, and for each $\phi \in \{0.25, 0.50, 0.75, 0.95\}$.}
\end{table}

\begin{figure}
\ssp
\centering
\caption{False positive rates for simulated fMRI data} \label{fig:fmri:fpr}
\includegraphics[width=1.0\textwidth]{simstudy-FPR}
\caption*{False positive rates (FPR, solid lines) and 95\% confidence intervals (dashed lines) for testing $H_0: \beta_1 = 0$ vs $H_A: \beta_1 > 0$ plotted against the nominal threshold level $\alpha$ (gray line) using OLS (black lines), PW (red lines), REML (green lines), and REMLc (blue lines) on simulated data from $M_{100}$ with $T = 250$, $\beta = (750, 0)$, $\sigma^2 = 15$, and increasing $\phi$ (plot panels). Each panel is based on the same set of 1000 simulations (using the specified $\phi$) for all values of $\alpha$, and plot axes are the same across all panels.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{ROC curves for simulated fMRI data} \label{fig:fmri:roc}
\includegraphics[width=1.0\textwidth]{simstudy-ROC-3-fill2}
\caption*{ROC curves for testing $H_0: \beta_1 = 0$ vs $H_A: \beta_1 > 0$ using OLS (black lines), PW (red lines), REML (green lines), and REMLc (blue lines) on simulated data from $M_{100}$ with $T = 250$, $\beta = (750, 3)$, $\sigma^2 = 15$, and increasing $\phi$ (plot panels). In each panel, the vertical axis is the true positive rate (TPR) and the horizontal axis is the false positive rate (FPR). The axes are the same in all panels. Diagonal dashed line would occur if TPR and FPR equalled each other.}
\end{figure}

\subsection{Testing independence of residuals \label{sec:fmri:res}}

In the previous section, we used false positive rates to compare several methods that attempt to capture the autocorrelation in fMRI time series. To do this, we simulated non-active voxels by letting the true $\beta_1 = 0$ in $M_{001}$. In practice, however, we don't know beforehand which voxels are inactive, making false positive rates difficult to obtain. Many studies have attempted to analyze false positive rates using \emph{resting state} data, or fMRI data generated from a subject at rest \citep{purdon:weiss:fpr:1998,burock:dale:fpr:2000,wool:rip:auto:2001}. These studies have effectively provided insight into the impact of certain autocorrelation estimation algorithms, sampling rates, and experimental designs on false positive rates. However, it is difficult to assess whether voxels from a subject who is resting are really inactive. For example, the subject's mind could wander during the experiment and generate a BOLD signal. Furthermore, research suggests that some brain areas exhibit some intrinsic activation during resting state, such as those associated with the default mode network \citep{grei:kras:dfmnet:2003,grei:sup:dfmnet:2009}.

An alternate strategy that has been used for evaluating different models of autocorrelation in fMRI data is to examine the residuals from a fitted model and test whether or not they are uncorrelated \citep{luo:nich:diag:2003,leonski:bax:res:2008}. In particular \citet{leonski:bax:res:2008} compares several autocorrelation estimation algorithms used in different software packages such as SPM and FSL, and then suggests that an AR(2) process be used for modeling the errors in fMRI time series. The latter recommendation is based in part on the fact that residuals from AR(2) fits to fMRI data used in their study were determined to be uncorrelated more often than for residuals from other models according statistical tests such as the Durbin-Watson and cumulative periodogram tests.

While an AR(2) error structure may be appropriate for modeling some data sets, we contend that an analysis of residuals should not be the basis for this decision. This is because of the potential for overfitting. To illustrate, we fit regression models with each of independent, AR(1), and AR(2) error structures to the 1000 simulated data sets of length $T = 250$ described in Section \ref{sec:fmri:fpr} with $\beta = (750,3)'$, $\sigma^2 = 15$, and for each $\phi \in \{0.25,0.50,0.75,0.95\}$. The regression models with independent errors were fit using OLS, and those with AR(1) and AR(2) errors were fit using the {\tt arima} function in R. For each fitted model, we tested the independence of the residuals using the Ljung-Box test for lag-1 autocorrelations \citep{box:test:1978}. Specifically, we test the null hypothesis ($H_0$) that the residuals are independently distributed against the alternative hypothesis ($H_A$) that they are not independently distributed by assuming that the test statistic
\begin{equation}
Q = \frac{T(T+2)}{\hat{\omega}^2(T-1)} \label{eqn:box}
\end{equation}
can be approximated by a chi-squared distribution with 1 degree of freedom under $H_0$, where $\hat{\omega}$ is the lag-1 sample autocorrelation in the residuals.

The results in Table \ref{tab:fmri:res} show that even though the true data-generating model has AR(1) errors, $H_0$ was not rejected when using residuals from the AR(2) fit just as often if not more often than when using residuals from the AR(1) fit. For this reason, we do not recommend evaluating models with autocorrelated errors based on an assessment of independence of residuals. Instead, in Section \ref{sec:fmri:pl}, we explore a model comparison strategy based on PL.

\begin{table}
\ssp
\centering
\caption{Proportion of times null hypothesis of independent errors was not rejected for simulated fMRI data} \label{tab:fmri:res}
\begin{tabular}{|c|ccc|}
\hline
$\alpha$ & OLS & AR(1) & AR(2) \\
\hline
 & \multicolumn{3}{|c|}{$\phi = 0.25$} \\
\hline
0.001 & 0.332 & 1.000 & 1.000 \\
0.010 & 0.134 & 1.000 & 1.000 \\
0.050 & 0.028 & 1.000 & 1.000 \\
\hline
 & \multicolumn{3}{|c|}{$\phi = 0.50$} \\
\hline
0.001 & 0.000 & 1.000 & 1.000 \\
0.010 & 0.000 & 1.000 & 1.000 \\
0.050 & 0.000 & 0.999 & 1.000 \\
\hline
 & \multicolumn{3}{|c|}{$\phi = 0.75$} \\
\hline
0.001 & 0.000 & 1.000 & 1.000 \\
0.010 & 0.000 & 1.000 & 1.000 \\
0.050 & 0.000 & 0.994 & 1.000 \\
\hline
 & \multicolumn{3}{|c|}{$\phi = 0.95$} \\
\hline
0.001 & 0.000 & 1.000 & 1.000 \\
0.010 & 0.000 & 0.991 & 1.000 \\
0.050 & 0.000 & 0.958 & 1.000 \\
\hline
\end{tabular}
\caption*{Proportion of times $H_0$ of independent residuals is not rejected in favor of $H_A$ of non-independent residuals based on 1000 simulations of length $T = 250$ from $M_{100}$ with $\beta = 3$, $\sigma^2 = 15$, and increasing $\phi$ (embedded tables), as determined by Ljung-Box test at varying significance levels $\alpha$ (rows) from fitting regression models with independent (OLS), AR(1), and AR(2) error structures.}
\end{table}

\section{Fitting dynamic regression models \label{sec:fmri:dr}}

We now turn our attention to the dynamic regression models described in Section \ref{sec:dlm:arwn}. Specifically, we examine the dynamic intercept model ($M_{101}$), dynamic slope model ($M_{011}$), and a model with both a dynamic intercept and a dynamic slope ($M_{111}$). $M_{101}$ can be thought of as a regression model with AR(1)+WN errors, which has been used to analyze fMRI time series \citep{purdon:weiss:fpr:1998,burock:dale:fpr:2000} and is similar to the model used in SPM \citep{kiebel:holmes:spm:2007}. Of particular interest to us is the possibility of modeling fMRI time series using $M_{011}$ or $M_{111}$ . While models with a constant slope and autocorrelation included only in the error term of the regression model, as in $M_{101}$, have been the norm for analyzing fMRI data, we explore the possibility that a model with a changing slope, such as $M_{011}$, can improve on existing methods through the ability to adapt to behaviors, such as learning or changes in focus, on the part of the subject.

\subsection{Identifiability of dynamic regression models \label{sec:fmri:id}}

Before applying the dynamic regression models to actual fMRI data, we examine whether we can identify these models using simulated data. That is, if we simulated multiple time series from $M_{011}$, for example, with the same true values of the model parameters, could we expect to recover these true values from the data? Since maximum likelihood estimators of unknown fixed parameters in these models are asymptotically normal and consistent \cite[Section 10.1][]{casella:berger:2002}, we'd expect that MLEs obtained from fitting repeated simulations from $M_{011}$ to the same model would crowd around the true parameter values if the generated time series were long enough. We must investigate if the voxel-wise time series generated from the word recognition experiment are long enough to identify model parameters in this way.

To investigate this, we simulated 1000 time series of length $T = 250$ (in the actual word recognition experiment analyzed in Sections \ref{sec:fmri:arma}, \ref{sec:fmri:mle}, and \ref{sec:fmri:real}, $T = 245$) from each of $M_{101}$, $M_{011}$, and $M_{111}$ with $u_t = \mbox{conv}_t$, the expected BOLD response from the simulated experiment pictured in the middle panel of Figure \ref{fig:fmri:design}. We let the true $\beta = (750, 15)'$ and $\sigma^2_m = 10$ in each of these simulation models, and repeated the simulations for various values of $\phi$, $\sigma^2_s$, $\rho$, and $\sigma^2_b$ (these last two parameters are only relevant for $M_{111}$). Specifically, for $M_{101}$ and $M_{011}$, we simulate for all combinations of $\phi \in \{0.1, 0.5, 0.9\}$ and $\sigma^2_s \in \{1, 5, 10, 15, 20\}$. For $M_{111}$, we simulate for all combinations of $\phi \in \{0.3, 0.6, 0.9\}$, $\sigma^2_s \in \{1, 5, 10, 15, 20\}$, $\sigma^2_b \in \{1, 5, 10, 15, 20\}$, and $\rho \in \{0.3, 0.6, 0.9\}$. The choice of these particular values for $\beta$ and range of values for the variance terms was motivated by the MLEs from fitting real fMRI data in Section \ref{sec:fmri:mle}.

For each simulated time series, we calculate MLEs for the unknown fixed parameters using the {\tt dlmMLE} function in R package {\tt dlm} \citep{petris:camp:2009:dynamic}. We use this function instead of {\tt arima} because it allows us to incorporate the observation error, $v_t$, into the model. However, {\tt dlmMLE} operates on models of the form given by equations \eqref{eqn:dlm:obs} and \eqref{eqn:dlm:state}, where the additional regression term $U_t\beta$ is not included. Thus, to use this function to find MLEs of fixed parameters in the dynamic regression models, $\beta$ must be incorporated into $x_t$ and $U_t$ into $F_t$. To allow for estimation via {\tt dlmMLE}, we therefore reformulate $M_{011}$ and $M_{101}$ as
\begin{align}
y_t &= \tilde{F}_t\tilde{x}_t + v_t \label{eqn:dlmmle:obs} \\
\tilde{x}_t &= \tilde{G}\tilde{x}_{t-1} + w_t, \label{eqn:dlmmle:state}
\end{align}
where $\tilde{x}_t = (\beta_0,\beta_1,x_t)'$, $\tilde{F}_t = (1,\mbox{conv}_t,F_t)$,
\[\tilde{G} = \left(\begin{array}{ccc} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & \phi\end{array}\right), \]
and \[v_t \stackrel{iid}{\sim} \mbox{N}(0,\sigma^2_m) \perp w_t \stackrel{iid}{\sim} \mbox{N}\left(\left(\begin{array}{c} 0 \\ 0 \\ 0 \end{array}\right), \left(\begin{array}{ccc} 0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & \sigma^2_s \end{array}\right)\right).\]
For $M_{011}$, we let $F_t = \mbox{conv}_t$, and for $M_{101}$, we let $F_t = 1$ for all $t$. In these models, $x_t$ represents either the change in regression slope or the change in the regression intercept, respectively, as in Section \eqref{sec:dlm:arwn}.

To allow maximum likelihood estimation of model parameters in $M_{111}$ using R function {\tt dlmMLE}, we reformulate the model from equations \eqref{eqn:arwn:dynboth:obs} through \eqref{eqn:arwn:dynboth:state2} into the form of equations \eqref{eqn:dlmmle:obs} and \eqref{eqn:dlmmle:state} with $\tilde{x}_t = (\beta_0,\beta_1,x_{1,t},x_{2,t})'$, $\tilde{F}_t = (1,\mbox{conv}_t,1,\mbox{conv}_t)$,
\[\tilde{G} = \left(\begin{array}{cccc} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & \phi & 0 \\ 0 & 0 & 0 & \rho \end{array}\right), \]
and \[v_t \stackrel{iid}{\sim} \mbox{N}(0,\sigma^2_m) \perp w_t \stackrel{iid}{\sim} \mbox{N}\left(\left(\begin{array}{c} 0 \\ 0 \\ 0 \\ 0 \end{array}\right), \left(\begin{array}{cccc} 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & \sigma^2_s & 0 \\  0 & 0 & 0 & \sigma^2_b \end{array}\right)\right).\]
Here, $x_{1,t}$ and $x_{2,t}$ represent the change in the regression intercept and slope, respectively.

Similar to {\tt arima}, {\tt dlmMLE} uses a call to {\tt optim} to minimize the negative log likelihood, expressed as
\begin{equation}
-\log p(y_{1:T}|\theta) \propto \frac{1}{2}\sum_{t=1}^T \log |Q_t| + \frac{1}{2}\sum_{t=1}^T (y_t-\tilde{F}_tz_t)'Q_t^{-1}(y_t-\tilde{F}_tz_t) \label{eqn:fmri:dlmll}
\end{equation}
\citep[Chapter 4]{petris:camp:2009:dynamic}. Here, $z_t$ and $Q_t$ depend implicitly on $\theta$ and are calculated according to the Kalman filter given by equation \eqref{eqn:dlm:kal} with $\tilde{F}_t$ and $\tilde{G}$ used in place of $F_t$ and $G$, respectively, and initial values $m_0 = C_0 = 0$ (to constrain $x_0 = 0$).

Maximum likelihood estimates of $\phi$, $\sigma^2_s$, and $\sigma^2_m$ (and $\rho$ and $\sigma^2_b$ for $M_{111}$) -- denoted $\hat{\phi}$, $\hat{\sigma}^2_s$, and $\hat{\sigma}^2_m$ (and $\hat{\rho}$ and $\hat{\sigma}^2_b$) -- are obtained directly from {\tt dlmMLE}, while MLEs for $\beta$ are obtained from the first and second elements of $m_T$ after running the Kalman filter in equation \eqref{eqn:dlm:kal} conditional on $\hat{\phi}$, $\hat{\sigma}^2_s$, and $\hat{\sigma}^2_m$ (and $\hat{\rho}$ and $\hat{\sigma}^2_b$) with $m_0 = C_0 = 0$, $F_t = \tilde{F}_t$, $V = \hat{\sigma}^2_m$, $G = \tilde{G}$, and $W = \tilde{W}$. Since $U_t$ and $\beta$ are already included in $F_t$ and $x_t$, respectively, the Kalman filter is implemented with the middle line in equation \eqref{eqn:dlm:kal} reading $f_t = \tilde{F}_tz_t$ (instead of $f_t = U_t\beta + \tilde{F}_tz_t$).

Unlike in Section \ref{sec:fmri:arma}, we do not restrict $\phi$ (or $\rho$) to the region of stationarity. This is intended to enable modeling of a wider range of behavior in fMRI data, as well as placing priors on the unknown fixed parameters that are conjugate conditional on the states, so that estimation using the particle learning algorithm (described in Section \ref{sec:pl}) can be performed. In some cases, we obtain estimates of $\phi$ that lay outside the region of stationarity when analyzing fMRI time series from the word recognition data set using maximum likelihood in Section \ref{sec:fmri:mle} and particle learning in Section \ref{sec:fmri:real}.

Figure \ref{fig:fmri:id:M011SNR} displays either univariate histograms or two-dimensional kernel density estimates \citep{wand2006kernsmooth} of the MLEs for fits of $M_{011}$ to data simulated from the same model with $\phi = 0.1$ and increasing signal-to-noise ratio $\sigma^2_s / \sigma^2_m$. We characterize the model as being ``well identified'' if the maximum likelihood estimates appear to be approximately normally distributed and concentrated around the true parameter values, since asymptotic distribution theory for MLEs guarantees the MLEs for the fixed parameters are asymptotically normal and consistent \citep[Section 10.1]{casella:berger:2002}. In this figure, $\beta$ appears to be well identified for all values of the signal-to-noise ratio, as evidenced by the two-dimensional kernel density estimates in the first column of Figure \ref{fig:fmri:id:M011SNR} that show an ellipse with a clear mode near the true value. However, for true $\sigma^2_s / \sigma^2_m = 0.1$, $\phi$, $\sigma^2_s$, and $\sigma^2_m$, don't appear to be well identified. By increasing $\sigma^2_s / \sigma^2_m > 0.1$, identification of these parameters seems to improve.

Figure \ref{fig:fmri:id:M011PRR} shows similar plots with $\sigma^2_s / \sigma^2_m$ fixed at 0.1 and increasing true values of $\phi$. While identification of $\phi$, $\sigma^2_s$, and $\sigma^2_m$ appears to be poor for $\phi = 0.1$, a drastic improvement is shown by increasing $\phi$ to 0.5 and 0.9. $\beta$, again, is identified well for all combinations of fixed parameter values shown in the figure. In addition, the rate at which the {\tt optim} function in R successfully converged at the minimum of the negative log likelihood for a given set of 1000 simulations using fixed true values of the unknown parameters (displayed along the top of the plots in the first column of Figures \ref{fig:fmri:id:M011SNR} and \ref{fig:fmri:id:M011PRR}) is 1 for all true values of $\sigma^2_s / \sigma^2_m$, indicating that a clear maximum value of the likelihood always exists for these simulated time series from $M_{011}$.

Lastly, we comment on the skewness of the distribution of the MLEs for $\phi$ when the true value is 0.9, as illustrated by the histogram in the last row of Figure \ref{fig:fmri:id:M011PRR}. Asymptotic distribution theory for MLEs guarantees that this distribution should appear more bell-shaped as $T$ approaches infinity \citep[Section 10.1]{casella:berger:2002}. However, for finite $T$, this distribution is skewed toward lower values of $\phi$. This is because values of $\phi$ larger than 1 lead to a model with a nonstationary dynamic slope, behavior that is fundamentally different from that exhibited by the simulated data with a stationary dynamic slope. Similar results using larger $T$ (not shown) show less skewness and smaller variance in the distribution for $\phi$, with a more bell-shaped histogram concentrated around the true value of $\phi = 0.9$.

\begin{figure}
\ssp
\centering
\caption{Identifying dynamic slope model by increasing signal-to-noise ratio} \label{fig:fmri:id:M011SNR}
\includegraphics[width=0.75\textwidth]{1000-250-M011-conv-750-15-1-5-SNR-10-10}
\caption*{Histograms in 1D (for $\phi$, second column) and 2D kernel density estimates (for $\beta$ in first column and $(\sigma^2_s,\sigma^2_m)$ in the third column) of MLEs of fits of $M_{011}$ to data simulated from $M_{011}$ with true $\beta = (750,15)'$, $\phi = 0.1$, $\sigma^2_m = 10$, and increasing $\sigma^2_s$ (rows). Blue crosses indicate the true values of $\beta$ and $(\sigma^2_s,\sigma^2_s)$ in each of the corresponding image panels, and blue vertical lines indicate the true value of $\phi$. Plot axes are the same within the first and second columns, but differ within the third column due to differing true signal to noise ratios $\sigma^2_s / \sigma^2_m$.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Identifying dynamic slope model by increasing autocorrelation} \label{fig:fmri:id:M011PRR}
\includegraphics[width=1.0\textwidth]{1000-250-M011-conv-750-15-PRR-5-1-10-10}
\caption*{Histograms in 1D (for $\phi$, second column) and 2D kernel density estimates (for $\beta$ in first column and $(\sigma^2_s,\sigma^2_m)$ in third column) of MLEs of fits of $M_{011}$ to data simulated from $M_{011}$ with true $\beta = (750,15)'$, $\sigma^2_s = 1$, $\sigma^2_m = 10$, and increasing $\phi$ (rows). Blue crosses indicate the true values of $\beta$ and $(\sigma^2_s,\sigma^2_s)$ in each of the corresponding image panels, and blue vertical lines indicate the true values of $\phi$. Plot axes are the same within the first and third columns, but differ within the second column due to differing true lag-1 autocorrelations $\phi$.}
\end{figure}

Figures \ref{fig:fmri:id:M011SNR} and \ref{fig:fmri:id:M011PRR} provide evidence that $M_{011}$ is well-identified provided the true signal-to-noise ratio and true autocorrelation coefficient are not too low. Similar plots shown in Figures \ref{fig:fmri:id:M101SNR} and \ref{fig:fmri:id:M101PRR} reveal that identifiability of true model parameters in $M_{101}$ is more challenging. When the true $\phi$ is fixed at 0.1, identification of $\phi$, $\sigma^2_s$, and $\sigma^2_m$ in $M_{101}$ is poor for all $\sigma^2_s \in \{1,5,10,15,20\}$, indicated by the bimodal two-dimensional kernel density estimates of the MLEs for $(\sigma^2_s, \sigma^2_m)$ and non-Gaussian distributions of MLEs for $\phi$ shown in Figure \ref{fig:fmri:id:M011SNR}. However, when the true $\sigma^2_s / \sigma^2_m$ is fixed at 0.1, increasing the true $\phi$ to 0.9 results in much better identification of these model parameters, as illustrated by the histograms and two-dimensional kernel density estimates of the MLEs for $\phi$ and $(\sigma^2_s, \sigma^2_m)$, respectively, that concentrate near their corresponding true values in the last row of Figure \ref{fig:fmri:id:M101PRR}. In each of these cases, the distributions of the MLEs for $\beta$ appear to be normally distributed around the true values. The challenge in identifying true parameter values in $M_{101}$, relative to $M_{011}$, is further highlighted by the existence of a small percentage of simulations for which the {\tt optim} function in R does not successfully converge at the minimum of the negative log likelihood (see convergence rates displayed along the top of the plots in the first column of Figures \ref{fig:fmri:id:M011SNR} and \ref{fig:fmri:id:M011PRR}).

\begin{figure}
\ssp
\centering
\caption{Identifying dynamic intercept model by increasing signal-to-noise ratio} \label{fig:fmri:id:M101SNR}
\includegraphics[width=0.75\textwidth]{1000-250-M101-conv-750-15-1-5-SNR-10-10}
\caption*{Histograms in 1D (for $\phi$, second column) and 2D kernel density estimates (for $\beta$ in first column and $(\sigma^2_s,\sigma^2_m)$ in third column) of MLEs of fits of $M_{101}$ to data simulated from $M_{101}$ with true $\beta = (750,15)'$, $\phi = 0.1$, $\sigma^2_m = 10$, and increasing $\sigma^2_s$ (rows). Blue crosses indicate true values of $\beta$ and $(\sigma^2_s,\sigma^2_s)$ in each of the corresponding image panels, and blue vertical lines indicate the true value of $\phi$.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Identifying dynamic intercept model by increasing autocorrelation} \label{fig:fmri:id:M101PRR}
\includegraphics[width=1.0\textwidth]{1000-250-M101-conv-750-15-PRR-5-1-10-10}
\caption*{Histograms in 1D (for $\phi$, second column) and 2D kernel density estimates (for $\beta$ in first column and $(\sigma^2_s,\sigma^2_m)$ in third column) of MLEs of fits of $M_{101}$ to data simulated from $M_{101}$ with true $\beta = (750,15)'$, $\sigma^2_s = 1$, $\sigma^2_m = 10$, and increasing $\phi$ (rows). Blue crosses indictate the true values of $\beta$ and $(\sigma^2_s,\sigma^2_s)$ in each of the corresponding image panels, and blue vertical lines indicate the true values of $\phi$.}
\end{figure}

Lastly, identification of model parameters in $M_{111}$ appears to be the most challenging. Figure \ref{fig:fmri:id:M111lowb} shows that for fixed $\phi = 0.9$, $\rho = 0.6$, $\sigma^2_b = 1$, and $\sigma^2_m = 10$, increasing the true white noise variance of the dynamic intercept, $\sigma^2_s$, to 15 improves identification of $\sigma^2_m$ while the distributions of MLEs for $\phi$ and $\sigma^2_b$ are skewed and not centered at the true values. On the other hand, if $\sigma^2_b$ is increased to 20 as in Figure \ref{fig:fmri:id:M111highb}, identification of $\phi$ and $\sigma^2_b$ improves with increasing $\sigma^2_s$, but the distribution of MLEs for $\sigma^2_m$ is now skewed and off-center. As with $M_{011}$ and $M_{101}$, $\beta$ appears to be better identified than other model parameters.

\begin{figure}
\ssp
\centering
\caption{Identifying model with both dynamic slope and intercept with small slope variance} \label{fig:fmri:id:M111lowb}
\includegraphics[width=1.0\textwidth]{1000-250-M111-conv-750-15-9-6-SNR-1-10}
\caption*{Histograms in 1D (for $\sigma^2_m$, last column) and 2D kernel density estimates (for $\beta$ in first column, $(\phi,\rho)$ in second column, and $(\sigma^2_s,\sigma^2_m)$ in third column) of MLEs of fits of $M_{111}$ to data simulated from $M_{111}$ with true $\beta = (750,15)'$, $\phi = 0.9$, $\rho = 0.6$, $\sigma^2_b = 1$, $\sigma^2_m = 10$, and increasing $\sigma^2_s$ (rows). Blue crosses indicate true values of $\beta$, $(\phi,\rho)$, and $(\sigma^2_s,\sigma^2_b)$ in each of the corresponding image panels, and blue vertical lines indicate the true value of $\sigma^2_m$.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Identifying model with both dynamic slope and intercept with large slope variance} \label{fig:fmri:id:M111highb}
\includegraphics[width=1.0\textwidth]{1000-250-M111-conv-750-15-9-6-SNR-20-10}
\caption*{Histograms in 1D (for $\sigma^2_m$, last column) and 2D kernel density estimates (for $\beta$ in first column, $(\phi,\rho)$ in second column, and $(\sigma^2_s,\sigma^2_m)$ in third column) of MLEs of fits of $M_{111}$ to data simulated from $M_{111}$ with true $\beta = (750,15)'$, $\phi = 0.9$, $\rho = 0.6$, $\sigma^2_b = 20$, $\sigma^2_m = 10$, and increasing $\sigma^2_s$ (rows). Blue crosses indicate the true values of $\beta$, $(\phi,\rho)$, and $(\sigma^2_s,\sigma^2_b)$ in each of the corresponding image panels, and blue vertical lines indicate the true value of $\sigma^2_m$.}
\end{figure}

Unimodal and elliptical distributions of MLEs for $\beta$ under all three models provides some confidence that we can expect estimates of the regression coefficients to be unbiased. However, when the true autocorrelation and signal-to-noise ratio are low, bimodal or non-normal distributions of MLEs appear for other model parameters, suggesting that inference on $\beta$, and specifically the conclusion of the hypothesis test in equation \eqref{eqn:fmri:hyp}, could be incorrect. Figures \ref{fig:fmri:id:M011SNR} through \ref{fig:fmri:id:M111highb} suggest that out of the three models, $M_{011}$ is the most likely to be well identified for a given set of values for true model parameters, while $M_{111}$ is least likely to be well-identified.

Poor identification of $M_{111}$ is further illustrated by the decrease in the proportion of simulations for which the {\tt optim} function successively converges to the MLEs (see the convergence rates displayed under the plots for $\beta$ in Figures \ref{fig:fmri:id:M111lowb} and \ref{fig:fmri:id:M111highb}). Models with identifiability issues are sometimes characterized by flat likelihoods that can make it difficult to find local maxima using iterative routines.

Identifiability of true model parameters in all three models improves by increasing the length of the simulated time series, $T$, or by simulating with the explanatory variable $u_t \stackrel{iid}{\sim} \mbox{N}(0,1)$, instead of simulating with correlated explanatory variable $\mbox{conv}_t$ (results not shown). Improvement in identifiability when simulating using uncorrelated explanatory variable, compared to simulations with $\mbox{conv}_t$, may be associated with confounding caused by autocorrelation present in both the regression covariate and the error term when $\mbox{conv}_t$ is used \citep{hodges:reich:confound:2010}. However, these are factors that we don't have much control over in fMRI experiments, since increasing the length of fMRI scanning sessions is expensive, and the expected BOLD response from an fMRI experiment typically exhibits autocorrelation due to nature of the hrf. Due to these identifiability concerns, we discard $M_{111}$ at this point and examine only $M_{011}$ and $M_{101}$ in the remainder of this chapter.

\subsection{Fitting word recognition data \label{sec:fmri:mle}}

We now provide results from fitting $M_{101}$ and $M_{011}$ to the word recognition data set, using maximum likelihood estimation. As in Section \ref{sec:fmri:id}, the {\tt dlmMLE} function was used to obtain MLEs for all the fixed parameters in $M_{101}$ and $M_{011}$. In addition, we offer a comparison with standard GLM fits of $M_{001}$ using OLS. That is, we use OLS to fit the model of the form shown in equation \eqref{eqn:dlm:reg:obs} with $U_t = (1, \mbox{conv}_t)$, $\beta = (\beta_0,\beta_1)'$, $F_t = 0$ for all $t$ (making the state equation \eqref{eqn:dlm:reg:state} irrelevant), and $v_t \stackrel{iid}{\sim} \mbox{N}(0,\sigma^2_m)$. OLS estimates are obtained according to equation \eqref{eqn:fmri:ols}, and in this case we let $\hat{\sigma}^2_m = \hat{\sigma}^2$ from equation \eqref{eqn:fmri:ols}. We let $\hat{\theta} = (\hat{\beta}',\hat{\phi},\hat{\sigma}^2_s,\hat{\sigma}^2_m)'$ denote the MLEs of the fixed parameters in $M_{011}$ and $M_{101}$, and $\hat{\theta} = (\hat{\beta}',\hat{\sigma}^2_m)'$ be the MLEs of the fixed parameters in $M_{001}$. All three model were fit with $\mbox{conv}_t$ as the expected BOLD response for the word recognition experiment shown in the middle panel of Figure \ref{fig:fmri:data}.

Figure \ref{fig:fmri:mle:beta} displays two-dimensional kernel density estimates of $\hat{\beta}$ over the 125 voxels from each of the 6 brain regions in Table \ref{tab:fmri:arma} according to each model. These density estimates suggest that significant brain activation is present in all regions except for FP. Also, estimates are relatively consistent across models for all brain regions with the exception of FP, where histograms for $M_{011}$ include a cloud of more active voxels while the other two models don't.

Also apparent from this figure is the bimodal nature of brain activation in SV-left and SV-right. For each model, voxels in these two regions were divided into high and low clusters, denoted by ``Cluster H'' and ``Cluster L'', respectively, using the k-means clustering method \citep{hartigan:wong:kmeans:1979} applied to $\hat{\theta}$. Table \ref{tab:fmri:prop} shows that about 65\% of voxels from these two regions fall into a cluster of higher activation and higher baseline BOLD response, evidenced by the higher regional average values of $\hat{\beta_1}$ and $\hat{\beta_0}$ in Table \ref{tab:fmri:mle:clusters}. The clustering of voxels in these brain regions could provide support for the $M_{011}$ model, since an apparent change in the regression slope over such close space might suggest that a change in the regression slope over time might also be reasonable.

Unlike MLEs for $\beta$, MLEs for $\phi$, $\sigma^2_s$, and $\sigma^2_m$ are not consistent between $M_{011}$ and $M_{101}$. Tables \ref{tab:fmri:mle:means} and \ref{tab:fmri:mle:clusters} show that in IPS-left, IPS-right, and PV, estimates for $\phi$ are, on average, higher under $M_{011}$ than they are under $M_{101}$.  In addition, the average signal-to-noise ratio, $\sigma^2_s / \sigma^2_m$, is estimated to be much higher in these three regions for $M_{101}$. In contrast, average estimates of $\phi$ in SV-left and SV-right are lower under $M_{011}$ than they are under $M_{101}$, and the opposite relationship is true for the average estimates of $\sigma^2_s / \sigma^2_m$. The opposing nature of autocorrelation and signal-to-noise estimates between $M_{101}$ and $M_{011}$ suggests that these models account for variation and autocorrelation in the data differently. What $M_{101}$ models as increased signal-to-noise, $M_{011}$ interprets as increased autocorrelation in the dynamic slope. Conversely, what $M_{011}$ models as increased signal-to-noise, $M_{101}$ interprets as increased autocorrelation in the errors.

%Two-dimensional histograms of $(\hat{\sigma}^2_s,\hat{\sigma}^2_m)$ in Figure \ref{fig:fmri:mle:sigma} also reveal patterns that differ between the two models. In IPS-left, IPS-right, PV, and SV-left, the estimated measurement variance, $\sigma^2_m$, under $M_{101}$ is close to 0 for most voxels. In contrast, voxels fit in these brain regions using $M_{011}$ yield estimates of $\sigma^2_m$ well above 0. In FP and SV-right, histograms for $M_{101}$ show larger values of $\hat{\sigma}^2_m$ and, interesting, the MLEs for $\sigma^2_m$ under $M_{011}$ seem to shrink toward 0.

\begin{figure}
\ssp
\centering
\caption{Kernel density estimates of MLEs of regression coefficients} \label{fig:fmri:mle:beta}
\includegraphics[width=0.6\textwidth]{craig_mle-beta}
\caption*{Two-dimensional kernel density estimates of MLEs for $\beta$ using fMRI data from a word recognition experiment extracted from six brain regions (rows) fit to models $M_{011}$, $M_{101}$, and $M_{001}$ (columns). Blue crosses denote the marginal averages of the MLEs from each brain region, and for each of two clusters in SV-left and SV-right.}
\end{figure}

%\begin{figure}
%\ssp
%\centering
%\caption{Histograms of MLEs for autocorrelation coefficient} \label{fig:fmri:mle:phi}
%\includegraphics[width=0.4\textwidth]{craig_mle-phi}
%\caption*{Histograms if MLEs of $\phi$ for real fMRI data from six brain regions (rows) fitted to dynamic regression models (columns). Blue vertical lines denote the average MLE of $\phi$ from each brain region, and for each of two clusters in SV-left and SV-right.}
%\end{figure}
%
%\begin{figure}
%\ssp
%\centering
%\caption{Histograms of MLEs for state and observation variances} \label{fig:fmri:mle:sigma}
%\includegraphics[width=0.6\textwidth]{craig_mle-sigma}
%\caption*{Two-dimensional histograms of MLEs of $(\sigma^2_s,\sigma^2_m)$ for real fMRI data from six brain regions (rows) fitted to dynamic regression models (columns). Blue X's denote the marginal averages of the MLEs from each brain region, and for each of two clusters in SV-left and SV-right.}
%\end{figure}

\begin{table}
\ssp
\centering
\caption{Average MLEs in single cluster brain regions} \label{tab:fmri:mle:means}
\begin{tabular}{|l|rrrr|}
\hline
Parameter & FP & IPS-left & IPS-right & PV \\
\hline
 & \multicolumn{4}{|c|}{$M_{011}$} \\
\hline
$\beta_0$ & 759.155 & 951.101 & 831.359 & 808.257 \\
$\beta_1$ & 1.395 & 15.009 & 24.894 & 16.492 \\
$\phi$ & 0.736 & 0.853 & 0.871 & 0.832 \\
$\sigma^2_s$ & 8.746 & 27.268 & 53.171 & 70.646 \\
$\sigma^2_m$ & 10.031 & 22.522 & 41.340 & 21.826 \\
\hline
 & \multicolumn{4}{|c|}{$M_{101}$} \\
\hline
$\beta_0$ & 759.875 & 950.038 & 830.901 & 807.434 \\
$\beta_1$ & -1.032 & 18.879 & 26.838 & 21.247 \\
$\phi$ & 0.746 & 0.637 & 0.654 & 0.596 \\
$\sigma^2_s$ & 3.323 & 16.970 & 29.565 & 23.498 \\
$\sigma^2_m$ & 6.105 & 0.534 & 1.382 & 1.727 \\
\hline
 & \multicolumn{4}{|c|}{$M_{001}$} \\
\hline
$\beta_0$ & 759.204 & 950.773 & 831.191 & 807.846 \\
$\beta_1$ & -1.448 & 16.087 & 24.688 & 19.039 \\
$\sigma^2_m$ & 12.480 & 29.579 & 54.511 & 37.629 \\
\hline
\end{tabular}
\caption*{Average MLEs calculated marginally for each fixed parameter (rows) using fMRI data from a word recognition experiment extracted from four different brain regions (columns) based on fitting models $M_{011}$, $M_{101}$, and $M_{001}$ (embedded tables).}
\end{table}

\begin{table}
\ssp
\centering
\caption{Average MLEs in bi-cluster brain regions} \label{tab:fmri:mle:clusters}
\begin{tabular}{|l|rr|rr|}
\hline
Parameter & \multicolumn{2}{|c|}{SV-left} & \multicolumn{2}{|c|}{SV-right} \\
\hline
 & Cluster H & Cluster L & Cluster H & Cluster L \\
\hline
 & \multicolumn{4}{|c|}{$M_{011}$} \\
\hline
$\beta_0$ & 874.999 & 363.601 & 697.816 & 308.080 \\
$\beta_1$ & 23.133 & 12.203 & 21.767 & 9.415 \\
$\phi$ & 0.566 & 0.520 & 0.489 & 0.630 \\
$\sigma^2_s$ & 11.475 & 4.378 & 13.162 & 4.889 \\
$\sigma^2_m$ & 0.502 & 0.393 & 2.423 & 3.906 \\
\hline
 & \multicolumn{4}{|c|}{$M_{101}$} \\
\hline
$\beta_0$ & 875.319 & 362.054 & 698.025 & 307.655 \\
$\beta_1$ & 20.009 & 11.708 & 13.883 & 9.361 \\
$\phi$ & 0.821 & 0.761 & 0.979 & 0.864 \\
$\sigma^2_s$ & 11.941 & 7.986 & 1.727 & 7.427 \\
$\sigma^2_m$ & 14.116 & 4.953 & 16.345 & 8.719 \\
\hline
 & \multicolumn{4}{|c|}{$M_{001}$} \\
\hline
$\beta_0$ & 875.084 & 361.957 & 697.769 & 307.538 \\
$\beta_1$ & 22.414 & 12.135 & 21.723 & 10.168 \\
$\sigma^2_m$ & 17.409 & 6.332 & 19.450 & 11.108 \\
\hline
\end{tabular}
\caption*{Average MLEs calculated marginally for each fixed parameter (rows) using fMRI data from a word recognition experiment extracted from each cluster of secondary visual left and secondary visual right (columns) fit to dynamic regression models (embedded tables).}
\end{table}

\begin{table}
\ssp
\centering
\caption{Proportion of voxels with high activation} \label{tab:fmri:prop}
\begin{tabular}{|c|cc|}
\hline
Model & SV-left & SV-right \\
\hline
$M_{011}$ & 0.672 & 0.648 \\
$M_{101}$ & 0.677 & 0.648 \\
$M_{001}$ & 0.672 & 0.648 \\
\hline
\end{tabular}
\caption*{Proportion of voxels in each of secondary visual left and right (columns) classified into high activation cluster after applying the k-means clustering algorithm to MLEs of $\theta$ under each model (rows).}
\end{table}

\section{Comparing dynamic regression models using particle learning \label{sec:fmri:pl}}

In the previous section, we explored fits of $M_{011}$, $M_{101}$, and $M_{001}$ to the word recognition data using maximum likelihood estimation. In this section, we investigate the relative appropriateness of these models for the data using an SMC model comparison strategy. Results in Chapter \ref{ch:comp} showed that the performance of PL is superior to the RM and KDPF in terms of efficiently and accurately estimating the marginal likelihood and posterior model probabilities within the context of the local level DLM with common state and observation variance factor. Since the dynamic regression models we consider for fMRI data admit tractable forms of the distributions needed to implement the PL, we use this algorithm to compare models in this section.

In Section \ref{sec:pl}, we described a PL scheme to estimate the filtered distributions of states and unknown fixed parameters in $M_{011}$ (letting $F_t = \mbox{conv}_t$) and $M_{101}$ (letting $F_t = 1$). Using this algorithm, we also have a way of estimating the marginal likelihood of the data through equation \eqref{eqn:onestep:pf}. For $M_{001}$, an exact form of the marginal likelihood is available \citep{ohagan:bayes:1994}, given by
\begin{equation}
p(y_{1:T}) = \frac{1}{(2\pi)^{T/2}}\sqrt{\frac{|B_0^{-1}|}{|B_T^{-1}|}}\left(\frac{(b_{m_0})^{a_{m_0}}}{(b_{m_T})^{a_{m_T}}}\right)\left(\frac{\Gamma(a_{m_T})}{\Gamma(a_{m_0})}\right), \label{eqn:ols:marglik}
\end{equation}
where
\begin{align}
B_T &= (X'X + B_0^{-1})^{-1} &\quad \vartheta_T &= B_T(X'y + B_0^{-1}\vartheta_0) \label{eqn:bayesreg} \\
a_{m_T} &= a_{m_0} + T/2 &\quad b_{m_T} &= b_{m_0} + \frac{1}{2}(y'y + \vartheta_0'B_0^{-1}\vartheta_0 - \vartheta_T'B_T^{-1}\vartheta_T), \nonumber
\end{align}
and $\vartheta_0$, $B_0$, $a_{m_0}$, and $b_{m_0}$ are prior hyperparameters that are assumed known (see equation \ref{eqn:dynreg:prior1}). In equation \eqref{eqn:bayesreg}, $y$ and $X$ are the data vector and design matrix, respectively, as defined in equation \eqref{eqn:fmri:ols}. Given the exact marginal likelihood of the data under $M_{001}$, and approximations to the marginal likelihood under $M_{101}$ and $M_{011}$, relative posterior model probabilities among the three models can be computed according to equation \eqref{eqn:modelcomp}.

In order to implement PL on fMRI time series data from a single voxel, we need to specify the prior distribution, $p(x_0,\theta)$, and the number of particles to use in the particle filter. For all three models under consideration, we use a prior of the form given by equations \eqref{eqn:dynreg:prior1} and \eqref{eqn:dynreg:prior2}, i.e. $p(x_0, \theta) = p(\beta|\sigma^2_m)p(\sigma^2_m)p(\phi|\sigma^2_s)p(\sigma^2_s)\delta_0(x_0)$ with
\begin{align}
&\beta|\sigma^2_m \sim \mbox{N}(\vartheta_0, \sigma^2_mB_0) \qquad \sigma^2_m \sim \mbox{IG}(a_{m_0}, b_{m_0}) \label{eqn:fmri:pl:prior1} \\
&\phi|\sigma^2_s \sim \mbox{N}(\varphi_0, \sigma^2_s\Phi_0) \qquad \sigma^2_s \sim \mbox{IG}(a_{s_0}, b_{s_0}). \label{eqn:fmri:pl:prior2}
\end{align}
For $M_{001}$, only equation \eqref{eqn:fmri:pl:prior1} is needed (since $\phi = \sigma^2_s = 0$). The hyperparameters $\vartheta_0$, $B_0$, $\varphi_0$, $\Phi_0$, $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ are assumed known, and we let $B_0$ and $\Phi_0$ take the form
\begin{equation}
B_0 = \kappa^2 \left(\begin{array}{cc} 1000 & 0 \\ 0 & 225 \end{array}\right) \quad \Phi_0 = \kappa^2\times0.25. \label{eqn:fmri:kappa}
\end{equation}
We let $\kappa = 1$ in Sections \ref{sec:fmri:sim} and \ref{sec:fmri:real}, but let $\kappa > 0$ in Section \ref{sec:fmri:dist} to examine the sensitivity of the marginal likelihood of the data to more diffuse priors.

%In Section \ref{sec:fmri:sim}, we use PL to estimate unknown states and fixed parameters in dynamic regression models using simulated data. In this case, we let the hyperparameters $b_0$ and $\varphi_0$ be equal to the true values of $\beta$ and $\phi$ used for simulation, respectively. The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ are set such that the means of the priors on $\sigma^2_s$ and $\sigma^2_m$ are equal to their respective true values used for simulation and the variances are both equal to $\kappa^2\times500$. We let $\kappa = 1$ in this section, but then compare the sensitivity of marginal likelihood estimates to more diffuse priors by increasing $\kappa$ in Section \ref{sec:fmri:dist}.
%
%In Section \ref{sec:fmri:dist}, we let $b_0$ and $\varphi_0$ be equal to the MLEs of $\beta$ and $\phi$, respectively, for the specific voxel that is being analyzed. Similarly, the inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ are set such that the means of the priors on $\sigma^2_s$ and $\sigma^2_m$ are equal to their respective MLEs for the specific voxel being analyzed and the variances are both equal to $\kappa^2\times500$. While this can be seen as using the data twice, we specify priors in this way in this section only in order to produce a fair model comparison among $M_{011}$, $M_{101}$, and $M_{001}$.
%
%In Section \ref{sec:fmri:real}, we analyze voxel-wise time series from the word recognition data set. When analyzing data from a specific voxel, we let $b_0$ and $\varphi_0$ be equal to the average MLE for $\beta$ and $\phi$, respectively, among voxels in the same brain region (as given in Table \ref{tab:fmri:mle:means}). For voxels in SV-left or SV-right, $b_0$ and $\varphi_0$ are set to the average values of $\hat{\beta}$ and $\hat{\phi}$ among voxels in the same cluster (as given in Table \ref{tab:fmri:mle:clusters}). The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ are set such that the mean of the priors on $\sigma^2_s$ and $\sigma^2_m$ are equal to their respective the average MLEs in Tables \ref{tab:fmri:mle:means} and \ref{tab:fmri:mle:clusters} and the variances are both equal to $\kappa^2\times500$.

\subsection{Analyzing simulated fMRI data using particle learning \label{sec:fmri:sim}}

In this section, we simulate data from each of $M_{011}$ and $M_{101}$, and we test the PL algorithm by running it under the true model for increasing number of particles. Based on the resulting particle samples, we obtain estimates of the filtered distributions of the dynamic regression coefficients and fixed parameters. Specifically, we compare sequential 95\% credible intervals for unknown states and fixed parameters obtained from PL with those from running the MCMC algorithm described in Section \ref{sec:mcmc:dr}.

Time series of length $T = 250$ were simulated from both models with true fixed parameter values set to $\beta = (750,15)'$, $\phi = 0.95$, $\sigma^2_s = 10$, and $\sigma^2_m = 10$. The same $\mbox{conv}_t$ generated from the simulated rapid event-design illustrated in Figure \ref{fig:fmri:design} was used as the regression covariate. The simulated time series, $y_t$, and the simulated change in the regression slope, $x_t$, from $M_{011}$ are pictured in Figure \ref{fig:fmri:sim}. Notice from this figure that $y_t$ mirrors the convolution function better at TRs where $x_t$ is high, since higher values of the dynamic slope amplify the signal in the data relative to the noise.

For both PL and MCMC, the prior distribution on the initial state and fixed parameters were specified according to equations \eqref{eqn:fmri:pl:prior1} and \eqref{eqn:fmri:pl:prior2} with $\kappa = 1$. We let the hyperparameters $b_0$ and $\varphi_0$ be equal to the true values of $\beta$ and $\phi$ used for simulation, respectively. The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ were set such that the prior means for each of $\sigma^2_s$ and $\sigma^2_m$ were equal to their respective true values used for simulation, and such that each prior variance was equal to $\kappa^2\times500$.

\begin{figure}
\ssp
\centering
\caption{Simulated fMRI data from dynamic slope model} \label{fig:fmri:sim}
\includegraphics[width=1.0\textwidth]{fmri-ar-sim-750-15-95-10-10-M101}
\caption*{Simulated fMRI time series $y_t$ (top) from $M_{011}$ with $\beta = (750,15)'$, $\phi = 0.95$, $\sigma^2_s = 10$, and $\sigma^2_m = 10$. Convolution of the hrf and neural activation pattern $\mbox{conv}_t$ and simulated change in dynamic slope ($x_t$) are displayed in the middle and bottom panels, respectively.}
\end{figure}

We ran the PL algorithm under the true model on time series simulated from both models using 500, 1000, 5000, 10000, and 20000 particles. In addition, we ran three MCMC chains for each simulation under the true model using the same priors. For each chain, initial values of $\beta_0$, $\beta_1$, $\phi$ were set to 0 and initial values for $\sigma^2_s$ and $\sigma^2_m$ were set to 1. Initial values of the states, $x_t$ for $t = 0,1,\ldots,T$, were drawn from a standard normal distribution. Twenty-five thousand iterations were run for each chain including a burn-in period of 5000 iterations, and every 20th iteration was saved.

The results for $M_{011}$ shown in Figure \ref{fig:fmri:quant:M011} indicate that the filtered distributions of the fixed parameters and dynamic slope estimated by PL seem to have converged if at least 10000 particles are used. In addition, the filtered distributions at time $t = T = 250$ appear to agree with the MCMC estimates for the dynamic slope and each fixed parameter. MCMC estimates can only be compared with PL at $t = T$ since MCMC provides smoothed estimates of the dynamic slope and fixed parameters for $t < T$, while PL provides only filtered estimates. Analagous plots for the data simulated from $M_{101}$ (Figure \ref{fig:fmri:quant:M101}) show similar results for the dynamic intercept and fixed parameters in $M_{101}$.

\begin{figure}
\ssp
\centering
\caption{Credible intervals from PL compared with MCMC for simulated fMRI data} \label{fig:fmri:quant:M011}
\includegraphics[width=1.0\textwidth]{fmri_pl_quant-M101-M101-560-1-1-FALSE-FALSE-FALSE}
\caption*{Sequential 95\% credible intervals for the dynamic slope (top left) and fixed parameters (other panels) in $M_{011}$ using PL with increasing number of particles (colors) compared with MCMC (black crosses, only displayed for $T = 250$ since MCMC was run using entire data set) run on simulated data of length $T = 250$ from $M_{011}$ with true $\beta = (750,15)'$, $\phi = 0.95$, $\sigma^2_s = 10$, and $\sigma^2_m = 10$ (displayed above top middle panel). The true values of fixed parameters used for simulation and the true simulated dynamic slopes are represented by gray lines/curves, respectively. Credible interval estimates from MCMC are displayed only for $\beta_1 + x_T$ and for each of the fixed parameters conditional on all the data ($T = 250$). The same prior distributions on the initial state and fixed parameters were used for running both PL and MCMC, with $p(x_0) = \delta_{0}(x_0)$, $b_0$ and $\phi_0$ set to the true $\beta$ and $\phi$, respectively, and the remaining hyperparameters displayed above the top left and right panels.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Credible intervals from PL compared with MCMC for simulated fMRI data} \label{fig:fmri:quant:M101}
\includegraphics[width=1.0\textwidth]{fmri_pl_quant-M011-M011-560-1-1-FALSE-FALSE-FALSE}
\caption*{Sequential 95\% credible intervals for the dynamic intercept (top left) and fixed parameters (other panels) in $M_{101}$ using PL with increasing number of particles (colors) compared with MCMC (black crosses, only displayed for $T = 250$ since MCMC was run using entire data set) run on simulated data from $M_{101}$ with $\beta = (750,15)'$, $\phi = 0.95$, $\sigma^2_s = 10$, and $\sigma^2_m = 10$ (displayed above top middle panel). The true values of fixed parameters used for simulation and the true simulated dynamic slopes are represented by gray lines/curves, respectively. Credible interval estimates from MCMC are displayed only for $\beta_0 + x_T$ and for each of the fixed parameters conditional on all the data ($T = 250$). The same prior distributions on the initial state and fixed parameters were used for running both PL and MCMC, with $p(x_0) = \delta_{0}(x_0)$, $b_0$ and $\phi_0$ set to the true $\beta$ and $\phi$, respectively, and the remaining hyperparameters displayed above the top left and right panels.}
\end{figure}

\subsection{Distinguishing dynamic regression models using particle learning \label{sec:fmri:dist}}

The results from the previous section indicate that stable estimates of dynamic regression coefficients and fixed parameters can be obtained by PL if enough particles are used. We now examine estimation of the marginal likelihood using PL. In particular, we are interested in gaining understanding about the parameter settings under which the true model can be distinguished amongst $M_{011}$, $M_{101}$, and $M_{001}$ by looking at the marginal likelihood.

To study this, we simulated time series of length $T = 250$ from both $M_{011}$ and $M_{101}$ with the same convolution function used in the previous section, $\beta = (750,15)'$, and various values of $\phi$, $\sigma^2_s$, and $\sigma^2_m$. Specifically, we simulated time series for all combinations of $\phi \in \{0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95,0.99\}$, $\sigma^2_s \in \{1,2,3,4,5,10,15,20\}$, and $\sigma^2_m = 10$. We then ran the PL algorithm, under both $M_{011}$ and $M_{101}$, three times on each simulated time series using 500 particles. The prior hyperparameters $B_0$ and $\Phi_0$ were specified by letting $\kappa = 1$ in equation \eqref{eqn:fmri:kappa}. For each simulation, we calculated the MLEs of the unknown fixed parameters using {\tt dlmMLE}, as in Section \ref{sec:fmri:dr}, prior to running the PL, and we let the hyperparameters $b_0$ and $\varphi_0$ be equal to the MLEs of $\beta$ and $\phi$, respectively. The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ were set such that the prior means for each of $\sigma^2_s$ and $\sigma^2_m$ were equal to their respective MLEs, and such that each prior variance was equal to $\kappa^2\times500$. The marginal likelihood is sensitive to specification of the prior distribution, as we discuss further in Section \ref{sec:fmri:kappa}. While setting priors in this way can be construed as data snooping, we do this in an attempt to limit the influence of the prior on comparison of the three models via the marginal likelihood.

Some PL runs suffered from numerical instability caused by values of the conditional likelihood, $p(y_t|x_t,\theta)$, being too low to be evaluated for some particles. For each PL run that did not encounter this issue, we computed estimates of the log marginal likelihood. In addition, we computed the exact log marginal likelihood under $M_{001}$ for each simulated time series using equation \eqref{eqn:ols:marglik}.

Figures \ref{fig:fmri:phi:M011} and \ref{fig:fmri:phi:M101} show the results for the data simulated from $M_{011}$ and $M_{101}$, respectively. Both figures indicate that the log marginal likelihood under the true data-generating model is larger than the log marginal likelihood under the other models provided the true $\phi$ and signal-to-noise ratio, $\sigma^2_s/\sigma^2_m$, are large enough. However, it appears more difficult to identify $M_{101}$ as the true model than it does for $M_{011}$. For example, when the true model is $M_{011}$ and the true signal-to-noise ratio is 1.5, 2, or 2.5 (bottom row of Figure \ref{fig:fmri:phi:M011}), the log marginal likelihood obtained from each PL run under $M_{011}$ is larger than those obtained from all PL runs under the other models for any $\phi \ge 0.1$. In contrast, when the true signal-to-noise ratio under $M_{101}$ is 1.5, 2, or 2.5 (bottom row of Figure \ref{fig:fmri:phi:M101}), $\phi \ge 0.6$ is required for all log marginal likelihoods obtained from PL runs under $M_{101}$ to be larger than those obtained for all PL runs with 500 particles under the other models.

\begin{figure}
\ssp
\centering
\caption{Distinguishing the dynamic slope model from the dynamic intercept and simple linear regression models} \label{fig:fmri:phi:M011}
\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-M101-1-500-phi-496-594-1}
\caption*{Log marginal likelihoods of data simulated from $M_{011}$ with $\beta=(750,15)$, $\sigma^2_m = 10$, increasing $\phi$ (x-axis) and increasing $\sigma^2_s$ (plot panels) under $M_{011}$ (black lines), $M_{101}$ (red lines), and $M_{001}$ (blue lines). Log marginal likelihoods from three independent PL runs with 500 particles under each model for each simulation are displayed by colored points. When running the PL, prior hyperparameters $B_0$ and $\Phi_0$ were specified by equation \eqref{eqn:fmri:kappa} with $\kappa = 1$, and $b_0$ and $\varphi_0$ were set to the MLEs of $\beta$ and $\phi$, respectively. The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ were set such that the prior means for each of $\sigma^2_s$ and $\sigma^2_m$ were equal to their respective MLEs, and such that each prior variance was equal to $500$. Points are not displayed for PL runs that did not complete due to numerical instability.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Distinguishing the dynamic intercept model from the dynamic slope and simple linear regression models} \label{fig:fmri:phi:M101}
\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-M011-1-500-phi-496-594-1}
\caption*{Log marginal likelihoods of data simulated from $M_{101}$ with $\beta=(750,15)$, $\sigma^2_m = 10$, increasing $\phi$ (x-axis) and increasing $\sigma^2_s$ (plot panels) under $M_{011}$ (black lines), $M_{101}$ (red lines), and $M_{001}$ (blue lines). Log marginal likelihoods from three independent PL runs with 500 particles under each model for each simulation are displayed by colored points. When running the PL, prior hyperparameters $B_0$ and $\Phi_0$ were specified by equation \eqref{eqn:fmri:kappa} with $\kappa = 1$, and $b_0$ and $\varphi_0$ were set to the MLEs of $\beta$ and $\phi$, respectively. The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ were set such that the prior means for each of $\sigma^2_s$ and $\sigma^2_m$ were equal to their respective MLEs, and such that each prior variance was equal to $500$. Points are not displayed for PL runs that did not complete due to numerical instability.}
\end{figure}

\subsection{Sensitivity of the marginal likelihood to priors \label{sec:fmri:kappa}}

It is important to understand that comparing models in terms of the log marginal likelihood, as in Figures \ref{fig:fmri:phi:M011} and \ref{fig:fmri:phi:M101}, is sensitive to the specified prior distribution on the initial state and fixed parameters. This is because the marginal likelihood is computed by integrating out the states and fixed parameters from the joint likelihood, i.e.
\begin{equation}
p(y_{1:T}) = \int_{\theta} \int_{x_0} \int_{x_1} \cdots \int_{x_T} \prod_{t=1}^T\left(p(y_t|x_t,\theta)p(x_t|x_{t-1},\theta)\right)p(x_0,\theta)\mbox{d}x_{0:T}\mbox{d}\theta. \label{eqn:int:marg}
\end{equation}
Thus, if $p(x_0,\theta)$ is diffuse relative to the joint posterior, $p(x_{0:T},\theta|y_{1:T})$, $p(y_{1:T})$ will be much smaller than it would be for $p(x_0,\theta)$ that is more concentrated around $p(x_{0:T},\theta|y_{1:T})$.

To examine the sensitivity of comparing $M_{011}$, $M_{101}$, and $M_{001}$ to specified priors of the form given by equations \eqref{eqn:fmri:pl:prior1} and \eqref{eqn:fmri:pl:prior2}, we simulated two more time series under both $M_{011}$ and $M_{101}$ for each set of fixed parameter values. Then, we ran the PL algorithm three times under the true data-generating model using $\kappa = 5$ and 500 particles for each of the now three total simulations generated using each set of true fixed parameter values (remaining prior hyperparameters were set based on the MLEs as in Section \ref{sec:fmri:dist}). This process was then repeated for $\kappa = 10$ and $\kappa = 15$. The goal here is that we want to examine the effect of increasing $\kappa$ on which true values of $\phi$ and $\sigma^2_s / \sigma^2_m$ would be required for the log marginal likelihoods obtained from all three PL runs under the true data-generating model to be higher than the log marginal likelihoods obtained from all three PL runs under the non-true dynamic regression model (either $M_{011}$ or $M_{101}$) and analytical estimate of the log marginal likelihood under $M_{011}$ with $\kappa = 1$. For example, for running the PL under $M_{011}$ with $\kappa = 1$ on data simulated from the same model with true $\sigma^2_s / \sigma^2_m = 1$, a true value of $\phi \ge 0.7$ is required for the log marginal likelihoods obtained from all three PL runs to be higher than those obtained from all PL runs under the other models (see plot in the second row and third column of Figure \ref{fig:fmri:phi:M011}).

Theoretically, we should be able to increase $\kappa$ to the point that the marginal likelihood of the true model is lower than that of the other models regardless of the true values of $\phi$ and $\sigma^2_s / \sigma^2_m$. Figures \ref{fig:fmri:kappa:M011} and \ref{fig:fmri:kappa:M101} illustrate this point. In Figure \ref{fig:fmri:kappa:M011}, it is clear that as $\kappa$ is increased, larger true values of $\phi$ and $\sigma^2_s / \sigma^2_m$ are required to identify $M_{011}$ as the true model. This phenomenon is even more pronounced when considering $M_{101}$ as the true model, as in Figure \ref{fig:fmri:kappa:M101}. For example, when $\kappa = 15$, the true lag-1 autocorrelation in the data must be at least 0.8 to identify $M_{101}$ as the true model, regardless of how large the signal-to-noise ratio is.

We use a prior of the form given by equations \eqref{eqn:fmri:pl:prior1} and \eqref{eqn:fmri:pl:prior2} with $\kappa = 1$ for the remainder of this chapter, since this prior seems reasonable given the distributions of the MLEs of fixed parameters examined in Section \ref{sec:fmri:mle} and, given the results in Figures \ref{fig:fmri:kappa:M011} and \ref{fig:fmri:kappa:M101}, provides the best chance of identifying a true model amongst $M_{011}$, $M_{101}$, and $M_{001}$. Briefly, setting $\kappa = 1$ assumes a prior standard deviation of 100 for the regression intercept and 15 for the regression slope. MLEs for $\beta$ from fitting these dynamic regression models to time series from voxels taken from the word recognition data set, displayed via two-dimensional kernel density estimates in Figure \ref{fig:fmri:mle:beta}, appear to be within 2 prior standard deviations (with $\kappa = 1$) of the average MLE of their respective regions or clusters displayed in Tables \ref{tab:fmri:mle:means} and \ref{tab:fmri:mle:clusters}. Similarly, most MLEs for $\phi$, $\sigma^2_s$, and $\sigma^2_m$ (not shown) fall within two standard deviations of their respective region or cluster averages.

% Furthermore, most of the MLEs for $\phi$ and $\sigma^2_s / \sigma^2_m$ calculated in Tables \ref{tab:fmri:mle:means} and \ref{tab:fmri:mle:clusters} are above the values required to identify $M_{011}$ or $M_{101}$ as the true model, as indicated by the top left plots of Figures \ref{fig:fmri:kappa:M011} and \ref{fig:fmri:kappa:M101}. From this perspective, it also encouraging that a decrease in the average MLEs of $\sigma^2_s / \sigma^2_m$ shown in Tables \ref{tab:fmri:mle:means} and \ref{tab:fmri:mle:clusters} is often accompanied by an increase in the the MLE of $\phi$ in the corresponding brain region.

\begin{figure}
\ssp
\centering
\caption{Distinguishing the true dynamic slope model $M_{011}$ from the dynamic intercept and simple linear regression models with increasing prior variance} \label{fig:fmri:kappa:M011}
\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-phiSNR-M101-3-500-496-594-1-5-10-15}
\caption*{Minimum values of $\phi \in \{0.1,0.2,\ldots,0.9,0.95,0.99\}$ (y-axis) for which the log marginal likelihood estimates under $M_{011}$ (obtained from three independent PL runs with 500 particles on data simulated from $M_{011}$) with $\beta = (750,15)'$, $\sigma^2_m = 10$, and fixed $\sigma^2_s \in \{0.1,0.2,\ldots,0.5,1.0,1.5,2.0,2.5\}$ (x-axis) each exceed all the log marginal likelihood estimates from the three PL runs on the same data under $M_{101}$, and also exceed the analytical estimates of the log marginal likelihood under $M_{001}$. Each panel corresponds to one of four increasing $\kappa$ values (where $\kappa$ partially determines the prior hyperparameters under $M_{011}$ - as described further in Section \ref{sec:fmri:dist} and equation \eqref{eqn:fmri:kappa}). Results are shown for three separate sets of simulations from $M_{011}$, where each set consists of simulated time series under all combinations of the aforementioned fixed parameter values. Prior hyperparameters under $M_{101}$ and $M_{001}$ were set as described in Section \ref{sec:fmri:dist} with $\kappa = 1$. If there exists no value of $\phi$ for which $M_{011}$ is distinguished from $M_{101}$ and $M_{001}$ for fixed $\sigma^2_s / \sigma^2_m$ within a given set of simulations, no point is plotted for that value of $\sigma^2_s / \sigma^2_m$.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Distinguishing the true dynamic intercept model $M_{101}$ from the dynamic slope and simple linear regression models with increasing prior variance} \label{fig:fmri:kappa:M101}
\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-phiSNR-M011-3-500-496-594-1-5-10-15}
\caption*{Minimum values of $\phi \in \{0.1,0.2,\ldots,0.9,0.95,0.99\}$ (y-axis) for which the log marginal likelihood estimates under $M_{101}$ (obtained from three independent PL runs with 500 particles on data simulated from $M_{101}$) with $\beta = (750,15)'$, $\sigma^2_m = 10$, and fixed $\sigma^2_s \in \{0.1,0.2,\ldots,0.5,1.0,1.5,2.0,2.5\}$ (x-axis) each exceed all the log marginal likelihood estimates from the three PL runs on the same data under $M_{011}$, and also exceed the analytical estimates of the log marginal likelihood under $M_{001}$.
Each panel corresponds to one of four increasing $\kappa$ values (where $\kappa$ partially determines the prior hyperparameters under $M_{101}$ - as described further in Section \ref{sec:fmri:dist} and equation \eqref{eqn:fmri:kappa}). Results are shown for three
separate sets of simulations from $M_{101}$, where each set consists of simulated time series under all combinations of the aforementioned fixed parameter values. Prior hyperparameters under $M_{011}$ and $M_{001}$ were set as described in Section \ref{sec:fmri:dist} with $\kappa = 1$. If there exists no value of $\phi$ for which $M_{101}$ is distinguished from $M_{011}$ and $M_{001}$ for fixed $\sigma^2_s / \sigma^2_m$ within a given set of simulations, no point is plotted for that value of $\sigma^2_s / \sigma^2_m$.}
\end{figure}

\subsection{Comparing posterior model probabilities using simulated fMRI data \label{sec:fmri:part}}

Our final analysis using simulated data is aimed at determining how many particles are needed when running the PL algorithm to accurately estimate relative posterior model probabilities among $M_{011}$, $M_{101}$, and $M_{001}$. This should depend on how different the marginal likelihoods are among the three models. For instance, if the marginal likelihood of the data under one of the models is large relative to the marginal likelihoods under the others, the posterior probability is likely to be 1 for that model and 0 for the others,  even if the estimate of the marginal likelihood is highly variable. For this reason, we consider a ``worst'' case scenario, i.e. time series simulated from each of $M_{011}$ and $M_{101}$ with true fixed parameter values set such that it is difficult to distinguish the true model from among $M_{011}$, $M_{101}$, and $M_{001}$. Using Figures \ref{fig:fmri:phi:M011} and \ref{fig:fmri:phi:M101} as a guide, we simulate time series from each of $M_{011}$ and $M_{101}$ using the following true fixed parameter values:
\begin{align}
M_{011}: \beta = (750,15)' \quad \phi = 0.3 \quad \sigma^2_s = 1 \quad \sigma^2_m = 10 \label{eqn:fmri:sim:M011} \\
M_{101}: \beta = (750,15)' \quad \phi = 0.5 \quad \sigma^2_s = 1 \quad \sigma^2_m = 10 \label{eqn:fmri:sim:M101}
\end{align}

The PL algorithm was run twenty times under both $M_{011}$ and $M_{101}$ on each simulated time series using 500, 1000, 5000, and 10000 particles. Again, we specify prior hyperparameters based on the MLEs as described in Sections \ref{sec:fmri:dist} and \ref{sec:fmri:kappa} with $\kappa = 1$. By grouping together a single log marginal likelihood approximation (based on a single PL run) under $M_{101}$, a single log marginal likelihood approximation under $M_{011}$, and an exact marginal likelihood under $M_{001}$ calculated according to equation \eqref{eqn:ols:marglik}, a set of approximate posterior probabilities among the three models can be calculated according to equation \eqref{eqn:modelcomp} with prior model probabilities equal to 1/3 for each model. For each of the given number of particles, twenty such sets of approximate posterior model probabilities were calculated using the log marginal likelihood approximations based on the twenty PL runs under each model.

The results are displayed in Figure \ref{fig:fmri:comp:M011} using compositional plots. Notice that the estimates of the posterior model probabilities become less variable with increasing number of particles used in the PL, evidenced by the points in the compositional plots in Figure \ref{fig:fmri:comp:M011} clustering together in panels with higher number of particles. In addition, the points cluster near the middle of the ternary diagrams, suggesting that the three models considered are equally likely given the data. This is to be expected, since we purposely chose true values of the fixed parameters (particularly $\phi$) for simulation such that correctly identifying $M_{011}$ as the true model would be difficult. Based on these figures, we suggest that at least 5000 particles be used when running the PL under these models in order to obtain stable estimates of posterior model probabilities.

%\begin{figure}
%\ssp
%\centering
%\caption{Log marginal likelihoods of data simulated from dynamic slope model with increasing particles in PL} \label{fig:fmri:loglik:M011}
%\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-M101-498-1}
%\caption*{Kernel density approximation to the distribution of 20 log marginal likelihood estimates for $M_{011}$ (black lines) and $M_{101}$ (red lines) along with true log marginal likelihood of $M_{001}$ (blue vertical lines) using PL with increasing number of particles (plot panels) on simulated data from $M_{011}$ with $\beta = (750,15)'$, $\phi = 0.3$, $\sigma^2_s = 1$, and $\sigma^2_m = 10$.}
%\end{figure}
%
%, and another simulated time series from $M_{101}$ with $\beta = (750,15)'$, $\phi = 0.5$, $\sigma^2_s = 1$, and $\sigma^2_m = 10$.
%
%\begin{figure}
%\ssp
%\centering
%\caption{Log marginal likelihoods of data simulated from dynamic intercept model with increasing particles in PL} \label{fig:fmri:loglik:M101}
%\includegraphics[width=1.0\textwidth]{fmri_pl_loglik-M011-500-1}
%\caption*{Kernel density approximation to the distribution of 20 log marginal likelihood estimates for $M_{011}$ (black lines) and $M_{101}$ (red lines) along with true log marginal likelihood of $M_{001}$ (blue vertical lines) using PL with increasing number of particles (plot panels) on simulated data from $M_{101}$ with $\beta = (750,15)'$, $\phi = 0.5$, $\sigma^2_s = 1$, and $\sigma^2_m = 10$.}
%\end{figure}

\begin{figure}
\ssp
\centering
\caption{Ternary diagrams of posterior model probabilities for simulated fMRI data from dynamic slope model} \label{fig:fmri:comp:M011}
\includegraphics[width=1.0\textwidth]{fmri_pl_comp-M101-498-1}
\caption*{Posterior model probabilities among $M_{011}$, $M_{101}$, and $M_{001}$ (corners of triangles) estimated for each of twenty runs of the PL under each model for increasing number of particles (plot panels) on data simulated from $M_{011}$ with $\beta = (750,15)'$, $\phi = 0.3$, $\sigma^2_s = 1$, and $\sigma^2_m = 10$. Each point represents a set of posterior probabilities (one for each model), and the proximity of the point to a particular corner of the triangle represents the posterior probability of the model in that corner relative to the other models. The prior distribution $p(x_0,\theta)$ used in the PL runs is given by equations \eqref{eqn:fmri:pl:prior1}, \eqref{eqn:fmri:pl:prior2}, and \eqref{eqn:fmri:kappa} with $\kappa = 1$ and $b_0$, $\varphi_0$, $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ set based on the MLEs as described in Section \ref{sec:fmri:dist}.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Ternary diagrams of posterior model probabilities for simulated fMRI data from dynamic intercept model} \label{fig:fmri:comp:M101}
\includegraphics[width=1.0\textwidth]{fmri_pl_comp-M011-500-1}
\caption*{Posterior model probabilities among $M_{011}$, $M_{101}$, and $M_{001}$ (corners of triangles) estimated for each of twenty runs of the PL under each of the models for increasing number of particles (plot panels) on data simulated from $M_{101}$ with $\beta = (750,15)'$, $\phi = 0.5$, $\sigma^2_s = 1$, and $\sigma^2_m = 10$. Each point represents a set of posterior probabilities (one for each model), and the proximity of the point to a particular corner of the triangle represents the posterior probability of the model in that corner relative to the other models. The prior distribution $p(x_0,\theta)$ used in the PL runs is given by equations \eqref{eqn:fmri:pl:prior1}, \eqref{eqn:fmri:pl:prior2}, and \eqref{eqn:fmri:kappa} with $\kappa = 1$ and $b_0$, $\varphi_0$, $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ set based on the MLEs as described in Section \ref{sec:fmri:dist}.}
\end{figure}

\subsection{Comparing models for word recognition data using particle learning \label{sec:fmri:real}}

In this section, we examine results from running the PL algorithm on actual fMRI data generated from the word recognition experiment described in Section \ref{sec:fmri:data}. We ran the PL algorithm using 5000 particles under each of $M_{011}$ and $M_{101}$ on time series from every voxel in our study (750 total). As in Sections \ref{sec:fmri:dist}, \ref{sec:fmri:kappa}, and \ref{sec:fmri:part}, the prior distribution $p(x_0,\theta)$ was specified by equations \eqref{eqn:fmri:pl:prior1}, \eqref{eqn:fmri:pl:prior2}, and \eqref{eqn:fmri:kappa} with $\kappa = 1$. However, prior means $b_0$ and $\varphi_0$ were set to the average MLEs (under the corresponding model for which the PL is to be run) of $\beta$ and $\phi$, respectively, among voxels in the brain region (or cluster for SV-left and SV-right) from which the voxel being analyzed came from (MLEs were calculated as described in Section \ref{sec:fmri:mle}, summarized in Tables \ref{tab:fmri:mle:means} and \ref{tab:fmri:mle:clusters}). The inverse-gamma hyperparameters $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ were set such that the prior means for each of $\sigma^2_s$ and $\sigma^2_m$ were equal to their respective regional or cluster average MLEs, and such that each prior variance was equal to $500$.

For each voxel-specific time series, we estimated the marginal likelihood of the data under each of $M_{011}$ and $M_{101}$ from the output of the PL algorithm run under each model. We also computed the exact marginal likelihood under $M_{001}$ for time series from each voxel using equations \eqref{eqn:ols:marglik} and \eqref{eqn:bayesreg} (with prior hyperparameters specified as in the previous paragraph). We then used the estimated and exact marginal likelihoods to compute approximate relative posterior probabilities among the three models for each voxel, according to equation \eqref{eqn:modelcomp}, with prior model probabilities equal to 1/3 for each model. The model with the highest posterior probability for a given voxel was determined to be the ``preferred'' model for that voxel. The proportion of voxels that prefer each of the models across the six different brain regions are displayed in Table \ref{tab:fmri:favor}.

From Table \ref{tab:fmri:favor}, it is clear that a vast majority of the voxels prefer $M_{101}$. The compositional plots in Figure \ref{fig:fmri:comp:real} affirm this as well, with a majority of points from each brain region concentrated near the corner of the ternary diagram represented by $M_{101}$. Models that account for temporal autocorrelation in fMRI time series using a constant slope and an autocorrelated error structure, such as $M_{101}$, have been standard in fMRI studies, and these results provide further support for that standard.

%\begin{figure}
%\ssp
%\centering
%\caption{Log marginal likelihoods of real fMRI data} \label{fig:fmri:loglik:real}
%\includegraphics[width=1.0\textwidth]{craig_pl-loglik-1-5000-1-FALSE-FALSE-FALSE}
%\caption*{Kernel density approximation to the distribution of log marginal likelihood estimates of data from 125 voxels from each of 6 different brain regions (plot panels) for $M_{011}$ (black lines) and $M_{101}$ (red lines) along with true log marginal likelihood of $M_{001}$ (blue vertical lines) using PL with 5000 particles.}
%\end{figure}

\begin{table}
\ssp
\centering
\caption{Proportion of voxels favoring different regression models} \label{tab:fmri:favor}
\begin{tabular}{|c|ccc|}
\hline
Region & $M_{101}$ & $M_{011}$ & $M_{001}$ \\
\hline
FP & 0.976 & 0.000 & 0.024 \\
IPS-left & 0.992 & 0.008 & 0.000 \\
IPS-right & 0.880 & 0.096 & 0.024 \\
PV & 1.000 & 0.000 & 0.000 \\
SV-left & 0.800 & 0.144 & 0.056 \\
SV-right & 0.952 & 0.032 & 0.016 \\
\hline
\end{tabular}
\caption*{Proportion of voxels in each brain region (rows) with highest posterior model probability for each of $M_{101}$, $M_{011}$, and $M_{001}$ (columns). For $M_{101}$ and $M_{011}$, posterior model probabilities were approximated using the PL with 5000 particles. For $M_{001}$, the true posterior probability was calculated analytically according to equation \eqref{eqn:ols:marglik}. The prior distribution, $p(x_0,\theta)$, assumed for each of the three models is as described at the beginning of Section \ref{sec:fmri:real}.}
\end{table}

\begin{figure}
\ssp
\centering
\caption{Posterior probabilities of dynamic regression models for real fMRI data} \label{fig:fmri:comp:real}
\includegraphics[width=1.0\textwidth]{craig_pl-comp-1-5000-1-FALSE-FALSE-FALSE}
\caption*{Posterior model probabilities among dynamic regression models (corners of triangles) calculated according to equation \eqref{eqn:modelcomp} and represented via compositional plots for 125 voxels (black dots) in each of 6 brain regions (plot panels). Marginal likelihoods for calculating posterior model probabilities were calculated analytically using equation \eqref{eqn:ols:marglik} for $M_{001}$, and approximated using the PL with 5000 particles for each of $M_{011}$ and $M_{101}$. The prior distribution $p(x_0,\theta)$ assumed for each model is as described at the beginning of Section \ref{sec:fmri:real}. Each point represents a set of posterior probabilities (one for each model), and the proximity of the point to a particular corner of the triangle represents the posterior probability of the model in that corner relative to the other models.}
\end{figure}

However, there are a few brain regions for which a small percentage of voxels prefer $M_{011}$ or $M_{001}$. Most notably, about 10\% of voxels in IPS-right and close to 15\% of voxels in SV-left prefer $M_{011}$. To examine this further, we have plotted 95\% credible intervals for the filtered distributions of the dynamic slope, $p(\beta_1 + x_t|y_{1:t})$ at each time $t$, based on samples generated from the PL runs under $M_{011}$. We also display 95\% credible intervals for $\phi$ and $\sigma^2_s / \sigma^2_m$ for each voxel based on samples from these PL runs generated at time $t = T = 245$ (i.e. conditional on all the data). Figures \ref{fig:fmri:slopes:real:IPSr} and \ref{fig:fmri:slopes:real} display these intervals for 5 by 5 slices of voxels in IPS-right and SV-left, respectively. In addition, in Figure \ref{fig:fmri:slopes:real} for SV-left, we have color coded the lines representing the sequential credible intervals according to whether the corresponding voxel falls into the low or high activation cluster (there is only one cluster in IPS-right, hence only one line color throughout Figure \ref{fig:fmri:slopes:real:IPSr}). Colored bars have been inserted along the top of the plots to provide a visualization of the relative posterior model probabilities for each voxel. A legend lists the models and corresponding colors.

These figures for both slices of voxels reveal spatial patterns in the voxel-specific model preferences. For example, a cluster of voxels in the top two rows of Figure \ref{fig:fmri:slopes:real:IPSr} (corresponding to neighboring voxels from the slice from IPS-right) prefer $M_{011}$ or $M_{001}$, while the rest prefer $M_{101}$. In SV-left \ref{fig:fmri:slopes:real}, a cluster of voxels in the top left portion of the slice prefer $M_{011}$ or $M_{001}$, with the rest preferring $M_{101}$. In both brain regions, it appears that the voxels which prefer $M_{011}$ or $M_{001}$ tend to have lower values of the dynamic slope throughout time than do the voxels which prefer $M_{101}$. This is more pronounced in SV-left, where the k-means clustering method separated voxels into low and high activation clusters. In addition, voxels in SV-left which prefer $M_{101}$ tend to have 95\% credible intervals for $\phi$ which contain larger values than do 95\% credible intervals for voxels which prefer $M_{011}$, and in some cases the upper bounds of these intervals extend near or beyond the stationary region (i.e. close to or greater than 1). The behavior of the dynamic slopes for these voxels appears to be nonstationary, with a rising trend over the course of the experiment.

%In addition, it appears that the voxels in or near the cluster which prefers $M_{101}$ have larger estimated values of $\phi$, the autocorrelation coefficient for the dynamic slope, although the uncertainty in these estimates is large for some voxels. resulting in dynamic slopes which tend to rise over the course of the experiment.

%We notice from this slice of voxels that there is a spatial nature to the location of the low and high activation clusters. In addition, we see a spatial pattern associated with which model the voxels prefer. The cluster of voxels that prefer the dynamic slope model seem to lie along the gradient between the low and high activation clusters, suggesting the possibility that the temporal shift in activation over the course of the experiment is related to the spatial shift. This increase in neural activity could perhaps be in response to a shift in focus or adaptation in the processing of words on the part of the subject in the scanner, with the response being prominent in some voxels more than others.

\begin{figure}
\ssp
\centering
\caption{Filtered dynamic slopes and posterior model probabilities for data from IPS-right} \label{fig:fmri:slopes:real:IPSr}
\includegraphics[width=1.0\textwidth]{craig_state-pl-IPS-right-M101-1-FALSE-5000}
\caption*{Sequential 95\% credible intervals for dynamic slopes (lines) and 95\% credible intervals for $\phi|y_{1:T}$ and $\frac{\sigma^2_s}{\sigma^2_m}|y_{1:T}$ (the latter two fixed parameter credible intervals are written in text above each plot panel). Each interval was obtained by running PL under $M_{011}$ with 5000 particles on time series from each voxel in a 5 by 5 slice in the y-z plane of the left intraparietal sulcus. Pink lines represent results based on all 125 IPS-right voxels, since clustering was not applied in this brain region. The proportion of the solid bar along the top of a particular plot panel colored for a specific model (as indicated in the model legend) represents the posterior probability of that model, relative to the other models, given data from the corresponding voxel for that plot panel (also represented by Figure \ref{fig:fmri:comp:real}). The prior distribution $p(x_0,\theta)$ assumed for each model is as described at the beginning of Section \ref{sec:fmri:real}.}
\end{figure}

\begin{figure}
\ssp
\centering
\caption{Filtered dynamic slopes and posterior model probabilities for data from SV-left} \label{fig:fmri:slopes:real}
\includegraphics[width=1.0\textwidth]{craig_state-pl-SV-left-M101-3-FALSE-5000}
\caption*{Sequential 95\% credible intervals for dynamic slopes (lines) and 95\% credible intervals for $\phi|y_{1:T}$ and $\frac{\sigma^2_s}{\sigma^2_m}|y_{1:T}$ (the latter two fixed parameter credible intervals are written in text above each plot panel). Each interval was obtained by running PL under $M_{011}$ with 5000 particles on time series from each voxel in a 5 by 5 slice in the y-z plane of secondary visual left. Line colors correspond to whether a voxel was classified into the low (black lines) or high (pink lines) activation cluster according to the k-means clustering algorithm applied to the MLEs for $\theta$ obtained in Section \ref{sec:fmri:mle}. The proportion of the solid bar along the top of a particular plot panel colored for a specific model (as indicated in the model legend) represents the posterior probability of that model, relative to the other models, given data from the corresponding voxel for that plot planet (also represented by Figure \ref{fig:fmri:comp:real}). The prior distribution $p(x_0,\theta)$ assumed for each model is as described at the beginning of Section \ref{sec:fmri:real}.}
\end{figure}

The results shown in Figures \ref{fig:fmri:slopes:real:IPSr} and \ref{fig:fmri:slopes:real} seem to run counter to our hypothesis that the dynamic slope model would be better suited than the dynamic intercept model to model changes in brain activation over the course of the experiment. Specifically, voxels in IPS-right and SV-left with dynamic slopes that change the most over time tend to prefer the dynamic intercept model. One explanation for this could be that an increase in neural activity over the course of the experiment is also accompanied by an increase in sources of autocorrelation, such as heartbeat or respiration, that are better accounted for by the dynamic intercept model, but nonetheless manifest themselves in terms of an increasing dynamic slope when fit by $M_{011}$.

An alternate explanation for these results could be that the increase in the dynamic slope over time is not due to increased neural activity, but rather to mis-specification of the hrf. The errors between the observed and expected BOLD responses in voxels for which the canonical hrf used in this analysis is inaccurate will be temporally autocorrelated, and they could be modeled according to a first-order autoregressive process as in $M_{101}$. The dynamic slope model could be accounting for inaccuracies in the hrf through an increasing slope, while the dynamic intercept model more suitably captures these inaccuracies through a dynamic intercept. Voxels which prefer $M_{011}$ or $M_{001}$ could have BOLD responses that are more accurately characterized by the canonical hrf, and the gradual increase in the dynamic slope for these voxels could reflect small changes in neural activation or other sources of autocorrelation that mirror the stimulus pattern.

%or physiological processes like heartbeat and respiration. These sources of autocorrelation in the data may be more suitably modeled by $M_{101}$, as evidenced by the fact that most of the voxels in the high activation cluster prefer $M_{101}$. The voxels that prefer $M_{011}$ or $M_{101}$ could lie in areas where the hrf is more accurate or where signals due to physiological processes are not as pronounced. The fact that a few of these voxels prefer $M_{001}$ over $M_{011}$ supports this hypothesis.

Model identification results from Sections \ref{sec:fmri:id} and \ref{sec:fmri:dist} suggest that our model comparison analysis using PL should be used with caution. Specifically, the true $\phi$ and $\sigma^2_s / \sigma^2_m$ need to be sufficiently large in order to be able to identify the true model among $M_{011}$, $M_{101}$, $M_{001}$ using an estimate of the marginal likelihood. In addition, the marginal likelihood can be sensitive to specific prior distributions on the unknown states and fixed parameters. For example, if the prior distribution of states and fixed parameters used in this Section is closer to the posterior under $M_{101}$ than it is to the posterior under $M_{011}$, model comparison results based on the marginal likelihood of the data could be biased toward $M_{101}$. The average maximum likelihood estimates of $\phi$ and $\sigma^2_s$ for IPS-right and SV-left shown in Tables \ref{tab:fmri:mle:means} and \ref{tab:fmri:mle:clusters}, respectively, appear to be high enough to believe that the results shown in Figures \ref{fig:fmri:slopes:real:IPSr} and \ref{fig:fmri:slopes:real} are not a fluke to misidentification. However, the 95\% credible interval estimates for $\phi$ and $\sigma^2_s / \sigma^2_m$ obtained from running the PL, displayed above the plots in Figures \ref{fig:fmri:slopes:real:IPSr} and \ref{fig:fmri:slopes:real}, indicate that there is a large degree of uncertainty in these parameter estimates.

\section{Discussion \label{sec:fmri:discussion}}

In this chapter, we present an analysis of fMRI data collected from an episodic word recognition task, focusing specifically on voxels from six different brain regions. Using maximum likelihood estimation, we fit regression models with ARMA errors to data from randomly selected voxels in each brain region, and we found that AIC and AICC prefer models with an ARMA(3,3) error structure while BIC tends to prefer AR(1) or ARMA(1,1) errors. We showed via simulation that testing for significant brain activation in fMRI time series using a standard OLS regression technique leads to an inflation of the false positive rate of concluding significant brain activation. In addition, we showed that in the presence of highly autocorrelated time series, a method for adjusting the degrees of freedom in the t-test for significant brain activation can lower the false positive rate while decreasing the power of the test. We also illustrated using a simulated example that comparing autocorrelation estimation algorithms by examining the independence of model residuals can give misleading results.

We proposed models for accounting for autocorrelation in fMRI data that contain a dynamic intercept, dynamic slope, or both. Using simulated fMRI data from each model, we explored parameter settings under which the distribution of maximum likelihood estimates appear normally distributed and centered at the true values. We concluded that it is easiest to find parameter settings under which the dynamic slope model can be identified in this way, while identification of the model with both a dynamic slope and dynamic intercept is the most difficult. We fit the dynamic slope, dynamic intercept, and ordinary regression models to the word recognition data set using maximum likelihood and identified clusters of high and low activation in the secondary visual cortex.

Lastly, we introduced a model comparison strategy based on estimating the marginal likelihood of data under different models using PL. We showed using simulated data that sufficiently high lag-1 autocorrelation and signal-to-noise needs to be present in the data in order to correctly select the dynamic slope or dynamic intercept model. Using the fMRI data from the word recognition experiment, we estimated relative posterior probabilities among the dynamic slope, dynamic intercept, and ordinary regression models and found that a vast majority of voxels prefer the dynamic intercept model, while the region with the highest percentage of voxels that prefer the dynamic slope model is the left secondary visual cortex ($\approx$ 15\%).

It is conceivable that the most appropriate model for this data might be one with both a dynamic intercept and a dynamic slope. For instance, it could be the case that, for most voxels, variation in the data due to sources that may be better captured by the dynamic intercept model, such as physiological processes or misspecification of the hrf, overwhelm variation in the data that could be captured by a dynamic slope, such as learning. The small clusters of voxels that prefer the dynamic slope model could be one of the few areas where the dynamic slope component accounts for more of the variation in the data. The fact that a significant portion of the relative posterior model probability in these voxels belongs to $M_{001}$ (i.e. visible blue bars in Figures \ref{fig:fmri:slopes:real:IPSr} and \ref{fig:fmri:slopes:real}) further supports the notion that the dynamic slope accounts for very little of the autocorrelation in the data relative to the dynamic intercept.

Our results in Section \ref{sec:fmri:id} suggest that fMRI experiments with runs lasting for only $T = 250$ TRs do not generate time series long enough to adequately estimate fixed parameters in the model with both a dynamic slope and dynamic intercept. Spatio-temporal modeling approaches that borrow information from neighboring voxels could possibly alleviate this problem and open up the possibility of correctly analyzing models with multiple autoregressive components. Several more recent studies have used spatio-temporal models that incorporate time-varying regression slopes to study dynamic brain connectivity \citep{ho:ombao:2005:statespace,bhatt:matira:aoas:2011}.

The results from this section support the use of a dynamic intercept model, i.e. a model with a constant slope and autocorrelated error structure, which has been the norm in voxel-wise analysis of fMRI time series using the GLM. The dynamic slope model, despite being less suitable for the word recognition data, is perhaps a more interpretable model and, as shown in Section \ref{sec:fmri:dist}, can be more easily identified when it is the true model. The use of the PL algorithm for model comparison provides insight into the relative appropriateness of these models for describing the behavior of neural activation in specific brain regions of interest, and provides motivation for parameterizing future models for fMRI data in terms of a dynamic slope. 