\chapter{Simulation study: SMC model comparison of local level DLMs \label{ch:comp}}

In Chapter \ref{ch:epid}, we illustrated the improved performance of the KDPF over the BF and APF within the context of tracking an epidemic using a model that contains unknown fixed parameters. In this chapter, we compare the KDPF with more advanced strategies, specifically the RM and PL. In particular, we focus on how efficiently these algorithms perform in terms of estimating the marginal likelihood and comparing possible data-generating models. To evaluate the relative performance of the particle filters, we simulate data from the local level DLM with common observation and state variance factor described in Section \ref{sec:dlm:ll}, since this model emits an analytically tractable form of the marginal likelihood of the data.

This short chapter consists of three sections. Section \ref{sec:comp:data} describes the simulated data set as well as estimation of states and the unknown common precision factor (i.e. the inverse of the unknown common variance factor) using analytical forms of the their respective marginal filtered distributions. Section \ref{sec:comp:est} describes estimation of states and the unknown common precision factor using the KDPF, RM, and PL. Finally, in Section \ref{sec:comp:models}, we compare the performance of the KPDF, RM and PL in terms of efficiency in estimating the marginal likelihood of the data and relative posterior probabilities among local level DLMs of the form given by equations \eqref{eqn:ll:obs} and \eqref{eqn:ll:state} with varying signal-to-noise ratios.

\section{Simulated data and analytical forms for estimation} \label{sec:comp:data}

Consider the local level DLM with unknown common state and observation variance factor, $\theta$, and known signal-to-noise ratio, $\lambda$, given by equations \eqref{eqn:ll:obs} and \eqref{eqn:ll:state} and rewritten below as
\begin{align*}
y_t &\sim \mbox{N}(x_t, \theta) \\
x_t &\sim \mbox{N}(x_{t-1}, \theta\lambda).
\end{align*}
A time series of length $T = 100$ was simulated from this model with true $\theta = \lambda = 1$. The data, $y_t$, and true unobserved states $x_t$, for $t=1,\ldots,T$, are shown by black dots and lines, respectively, in the left panel of Figure \ref{fig:comp:data}.

\begin{figure}[ht]
\ssp
\centering
\caption{Simulated data and analytical estimates for local level DLM} \label{fig:comp:data}
\includegraphics[width=1.0\textwidth]{cv-states-precision-1}
\caption*{True observed data (black dots) and unobserved states (black lines) for data simulated from the local level DLM from equations \eqref{eqn:ll:obs} and \eqref{eqn:ll:state} with $\theta = \lambda = 1$, along with marginal 95\% credible intervals (red lines) for the states (left) and precision (right), as well as 95\% one-step ahead prediction intervals (blue lines) for the data (left).}
\end{figure}

We assume the prior distribution $p(x_0,\theta)$ from equation \eqref{eqn:ll:prior} with $a_0 = b_0 = 1$. The red and blue lines in the left panel of Figure \ref{fig:comp:data} show 95\% credible intervals, at each time $t$, for the marginal filtered distribution of $x_t$ and the one-step ahead predictive distribution for $y_t$, respectively. We can obtain these intervals without need for running a particle filter because these distributions can be calculated analytically according to equations \eqref{eqn:ll:marg} and \eqref{eqn:ll:onestep}. Similarly, we can calculate sequential 95\% credible intervals for the marginal filtered distribution of the unknown common state and observation precision factor, $1/\theta$, since this is known analytically to follow a gamma distribution with shape $a_t$ and rate $b_t$  (see right panel of Figure \ref{fig:comp:data}). The shape and rate are calculated recursively according to equation \eqref{eqn:ll:kal}. We estimate the common precision factor instead of the common variance factor because quantiles of the gamma distribution are easier to obtain than quantiles of the inverse-gamma distribution.

In practice, particle filters are not needed to analyze data from this model since analytical forms for the filtered distributions of states and unknown parameter are available. However, in the remaining sections of this chapter, we use the analytical forms of these distributions, referred to as the ``true posterior'' or ``true filtered distribution'', as a benchmark for assessing the performance of the KDPF, RM, and PL. Specifically, we search for the algorithm which yields the best approximation to the true posterior while requiring the fewest number of particles.

\section{Estimation using particle filters} \label{sec:comp:est}

The KDPF, RM, and PL were each run twenty times on the simulated data set using $J = 100, 500, 1000, \mbox{ and } 5000$ particles. For each particle filter run, the data were assumed to be generated from the local level DLM described by equations \eqref{eqn:ll:obs} and \eqref{eqn:ll:state} with $\lambda = 1$ (i.e. the true model from which the data were simulated). Resampling was performed in each algorithm at time points where the effective sample size dropped below $0.8J$ (this is the same resampling threshold used in Chapter \ref{ch:epid}). For the KDPF, the discount factor $\Delta$ was set to 0.99, and the RM and PL were implemented as described in Sections \ref{sec:rm:ll} and \ref{sec:pl:ll}. Each algorithm was run assuming a prior of the form given in \eqref{eqn:ll:prior} with $a_0 = b_0 = 1$.

Sequential 95\% credible intervals for the marginal filtered distributions of $x_t$ and $1/\theta$ for each $J$ are displayed in Figure \ref{fig:comp:quant}. Compared with the 95\% credible intervals of the true filtered distribution of the states, all algorithms seem to perform well, yielding credible intervals in line with the truth for $J > 100$. The KDPF, however, is outperformed by the other two algorithms, with credible intervals for the filtered precision that are inaccurate for $J < 1000$ and exhibit wide variability around the true upper bounds of the intervals for $J >= 1000$.

The RM and PL both perform well, yielding sequential 95\% credible intervals for both $x_t$ and $1/\theta$ near those for their respective true filtered distributions for $J = 100$. By $J = 5000$ the true and estimated bounds for both $x_t$ and $1/\theta$ become almost indistinguishable from one another using either algorithm. Looking at the filtered precision for $J = 100$, however, credible intervals generated by the RM within a single particle filter run appear to exhibit more variability than those generated within a single run of the PL algorithm.

\begin{figure}[ht]
\ssp
\centering
\caption{Comparing sequential credible intervals for KDPF, RM, and PL} \label{fig:comp:quant}
\includegraphics[width=0.65\textwidth]{cv-pl-quant-10-1-20-5}
\caption*{Sequential 95\% credible intervals for the marginal filtered distribution of the states (left) and precision (right) for increasing number of particles $J$ (rows) for the KDPF (green lines), RM (blue lines), and PL (red lines) compared with the true posterior (black lines) and true simulated values (gray lines). All axes within columns are on the same scale.}
\end{figure}

\section{Comparing models with varying signal-to-noise ratios} \label{sec:comp:models}

We now discuss estimation of the marginal likelihood of the simulated data and calculating posterior model probabilities. Recall that, given the density of the one-step ahead predictions, the marginal likelihood can be calculated by equation \eqref{eqn:ll:marglik}. Since the distribution of the one-step ahead predictions, $p(y_t|y_{1:t-1})$ for all $t$, is known for a local level DLM with common observation and state variance factor, the marginal likelihood $p(y_{1:T})$ can be calculated analytically. For computational stability, we calculate the log marginal likelihood, $\log p(y_{1:T})$, when comparing different models.

The true signal-to-noise ratio $\lambda$ for our simulated data is 1. However, we can consider the marginal likelihood of the data under models with a different $\lambda$. Figure \ref{fig:comp:lambda} displays the true log marginal likelihood of the data when different values of $\lambda$ are assumed. Notice that, starting at $\lambda = 0$, there is a sharp increase in $\log p(y_{1:T})$ to maximum value as we approach the true $\lambda$ of 1, with a gradual decrease in $\log p(y_{1:T})$ for $\lambda > 1$.

\begin{figure}[ht]
\ssp
\centering
\caption{Log marginal likelihood versus $\lambda$} \label{fig:comp:lambda}
\includegraphics[width=1.0\textwidth]{cv-loglikVlambda}
\caption*{True log marginal likelihood (y-axis) of simulated data from the local level DLM with common state and observation variance factor for increasing signal-to-noise ratio $\lambda$ (x-axis). Solid vertical line denotes the true log marginal likelihood under the model with $\lambda = 1$, and dashed vertical lines represent the true log marginal likelihood under $\lambda = 0.5$ and $\lambda = 2$.}
\end{figure}

We ran each particle filter twenty more times for each of $J = 100, 500, 1000, \mbox{ and } 5000$ under the local level DLM described by equations \eqref{eqn:ll:obs} and \eqref{eqn:ll:state} with $\lambda$ assumed to be 0.5. We then repeated these runs for $\lambda = 2$. We consider these two values of $\lambda$ because, as seen from Figure \ref{fig:comp:lambda}, these two values of $\lambda$ yield log marginal likelihoods that are lower than the true value but fairly close to one another. Figure \ref{fig:comp:loglik} shows kernel density approximations to the empirical distributions of the twenty log marginal likelihood estimates, $\log p(y_{1:T})$, generated using each particle filter for each $J$ and $\lambda$. For $\lambda = 1 \mbox{ and } 2$, the PL appears to provide a better estimate of $\log p(y_{1:T})$ the fastest as a function $J$, as indicated by more concentrated densities around the truth relative to the RM and KDPF. For $J > 100$ and $\lambda = 0.5$, the RM is competitive with PL, while the KDPF appears to be outperformed in all scenarios.

\begin{figure}[ht]
\ssp
\centering
\caption{Comparing log marginal likelihood for KDPF, RM, and PL} \label{fig:comp:loglik}
\includegraphics[width=0.9\textwidth]{cv_pl_loglik-5-10-20-1-20}
\caption*{Kernel density estimates of the distribution of twenty log marginal likelihood estimates generated by running the KDPF (green lines), RM (blue lines), and PL (red lines) under local level DLMS with common state and observation variance factor and different values of the signal-to-noise ratio $\lambda$ (columns) and increasing number of particles $J$ (rows), compared with the true log marginal likelihood (solid black vertical lines with values printed along the x-axis). Dashed black vertical lines on graphs within a particular column correspond to the true log marginal likelihood of the data under models with $\lambda$ equal to values from the other columns. Axes for all plot panels are on the same scale.}
\end{figure}

Lastly, we can consider posterior model probabilities among the set of models that assume $\lambda = 0.5, 1, \mbox{ and } 2$. We assume the prior probability of each model is $1/3$, and calculate posterior model probabilities according to equation \eqref{eqn:modelcomp} with $N = 3$ and $M_1$, $M_2$, and $M_3$ representing models with $\lambda = 0.5, 1, \mbox{ and } 2$, respectively. Given a single estimate of the log marginal likelihood of the data under each of $M_1$, $M_2$, and $M_3$, a set of posterior probabilities among the three models can be calculated according to equation \eqref{eqn:modelcomp}. Thus, for each of the KDPF, RM, and PL, we generate twenty such sets. We also calculate the set of true posterior probabilities among the three models by plugging in the true marginal likelihood of the data under each model into equation \eqref{eqn:modelcomp}.

Figure \ref{fig:comp:post} summarizes these calculations using compositional plots, where each corner of the ternary diagrams represents one of the three possible models. Each point in a diagram represents a set of three posterior probabilities, one for each model, estimated by a specific particle filtering algorithm using $J$ particles. The PL appears to perform the best, as the clustering of red points hones in around the point representing the true posterior probabilities the fastest with increasing $J$. The KDPF, again, is outperformed, needing at least 5000 particles to even start to cluster around the true posterior.

\begin{figure}[ht]
\ssp
\centering
\caption{Comparing posterior model probabilities for KDPF, RM, and PL} \label{fig:comp:post}
\includegraphics[width=1.0\textwidth]{cv_pl_ternary-5-10-20-1-20}
\caption*{Posterior model probabilities among local level DLMs with common state and observation variance factor and different signal-to-noise ratios $\lambda$ (corners of triangles) for twenty runs of the KDPF (green dots), RM (blue dots), and PL (red dots) using increasing number of particles $J$ (plot panels). Each point represents a set of posterior probabilities (one for each model), and the proximity of each point to a particular corner of the triangle represents the posterior probability of the model in that corner relative to the other models. The true posterior probabilities are represented by the gray dot (the same for all panels).}
\end{figure}

In this chapter, we've compared the relative performance of the KDPF, RM, and PL for comparing local level DLMs with common state and observation variance factor and different signal-to-noise ratios. The superior performance of PL relative to the RM is convenient from the practitioner's perspective, since this algorithm is easier to implement than the RM, which requires the specification of an MCMC algorithm in addition to the SMC. However, PL can only be used for specific models where the the distributions $p(y_{t+1}|x_t,\theta)$, $p(x_{t+1}|y_t,x_t,\theta)$, and $p(\theta|y_{1:t},x_{0:t})$ are analytically tractable. The dynamic regression models described in Sections \ref{sec:dlm:M101} and \ref{sec:dlm:M011} emit analytical tractable forms of these distributions, and so we use PL for comparing these models in Chapter \ref{ch:fmri}. 